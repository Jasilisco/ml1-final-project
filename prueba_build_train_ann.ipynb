{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code build and train ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./code/general/utils_general.jl\")\n",
    "\n",
    "include(\"./code/ann/build_train.jl\")\n",
    "include(\"./code/ann/utils_ann.jl\")\n",
    "\n",
    "using Pkg; Pkg.add(\"DelimitedFiles\");    \n",
    "using DelimitedFiles\n",
    "\n",
    "using Pkg; Pkg.add(\"Plots\")\n",
    "using Plots; Pkg.add(\"PyPlot\")\n",
    "\n",
    "\n",
    "\n",
    "#Load iris dataset\n",
    "dataset = readdlm(\"./data_test/iris.data\",',');\n",
    "datasetLength = size(dataset, 1)\n",
    "\n",
    "\n",
    "(trainIndexes, validationIndexes, testIndexes) = holdOut(datasetLength, 0.2, 0.2)\n",
    "(trainDataset, validationDataset, testDataset) = (dataset[trainIndexes, :], dataset[validationIndexes, :], dataset[testIndexes, :])\n",
    "\n",
    "\n",
    "(trainInput, validationInput, testInput) = (convert(Array{Float32,2}, trainDataset[:,1:4]), convert(Array{Float32,2}, validationDataset[:,1:4]), convert(Array{Float32,2}, testDataset[:,1:4]))\n",
    "\n",
    "\n",
    "classes = unique(trainDataset[:,5])\n",
    "(trainOutput, validationOutput, testOutput) = (oneHotEncoding(trainDataset[:,5], classes), oneHotEncoding(validationDataset[:,5], classes), oneHotEncoding(testDataset[:,5], classes))\n",
    "\n",
    "\n",
    "# Normalization \n",
    "normalizationParameters = calculateMinMaxNormalizationParameters(trainInput);\n",
    "(trainInputNormalized, validationInputNormalized, testInputNormalized) = (normalizeMinMax(trainInput, normalizationParameters), normalizeMinMax(validationInput, normalizationParameters), normalizeMinMax(testInput, normalizationParameters))\n",
    "\n",
    "\n",
    "#Define the parameters\n",
    "topology = [4, 3]; \n",
    "learningRate = 0.01;\n",
    "numMaxEpochs = 1000; \n",
    "topologies_to_try = [[5], [10], [4, 3], [8, 4]]\n",
    "    \n",
    "for topo in topologies_to_try\n",
    "    println(\"Training with topology: \", topo)\n",
    "    (ann, trainingLosses, validationLosses, testLosses) = trainClassANN(topo, (trainInputNormalized, trainOutput); validationDataset=(validationInputNormalized, validationOutput), testDataset=(testInputNormalized, testOutput), maxEpochs=numMaxEpochs, learningRate=learningRate);\n",
    "\n",
    "  g =  plot(1:length(trainingLosses), \n",
    "    trainingLosses, \n",
    "    label=\"Train losses\", \n",
    "    xlabel=\"Epoch\", \n",
    "    ylabel=\"Loss value\", \n",
    "    title=\"Loss evolution\")\n",
    "\n",
    "    if !isempty(validationLosses)\n",
    "        plot!(1:length(validationLosses), validationLosses, label=\"Validation losses\")\n",
    "    end\n",
    "\n",
    "    if !isempty(testLosses)\n",
    "        plot!(1:length(testLosses), testLosses, label=\"Test losses\")\n",
    "    end\n",
    "\n",
    "    display(g)\n",
    "end;  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./code/general/train_metrics.jl\")\n",
    "\n",
    "#Test boolean and boolean function\n",
    "outputs=[0,0,1,1,0,1,1,0,0,0,1,1]\n",
    "targets=[0,1,1,0,1,1,1,0,1,1,0,0]\n",
    "printConfusionMatrix(convert(Array{Bool,1}, outputs), convert(Array{Bool,1}, targets));\n",
    "println(\"\\n\\n\")\n",
    "\n",
    "#Test real and boolean\n",
    "outputs=[0.4; 0.6; 1; 0.4;  0.55]\n",
    "targets=[0;   1;   1; 1; 0]\n",
    "printConfusionMatrix(convert(Array{Real,1}, outputs), convert(Array{Bool,1}, targets));\n",
    "\n",
    "\n",
    "#Test array bool\n",
    "testOutputs=Bool[0 0 1;1 0 0;0 1 0; 0 0 1; 0 0 1]\n",
    "testTargets=Bool[0 0 1;0 1 0;0 1 0; 1 0 0; 1 0 0]\n",
    "printConfusionMatrix(testOutputs, testTargets, weighted=false)\n",
    "println(\"\\n\\n\")\n",
    "\n",
    "#Test array real and target bool\n",
    "testRealOutputs=Real[0 0 0.7;0 0 0.6;0 1 0; 0 0 1; 0 0 1]\n",
    "printConfusionMatrix(testRealOutputs, testTargets, weighted=false)\n",
    "println(\"\\n\\n\")\n",
    "\n",
    "#Test array any \n",
    "result = confusionMatrix(testOutputs, testTargets)\n",
    "\n",
    "testClasses=[\"dog\", \"cat\", 3, :green, \"dog\", 3, \"dog\"]\n",
    "testClassesTargets=[\"dog\", \"cat\", 3, :green, \"dog\", 3, \"dog\"]\n",
    "uniqueClasss=unique(testClasses)\n",
    "printConfusionMatrix(testClasses, testClassesTargets, uniqueClasss)\n",
    "println(\"\\n\\n\")\n",
    "\n",
    "#Test two classes \n",
    "result = confusionMatrix(testOutputs, testTargets)\n",
    "\n",
    "testClasses=[\"dog\"; \"cat\"]\n",
    "testClassesTargets=[\"dog\"; \"cat\"]\n",
    "uniqueClasss=unique(testClasses)\n",
    "printConfusionMatrix(testClasses, testClassesTargets, uniqueClasss)\n",
    "println(\"\\n\\n\")\n",
    "println(\"hola\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD AND TRAIN CROSS VALIDATION ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg; Pkg.add(\"DelimitedFiles\");    \n",
    "using DelimitedFiles\n",
    "\n",
    "include(\"./code/general/utils_general.jl\")\n",
    "include(\"./code/ann/build_train.jl\")\n",
    "include(\"./code/ann/utils_ann.jl\")\n",
    "\n",
    "\n",
    "a=[false,true, false, true, true, false]\n",
    "\n",
    "\n",
    "result = crossvalidation(5, 3)\n",
    "\n",
    "println(\"Result\", result)\n",
    "\n",
    "b = crossvalidation(a, 3)\n",
    "println(\"Cross validation AbstractArray{Bool, 1}\", b)\n",
    "\n",
    "\n",
    "a = Bool[0 1;1 0;1 0; 0 1;0 1]\n",
    "\n",
    "bool2_indices = crossvalidation(a, 10)\n",
    "println(\"Cross validation AbstractArray{Bool,2} \", bool2_indices)\n",
    "\n",
    "unique(bool2_indices)\n",
    "\n",
    "\n",
    "any_array = ['a', :b, 1, 'a']\n",
    "one = oneHotEncoding(any_array)\n",
    "\n",
    "println(\"Size \", size(any_array, 1), \" lenght one \" ,length(one), \" size one \", size(one), \"number columns one\", size(one, 2))\n",
    "\n",
    "any_indices = crossvalidation(any_array, 2)\n",
    "println(\"Cross validation AbstractArray{<:Any,2} \", any_indices)\n",
    "\n",
    "\n",
    "#HOW TO\n",
    "\n",
    "b = [1 1 1 \"perro\"; 0 0 0 \"gato\"]\n",
    "\n",
    "\n",
    "#Load iris dataset\n",
    "dataset = readdlm(\"./data_test/iris.data\",',');\n",
    "datasetLength = size(dataset, 1)\n",
    "\n",
    "\n",
    "(trainIndexes, testIndexes) = holdOut(datasetLength, 0.2)\n",
    "(trainDataset, testDataset) = (dataset[trainIndexes, :], dataset[testIndexes, :])\n",
    "(trainInput, testInput) = (convert(Array{Float32,2}, trainDataset[:,1:4]), convert(Array{Float32,2}, testDataset[:,1:4]))\n",
    "\n",
    "\n",
    "\n",
    "classes = unique(trainDataset[:,5])\n",
    "normalizationParameters = calculateMinMaxNormalizationParameters(trainInput);\n",
    "(trainInputNormalized, testInputNormalized) = (normalizeMinMax(trainInput, normalizationParameters), normalizeMinMax(testInput, normalizationParameters))\n",
    "\n",
    "topology = [4, 3]; \n",
    "crossValidationIndices = crossvalidation(trainDataset[:, 5], 8)\n",
    "\n",
    "\n",
    "ANNCrossValidation(topology,\n",
    "        (trainInputNormalized, trainDataset[:, 5]),\n",
    "        crossValidationIndices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLJ CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Pablo\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: -- Training loss 1.582955 -- Validation loss:1.516366 -- Test loss 1.5363024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: -- Training loss 1.5456207 -- Validation loss:1.4820348 -- Test loss 1.5008374\n",
      "Epoch 1: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 2: -- Training loss 1.5101367 -- Validation loss:1.449493 -- Test loss 1.4671837\n",
      "Epoch 2: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 3: -- Training loss 1.4765204 -- Validation loss:1.4187559 -- Test loss 1.4353577\n",
      "Epoch 3: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 4: -- Training loss 1.4447755 -- Validation loss:1.3898245 -- Test loss 1.4053617\n",
      "Epoch 4: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 5: -- Training loss 1.4148923 -- Validation loss:1.3626877 -- Test loss 1.3771864\n",
      "Epoch 5: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 6: -- Training loss 1.3868486 -- Validation loss:1.3373212 -- Test loss 1.3508092\n",
      "Epoch 6: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 7: -- Training loss 1.3606094 -- Validation loss:1.3136894 -- Test loss 1.3261951\n",
      "Epoch 7: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 8: -- Training loss 1.33613 -- Validation loss:1.2917458 -- Test loss 1.3032995\n",
      "Epoch 8: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 9: -- Training loss 1.3133563 -- Validation loss:1.2714365 -- Test loss 1.282068\n",
      "Epoch 9: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 10: -- Training loss 1.2922277 -- Validation loss:1.2526995 -- Test loss 1.2624401\n",
      "Epoch 10: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 11: -- Training loss 1.2726784 -- Validation loss:1.2354687 -- Test loss 1.24435\n",
      "Epoch 11: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 12: -- Training loss 1.254638 -- Validation loss:1.2196738 -- Test loss 1.2277272\n",
      "Epoch 12: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 13: -- Training loss 1.2380333 -- Validation loss:1.2052413 -- Test loss 1.2124982\n",
      "Epoch 13: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 14: -- Training loss 1.2227893 -- Validation loss:1.1920958 -- Test loss 1.1985881\n",
      "Epoch 14: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 15: -- Training loss 1.208829 -- Validation loss:1.1801606 -- Test loss 1.1859199\n",
      "Epoch 15: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 16: -- Training loss 1.196075 -- Validation loss:1.1693583 -- Test loss 1.174416\n",
      "Epoch 16: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 17: -- Training loss 1.1844498 -- Validation loss:1.1596118 -- Test loss 1.1639993\n",
      "Epoch 17: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 18: -- Training loss 1.1738766 -- Validation loss:1.1508454 -- Test loss 1.1545932\n",
      "Epoch 18: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 19: -- Training loss 1.164281 -- Validation loss:1.1429843 -- Test loss 1.1461229\n",
      "Epoch 19: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 20: -- Training loss 1.1555892 -- Validation loss:1.1359558 -- Test loss 1.1385154\n",
      "Epoch 20: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 21: -- Training loss 1.1477307 -- Validation loss:1.1296904 -- Test loss 1.1317006\n",
      "Epoch 21: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 22: -- Training loss 1.1406375 -- Validation loss:1.1241211 -- Test loss 1.1256104\n",
      "Epoch 22: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 23: -- Training loss 1.1342452 -- Validation loss:1.1191844 -- Test loss 1.1201811\n",
      "Epoch 23: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 24: -- Training loss 1.1284925 -- Validation loss:1.1148205 -- Test loss 1.1153514\n",
      "Epoch 24: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 25: -- Training loss 1.1233214 -- Validation loss:1.1109723 -- Test loss 1.1110644\n",
      "Epoch 25: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 26: -- Training loss 1.1186779 -- Validation loss:1.1075876 -- Test loss 1.1072668\n",
      "Epoch 26: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 27: -- Training loss 1.1145113 -- Validation loss:1.1046172 -- Test loss 1.1039083\n",
      "Epoch 27: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 28: -- Training loss 1.110775 -- Validation loss:1.1020156 -- Test loss 1.1009427\n",
      "Epoch 28: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 29: -- Training loss 1.1074253 -- Validation loss:1.0997415 -- Test loss 1.0983278\n",
      "Epoch 29: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 30: -- Training loss 1.1044226 -- Validation loss:1.0977563 -- Test loss 1.0960243\n",
      "Epoch 30: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 31: -- Training loss 1.1017298 -- Validation loss:1.0960249 -- Test loss 1.0939962\n",
      "Epoch 31: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 32: -- Training loss 1.0993135 -- Validation loss:1.0945157 -- Test loss 1.0922103\n",
      "Epoch 32: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 33: -- Training loss 1.0971429 -- Validation loss:1.0931998 -- Test loss 1.0906376\n",
      "Epoch 33: -- Training acc  0.29577464788732394 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 34: -- Training loss 1.0951905 -- Validation loss:1.0920515 -- Test loss 1.0892509\n",
      "Epoch 34: -- Training acc  0.4225352112676056 -- Validation acc: 0.5 -- Test acc  0.44\n",
      "Epoch 35: -- Training loss 1.0934306 -- Validation loss:1.0910467 -- Test loss 1.0880257\n",
      "Epoch 35: -- Training acc  0.5774647887323944 -- Validation acc: 0.5833333333333334 -- Test acc  0.6\n",
      "Epoch 36: -- Training loss 1.0918403 -- Validation loss:1.0901645 -- Test loss 1.0869398\n",
      "Epoch 36: -- Training acc  0.5774647887323944 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 37: -- Training loss 1.0903988 -- Validation loss:1.0893859 -- Test loss 1.0859736\n",
      "Epoch 37: -- Training acc  0.5352112676056338 -- Validation acc: 0.5416666666666666 -- Test acc  0.6\n",
      "Epoch 38: -- Training loss 1.0890875 -- Validation loss:1.088694 -- Test loss 1.0851096\n",
      "Epoch 38: -- Training acc  0.4507042253521127 -- Validation acc: 0.5 -- Test acc  0.52\n",
      "Epoch 39: -- Training loss 1.0878893 -- Validation loss:1.0880736 -- Test loss 1.0843309\n",
      "Epoch 39: -- Training acc  0.36619718309859156 -- Validation acc: 0.4166666666666667 -- Test acc  0.4\n",
      "Epoch 40: -- Training loss 1.0867893 -- Validation loss:1.0875114 -- Test loss 1.0836242\n",
      "Epoch 40: -- Training acc  0.36619718309859156 -- Validation acc: 0.375 -- Test acc  0.36\n",
      "Epoch 41: -- Training loss 1.0857736 -- Validation loss:1.0869955 -- Test loss 1.0829761\n",
      "Epoch 41: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 42: -- Training loss 1.08483 -- Validation loss:1.0865153 -- Test loss 1.0823759\n",
      "Epoch 42: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 43: -- Training loss 1.0839477 -- Validation loss:1.0860611 -- Test loss 1.0818127\n",
      "Epoch 43: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 44: -- Training loss 1.0831164 -- Validation loss:1.085625 -- Test loss 1.0812784\n",
      "Epoch 44: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 45: -- Training loss 1.082328 -- Validation loss:1.0851997 -- Test loss 1.0807644\n",
      "Epoch 45: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 46: -- Training loss 1.0815738 -- Validation loss:1.0847789 -- Test loss 1.0802641\n",
      "Epoch 46: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 47: -- Training loss 1.0808474 -- Validation loss:1.0843571 -- Test loss 1.079771\n",
      "Epoch 47: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 48: -- Training loss 1.080142 -- Validation loss:1.0839287 -- Test loss 1.0792797\n",
      "Epoch 48: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 49: -- Training loss 1.0794524 -- Validation loss:1.0834907 -- Test loss 1.0787857\n",
      "Epoch 49: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 50: -- Training loss 1.0787734 -- Validation loss:1.0830382 -- Test loss 1.0782843\n",
      "Epoch 50: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 51: -- Training loss 1.0781004 -- Validation loss:1.0825686 -- Test loss 1.0777719\n",
      "Epoch 51: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 52: -- Training loss 1.0774292 -- Validation loss:1.0820792 -- Test loss 1.077245\n",
      "Epoch 52: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 53: -- Training loss 1.0767566 -- Validation loss:1.0815668 -- Test loss 1.0767009\n",
      "Epoch 53: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 54: -- Training loss 1.0760791 -- Validation loss:1.0810301 -- Test loss 1.0761371\n",
      "Epoch 54: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Test acc  0.36\n",
      "Epoch 55: -- Training loss 1.0753934 -- Validation loss:1.0804667 -- Test loss 1.075551\n",
      "Epoch 55: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 56: -- Training loss 1.0746973 -- Validation loss:1.0798751 -- Test loss 1.0749412\n",
      "Epoch 56: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 57: -- Training loss 1.0739881 -- Validation loss:1.079254 -- Test loss 1.0743047\n",
      "Epoch 57: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 58: -- Training loss 1.0732635 -- Validation loss:1.0786017 -- Test loss 1.0736407\n",
      "Epoch 58: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 59: -- Training loss 1.0725213 -- Validation loss:1.0779177 -- Test loss 1.0729475\n",
      "Epoch 59: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 60: -- Training loss 1.0717599 -- Validation loss:1.0772002 -- Test loss 1.0722238\n",
      "Epoch 60: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 61: -- Training loss 1.0709773 -- Validation loss:1.0764481 -- Test loss 1.0714679\n",
      "Epoch 61: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 62: -- Training loss 1.0701715 -- Validation loss:1.0756612 -- Test loss 1.0706791\n",
      "Epoch 62: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 63: -- Training loss 1.069341 -- Validation loss:1.0748378 -- Test loss 1.0698558\n",
      "Epoch 63: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 64: -- Training loss 1.0684842 -- Validation loss:1.0739776 -- Test loss 1.0689971\n",
      "Epoch 64: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 65: -- Training loss 1.0675995 -- Validation loss:1.0730795 -- Test loss 1.0681018\n",
      "Epoch 65: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 66: -- Training loss 1.0666853 -- Validation loss:1.072142 -- Test loss 1.0671688\n",
      "Epoch 66: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 67: -- Training loss 1.0657405 -- Validation loss:1.0711652 -- Test loss 1.066197\n",
      "Epoch 67: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 68: -- Training loss 1.0647628 -- Validation loss:1.0701474 -- Test loss 1.0651851\n",
      "Epoch 68: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 69: -- Training loss 1.0637512 -- Validation loss:1.0690879 -- Test loss 1.064132\n",
      "Epoch 69: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 70: -- Training loss 1.0627041 -- Validation loss:1.0679859 -- Test loss 1.0630372\n",
      "Epoch 70: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 71: -- Training loss 1.0616201 -- Validation loss:1.06684 -- Test loss 1.0618984\n",
      "Epoch 71: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 72: -- Training loss 1.0604978 -- Validation loss:1.0656494 -- Test loss 1.0607152\n",
      "Epoch 72: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 73: -- Training loss 1.0593352 -- Validation loss:1.0644127 -- Test loss 1.0594863\n",
      "Epoch 73: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 74: -- Training loss 1.0581311 -- Validation loss:1.0631291 -- Test loss 1.0582099\n",
      "Epoch 74: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 75: -- Training loss 1.0568837 -- Validation loss:1.0617973 -- Test loss 1.0568851\n",
      "Epoch 75: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 76: -- Training loss 1.055592 -- Validation loss:1.060416 -- Test loss 1.055511\n",
      "Epoch 76: -- Training acc  0.36619718309859156 -- Validation acc: 0.375 -- Test acc  0.36\n",
      "Epoch 77: -- Training loss 1.0542539 -- Validation loss:1.0589838 -- Test loss 1.0540853\n",
      "Epoch 77: -- Training acc  0.38028169014084506 -- Validation acc: 0.375 -- Test acc  0.36\n",
      "Epoch 78: -- Training loss 1.0528679 -- Validation loss:1.0574998 -- Test loss 1.0526073\n",
      "Epoch 78: -- Training acc  0.39436619718309857 -- Validation acc: 0.375 -- Test acc  0.4\n",
      "Epoch 79: -- Training loss 1.0514327 -- Validation loss:1.0559627 -- Test loss 1.0510755\n",
      "Epoch 79: -- Training acc  0.4084507042253521 -- Validation acc: 0.4166666666666667 -- Test acc  0.44\n",
      "Epoch 80: -- Training loss 1.0499465 -- Validation loss:1.0543709 -- Test loss 1.0494884\n",
      "Epoch 80: -- Training acc  0.4507042253521127 -- Validation acc: 0.4166666666666667 -- Test acc  0.44\n",
      "Epoch 81: -- Training loss 1.0484079 -- Validation loss:1.0527233 -- Test loss 1.0478446\n",
      "Epoch 81: -- Training acc  0.5211267605633803 -- Validation acc: 0.5416666666666666 -- Test acc  0.6\n",
      "Epoch 82: -- Training loss 1.0468153 -- Validation loss:1.0510188 -- Test loss 1.0461429\n",
      "Epoch 82: -- Training acc  0.5774647887323944 -- Validation acc: 0.5416666666666666 -- Test acc  0.64\n",
      "Epoch 83: -- Training loss 1.0451672 -- Validation loss:1.0492557 -- Test loss 1.0443815\n",
      "Epoch 83: -- Training acc  0.6338028169014085 -- Validation acc: 0.5416666666666666 -- Test acc  0.68\n",
      "Epoch 84: -- Training loss 1.0434623 -- Validation loss:1.0474328 -- Test loss 1.0425596\n",
      "Epoch 84: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.68\n",
      "Epoch 85: -- Training loss 1.0416989 -- Validation loss:1.0455495 -- Test loss 1.0406753\n",
      "Epoch 85: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 86: -- Training loss 1.0398756 -- Validation loss:1.0436035 -- Test loss 1.0387274\n",
      "Epoch 86: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 87: -- Training loss 1.0379914 -- Validation loss:1.0415944 -- Test loss 1.0367149\n",
      "Epoch 87: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 88: -- Training loss 1.0360445 -- Validation loss:1.0395211 -- Test loss 1.0346363\n",
      "Epoch 88: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 89: -- Training loss 1.0340341 -- Validation loss:1.0373819 -- Test loss 1.0324903\n",
      "Epoch 89: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 90: -- Training loss 1.0319586 -- Validation loss:1.0351762 -- Test loss 1.0302761\n",
      "Epoch 90: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 91: -- Training loss 1.0298171 -- Validation loss:1.0329031 -- Test loss 1.0279921\n",
      "Epoch 91: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 92: -- Training loss 1.0276084 -- Validation loss:1.0305614 -- Test loss 1.0256377\n",
      "Epoch 92: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 93: -- Training loss 1.0253315 -- Validation loss:1.0281506 -- Test loss 1.023212\n",
      "Epoch 93: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 94: -- Training loss 1.0229852 -- Validation loss:1.0256693 -- Test loss 1.0207134\n",
      "Epoch 94: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 95: -- Training loss 1.0205688 -- Validation loss:1.0231177 -- Test loss 1.018142\n",
      "Epoch 95: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 96: -- Training loss 1.0180811 -- Validation loss:1.0204941 -- Test loss 1.0154965\n",
      "Epoch 96: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 97: -- Training loss 1.0155214 -- Validation loss:1.0177982 -- Test loss 1.0127758\n",
      "Epoch 97: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 98: -- Training loss 1.0128887 -- Validation loss:1.0150293 -- Test loss 1.0099801\n",
      "Epoch 98: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 99: -- Training loss 1.010182 -- Validation loss:1.0121869 -- Test loss 1.0071075\n",
      "Epoch 99: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 100: -- Training loss 1.0074006 -- Validation loss:1.0092705 -- Test loss 1.0041584\n",
      "Epoch 100: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 101: -- Training loss 1.0045433 -- Validation loss:1.0062789 -- Test loss 1.0011315\n",
      "Epoch 101: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 102: -- Training loss 1.0016094 -- Validation loss:1.0032119 -- Test loss 0.9980267\n",
      "Epoch 102: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 103: -- Training loss 0.9985981 -- Validation loss:1.0000689 -- Test loss 0.99484307\n",
      "Epoch 103: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 104: -- Training loss 0.995508 -- Validation loss:0.99684876 -- Test loss 0.9915801\n",
      "Epoch 104: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 105: -- Training loss 0.9923385 -- Validation loss:0.9935513 -- Test loss 0.9882373\n",
      "Epoch 105: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 106: -- Training loss 0.9890885 -- Validation loss:0.990176 -- Test loss 0.9848142\n",
      "Epoch 106: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 107: -- Training loss 0.9857573 -- Validation loss:0.9867215 -- Test loss 0.98131025\n",
      "Epoch 107: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 108: -- Training loss 0.9823441 -- Validation loss:0.9831876 -- Test loss 0.9777252\n",
      "Epoch 108: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 109: -- Training loss 0.9788482 -- Validation loss:0.97957397 -- Test loss 0.97405845\n",
      "Epoch 109: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 110: -- Training loss 0.97526896 -- Validation loss:0.97587997 -- Test loss 0.97031045\n",
      "Epoch 110: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 111: -- Training loss 0.97160596 -- Validation loss:0.972105 -- Test loss 0.9664805\n",
      "Epoch 111: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 112: -- Training loss 0.9678591 -- Validation loss:0.96824884 -- Test loss 0.96256864\n",
      "Epoch 112: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 113: -- Training loss 0.96402806 -- Validation loss:0.9643114 -- Test loss 0.9585756\n",
      "Epoch 113: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 114: -- Training loss 0.960113 -- Validation loss:0.96029264 -- Test loss 0.9545015\n",
      "Epoch 114: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 115: -- Training loss 0.95611477 -- Validation loss:0.9561929 -- Test loss 0.95034677\n",
      "Epoch 115: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 116: -- Training loss 0.9520336 -- Validation loss:0.95201236 -- Test loss 0.9461126\n",
      "Epoch 116: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 117: -- Training loss 0.9478709 -- Validation loss:0.94775134 -- Test loss 0.9417994\n",
      "Epoch 117: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 118: -- Training loss 0.9436277 -- Validation loss:0.94341093 -- Test loss 0.93740875\n",
      "Epoch 118: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 119: -- Training loss 0.93930537 -- Validation loss:0.938992 -- Test loss 0.9329418\n",
      "Epoch 119: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 120: -- Training loss 0.9349059 -- Validation loss:0.9344957 -- Test loss 0.9284002\n",
      "Epoch 120: -- Training acc  0.647887323943662 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 121: -- Training loss 0.9304312 -- Validation loss:0.92992306 -- Test loss 0.9237859\n",
      "Epoch 121: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 122: -- Training loss 0.92588365 -- Validation loss:0.9252761 -- Test loss 0.9191006\n",
      "Epoch 122: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 123: -- Training loss 0.9212655 -- Validation loss:0.9205561 -- Test loss 0.91434646\n",
      "Epoch 123: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 124: -- Training loss 0.9165798 -- Validation loss:0.9157651 -- Test loss 0.9095258\n",
      "Epoch 124: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 125: -- Training loss 0.9118291 -- Validation loss:0.91090566 -- Test loss 0.9046411\n",
      "Epoch 125: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 126: -- Training loss 0.9070167 -- Validation loss:0.90597945 -- Test loss 0.89969504\n",
      "Epoch 126: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 127: -- Training loss 0.9021457 -- Validation loss:0.90098953 -- Test loss 0.89469033\n",
      "Epoch 127: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 128: -- Training loss 0.89721966 -- Validation loss:0.8959386 -- Test loss 0.8896299\n",
      "Epoch 128: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 129: -- Training loss 0.892242 -- Validation loss:0.8908291 -- Test loss 0.8845173\n",
      "Epoch 129: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 130: -- Training loss 0.8872165 -- Validation loss:0.88566476 -- Test loss 0.8793558\n",
      "Epoch 130: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 131: -- Training loss 0.882147 -- Validation loss:0.8804488 -- Test loss 0.8741486\n",
      "Epoch 131: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 132: -- Training loss 0.87703764 -- Validation loss:0.8751847 -- Test loss 0.8689\n",
      "Epoch 132: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 133: -- Training loss 0.87189245 -- Validation loss:0.86987656 -- Test loss 0.86361384\n",
      "Epoch 133: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 134: -- Training loss 0.86671585 -- Validation loss:0.8645286 -- Test loss 0.85829425\n",
      "Epoch 134: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 135: -- Training loss 0.86151236 -- Validation loss:0.85914475 -- Test loss 0.85294586\n",
      "Epoch 135: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 136: -- Training loss 0.8562864 -- Validation loss:0.85373 -- Test loss 0.84757316\n",
      "Epoch 136: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 137: -- Training loss 0.85104287 -- Validation loss:0.8482892 -- Test loss 0.84218127\n",
      "Epoch 137: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 138: -- Training loss 0.8457863 -- Validation loss:0.84282666 -- Test loss 0.83677465\n",
      "Epoch 138: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 139: -- Training loss 0.84052193 -- Validation loss:0.83734864 -- Test loss 0.83135897\n",
      "Epoch 139: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 140: -- Training loss 0.83525485 -- Validation loss:0.83185977 -- Test loss 0.8259392\n",
      "Epoch 140: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 141: -- Training loss 0.8299898 -- Validation loss:0.82636553 -- Test loss 0.8205209\n",
      "Epoch 141: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 142: -- Training loss 0.8247322 -- Validation loss:0.8208716 -- Test loss 0.8151093\n",
      "Epoch 142: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 143: -- Training loss 0.8194869 -- Validation loss:0.8153836 -- Test loss 0.80971026\n",
      "Epoch 143: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 144: -- Training loss 0.8142593 -- Validation loss:0.809907 -- Test loss 0.80432856\n",
      "Epoch 144: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 145: -- Training loss 0.8090542 -- Validation loss:0.80444735 -- Test loss 0.79897016\n",
      "Epoch 145: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 146: -- Training loss 0.8038767 -- Validation loss:0.7990105 -- Test loss 0.79364014\n",
      "Epoch 146: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 147: -- Training loss 0.7987317 -- Validation loss:0.7936016 -- Test loss 0.78834367\n",
      "Epoch 147: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 148: -- Training loss 0.79362375 -- Validation loss:0.7882258 -- Test loss 0.78308576\n",
      "Epoch 148: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 149: -- Training loss 0.78855777 -- Validation loss:0.7828886 -- Test loss 0.7778713\n",
      "Epoch 149: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 150: -- Training loss 0.7835378 -- Validation loss:0.77759457 -- Test loss 0.7727047\n",
      "Epoch 150: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 151: -- Training loss 0.7785681 -- Validation loss:0.77234846 -- Test loss 0.7675904\n",
      "Epoch 151: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 152: -- Training loss 0.7736525 -- Validation loss:0.76715475 -- Test loss 0.7625325\n",
      "Epoch 152: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 153: -- Training loss 0.7687947 -- Validation loss:0.7620174 -- Test loss 0.75753456\n",
      "Epoch 153: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 154: -- Training loss 0.76399845 -- Validation loss:0.7569404 -- Test loss 0.7526\n",
      "Epoch 154: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 155: -- Training loss 0.7592661 -- Validation loss:0.75192714 -- Test loss 0.74773216\n",
      "Epoch 155: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 156: -- Training loss 0.7546008 -- Validation loss:0.74698085 -- Test loss 0.7429336\n",
      "Epoch 156: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 157: -- Training loss 0.75000507 -- Validation loss:0.7421043 -- Test loss 0.7382071\n",
      "Epoch 157: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 158: -- Training loss 0.74548084 -- Validation loss:0.7373002 -- Test loss 0.7335546\n",
      "Epoch 158: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 159: -- Training loss 0.74103 -- Validation loss:0.7325706 -- Test loss 0.7289779\n",
      "Epoch 159: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 160: -- Training loss 0.7366543 -- Validation loss:0.7279176 -- Test loss 0.72447854\n",
      "Epoch 160: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 161: -- Training loss 0.73235494 -- Validation loss:0.7233426 -- Test loss 0.7200577"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 161: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 162: -- Training loss 0.7281326 -- Validation loss:0.71884686 -- Test loss 0.7157167\n",
      "Epoch 162: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 163: -- Training loss 0.72398823 -- Validation loss:0.71443194 -- Test loss 0.711456\n",
      "Epoch 163: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 164: -- Training loss 0.7199225 -- Validation loss:0.71009785 -- Test loss 0.7072759\n",
      "Epoch 164: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 165: -- Training loss 0.7159353 -- Validation loss:0.70584565 -- Test loss 0.70317703\n",
      "Epoch 165: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 166: -- Training loss 0.71202666 -- Validation loss:0.7016757 -- Test loss 0.6991594\n",
      "Epoch 166: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 167: -- Training loss 0.7081967 -- Validation loss:0.6975877 -- Test loss 0.6952227\n",
      "Epoch 167: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 168: -- Training loss 0.70444477 -- Validation loss:0.6935818 -- Test loss 0.69136643\n",
      "Epoch 168: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 169: -- Training loss 0.70077056 -- Validation loss:0.68965787 -- Test loss 0.6875905\n",
      "Epoch 169: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 170: -- Training loss 0.69717336 -- Validation loss:0.6858151 -- Test loss 0.6838943\n",
      "Epoch 170: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 171: -- Training loss 0.6936522 -- Validation loss:0.68205315 -- Test loss 0.6802769\n",
      "Epoch 171: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 172: -- Training loss 0.6902064 -- Validation loss:0.67837137 -- Test loss 0.6767376\n",
      "Epoch 172: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 173: -- Training loss 0.6868349 -- Validation loss:0.67476887 -- Test loss 0.6732753\n",
      "Epoch 173: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 174: -- Training loss 0.68353665 -- Validation loss:0.67124444 -- Test loss 0.66988915\n",
      "Epoch 174: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 175: -- Training loss 0.6803104 -- Validation loss:0.66779757 -- Test loss 0.66657794\n",
      "Epoch 175: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 176: -- Training loss 0.67715496 -- Validation loss:0.66442674 -- Test loss 0.6633405\n",
      "Epoch 176: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 177: -- Training loss 0.6740691 -- Validation loss:0.6611307 -- Test loss 0.6601756\n",
      "Epoch 177: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 178: -- Training loss 0.6710514 -- Validation loss:0.6579085 -- Test loss 0.6570821\n",
      "Epoch 178: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 179: -- Training loss 0.6681006 -- Validation loss:0.65475863 -- Test loss 0.6540583\n",
      "Epoch 179: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 180: -- Training loss 0.6652153 -- Validation loss:0.6516797 -- Test loss 0.65110314\n",
      "Epoch 180: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 181: -- Training loss 0.66239405 -- Validation loss:0.6486705 -- Test loss 0.64821506\n",
      "Epoch 181: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 182: -- Training loss 0.6596354 -- Validation loss:0.64572936 -- Test loss 0.6453928\n",
      "Epoch 182: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 183: -- Training loss 0.6569382 -- Validation loss:0.6428548 -- Test loss 0.6426346\n",
      "Epoch 183: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 184: -- Training loss 0.6543008 -- Validation loss:0.6400456 -- Test loss 0.6399392\n",
      "Epoch 184: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 185: -- Training loss 0.65172184 -- Validation loss:0.6373002 -- Test loss 0.6373052\n",
      "Epoch 185: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 186: -- Training loss 0.64919984 -- Validation loss:0.6346168 -- Test loss 0.634731\n",
      "Epoch 186: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 187: -- Training loss 0.6467336 -- Validation loss:0.6319942 -- Test loss 0.6322151\n",
      "Epoch 187: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 188: -- Training loss 0.64432156 -- Validation loss:0.62943083 -- Test loss 0.6297562\n",
      "Epoch 188: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 189: -- Training loss 0.64196223 -- Validation loss:0.6269251 -- Test loss 0.6273528\n",
      "Epoch 189: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 190: -- Training loss 0.63965464 -- Validation loss:0.6244757 -- Test loss 0.62500334\n",
      "Epoch 190: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 191: -- Training loss 0.6373971 -- Validation loss:0.6220811 -- Test loss 0.6227065\n",
      "Epoch 191: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 192: -- Training loss 0.63518864 -- Validation loss:0.61973983 -- Test loss 0.6204608\n",
      "Epoch 192: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 193: -- Training loss 0.6330276 -- Validation loss:0.6174504 -- Test loss 0.6182649\n",
      "Epoch 193: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 194: -- Training loss 0.63091296 -- Validation loss:0.61521155 -- Test loss 0.6161176\n",
      "Epoch 194: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 195: -- Training loss 0.6288435 -- Validation loss:0.61302173 -- Test loss 0.61401737\n",
      "Epoch 195: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 196: -- Training loss 0.62681776 -- Validation loss:0.6108797 -- Test loss 0.611963\n",
      "Epoch 196: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 197: -- Training loss 0.6248347 -- Validation loss:0.6087842 -- Test loss 0.60995317\n",
      "Epoch 197: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 198: -- Training loss 0.6228933 -- Validation loss:0.60673374 -- Test loss 0.6079866\n",
      "Epoch 198: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 199: -- Training loss 0.62099224 -- Validation loss:0.6047273 -- Test loss 0.60606223\n",
      "Epoch 199: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 200: -- Training loss 0.6191307 -- Validation loss:0.6027635 -- Test loss 0.6041787\n",
      "Epoch 200: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 201: -- Training loss 0.6173071 -- Validation loss:0.6008411 -- Test loss 0.60233504\n",
      "Epoch 201: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 202: -- Training loss 0.6155208 -- Validation loss:0.5989591 -- Test loss 0.6005299\n",
      "Epoch 202: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 203: -- Training loss 0.6137705 -- Validation loss:0.5971161 -- Test loss 0.59876245\n",
      "Epoch 203: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 204: -- Training loss 0.6120555 -- Validation loss:0.5953112 -- Test loss 0.59703124\n",
      "Epoch 204: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 205: -- Training loss 0.6103746 -- Validation loss:0.59354335 -- Test loss 0.5953356\n",
      "Epoch 205: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 206: -- Training loss 0.60872686 -- Validation loss:0.5918115 -- Test loss 0.5936746\n",
      "Epoch 206: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 207: -- Training loss 0.6071115 -- Validation loss:0.59011436 -- Test loss 0.5920468\n",
      "Epoch 207: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 208: -- Training loss 0.6055275 -- Validation loss:0.5884513 -- Test loss 0.5904517\n",
      "Epoch 208: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 209: -- Training loss 0.60397404 -- Validation loss:0.5868211 -- Test loss 0.58888817\n",
      "Epoch 209: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 210: -- Training loss 0.6024503 -- Validation loss:0.585223 -- Test loss 0.58735543\n",
      "Epoch 210: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 211: -- Training loss 0.6009554 -- Validation loss:0.5836561 -- Test loss 0.5858524\n",
      "Epoch 211: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 212: -- Training loss 0.59948856 -- Validation loss:0.58211946 -- Test loss 0.58437866\n",
      "Epoch 212: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 213: -- Training loss 0.5980489 -- Validation loss:0.5806123 -- Test loss 0.58293295\n",
      "Epoch 213: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 214: -- Training loss 0.5966359 -- Validation loss:0.57913357 -- Test loss 0.5815147\n",
      "Epoch 214: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 215: -- Training loss 0.5952486 -- Validation loss:0.577683 -- Test loss 0.58012325\n",
      "Epoch 215: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 216: -- Training loss 0.5938865 -- Validation loss:0.5762593 -- Test loss 0.5787577\n",
      "Epoch 216: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 217: -- Training loss 0.59254867 -- Validation loss:0.57486194 -- Test loss 0.5774174\n",
      "Epoch 217: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 218: -- Training loss 0.5912347 -- Validation loss:0.57349014 -- Test loss 0.5761016\n",
      "Epoch 218: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 219: -- Training loss 0.58994365 -- Validation loss:0.57214326 -- Test loss 0.5748098\n",
      "Epoch 219: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 220: -- Training loss 0.58867514 -- Validation loss:0.57082075 -- Test loss 0.57354105\n",
      "Epoch 220: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 221: -- Training loss 0.58742845 -- Validation loss:0.5695217 -- Test loss 0.5722949\n",
      "Epoch 221: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 222: -- Training loss 0.58620304 -- Validation loss:0.5682456 -- Test loss 0.57107073\n",
      "Epoch 222: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 223: -- Training loss 0.5849981 -- Validation loss:0.56699175 -- Test loss 0.56986797\n",
      "Epoch 223: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 224: -- Training loss 0.5838132 -- Validation loss:0.56575966 -- Test loss 0.5686862\n",
      "Epoch 224: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 225: -- Training loss 0.5826479 -- Validation loss:0.5645487 -- Test loss 0.56752443\n",
      "Epoch 225: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 226: -- Training loss 0.58150184 -- Validation loss:0.56335837 -- Test loss 0.56638247\n",
      "Epoch 226: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 227: -- Training loss 0.58037406 -- Validation loss:0.562188 -- Test loss 0.56525964\n",
      "Epoch 227: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 228: -- Training loss 0.5792642 -- Validation loss:0.56103724 -- Test loss 0.56415546\n",
      "Epoch 228: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 229: -- Training loss 0.578172 -- Validation loss:0.5599054 -- Test loss 0.5630695\n",
      "Epoch 229: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 230: -- Training loss 0.5770967 -- Validation loss:0.55879205 -- Test loss 0.5620012\n",
      "Epoch 230: -- Training acc  0.6619718309859155 -- Validation acc: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 231: -- Training loss 0.57603806 -- Validation loss:0.55769676 -- Test loss 0.5609501\n",
      "Epoch 231: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 232: -- Training loss 0.5749956 -- Validation loss:0.55661887 -- Test loss 0.5599158\n",
      "Epoch 232: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 233: -- Training loss 0.5739687 -- Validation loss:0.55555815 -- Test loss 0.55889773\n",
      "Epoch 233: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 234: -- Training loss 0.5729571 -- Validation loss:0.5545141 -- Test loss 0.5578956\n",
      "Epoch 234: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 235: -- Training loss 0.57196033 -- Validation loss:0.5534862 -- Test loss 0.5569089\n",
      "Epoch 235: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 236: -- Training loss 0.5709781 -- Validation loss:0.55247414 -- Test loss 0.55593735\n",
      "Epoch 236: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 237: -- Training loss 0.57000977 -- Validation loss:0.5514774 -- Test loss 0.5549804\n",
      "Epoch 237: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 238: -- Training loss 0.56905514 -- Validation loss:0.55049556 -- Test loss 0.5540376\n",
      "Epoch 238: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 239: -- Training loss 0.56811386 -- Validation loss:0.5495285 -- Test loss 0.55310893\n",
      "Epoch 239: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 240: -- Training loss 0.5671856 -- Validation loss:0.54857546 -- Test loss 0.5521936\n",
      "Epoch 240: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 241: -- Training loss 0.56626976 -- Validation loss:0.54763645 -- Test loss 0.5512914\n",
      "Epoch 241: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 242: -- Training loss 0.5653662 -- Validation loss:0.5467109 -- Test loss 0.5504021\n",
      "Epoch 242: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 243: -- Training loss 0.56447464 -- Validation loss:0.5457985 -- Test loss 0.5495253\n",
      "Epoch 243: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 244: -- Training loss 0.56359464 -- Validation loss:0.5448988 -- Test loss 0.54866076\n",
      "Epoch 244: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 245: -- Training loss 0.5627258 -- Validation loss:0.54401165 -- Test loss 0.54780793\n",
      "Epoch 245: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 246: -- Training loss 0.56186795 -- Validation loss:0.54313666 -- Test loss 0.5469666\n",
      "Epoch 246: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 247: -- Training loss 0.5610208 -- Validation loss:0.5422735 -- Test loss 0.54613656\n",
      "Epoch 247: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 248: -- Training loss 0.5601839 -- Validation loss:0.5414219 -- Test loss 0.54531735\n",
      "Epoch 248: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 249: -- Training loss 0.55935705 -- Validation loss:0.54058164 -- Test loss 0.5445089\n",
      "Epoch 249: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 250: -- Training loss 0.55854005 -- Validation loss:0.5397522 -- Test loss 0.5437106\n",
      "Epoch 250: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 251: -- Training loss 0.55773246 -- Validation loss:0.5389335 -- Test loss 0.5429224\n",
      "Epoch 251: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 252: -- Training loss 0.55693406 -- Validation loss:0.53812516 -- Test loss 0.5421441\n",
      "Epoch 252: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 253: -- Training loss 0.5561446 -- Validation loss:0.537327 -- Test loss 0.5413752\n",
      "Epoch 253: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 254: -- Training loss 0.5553638 -- Validation loss:0.5365387 -- Test loss 0.54061556\n",
      "Epoch 254: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 255: -- Training loss 0.55459136 -- Validation loss:0.5357599 -- Test loss 0.539865\n",
      "Epoch 255: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 256: -- Training loss 0.55382705 -- Validation loss:0.5349906 -- Test loss 0.5391232\n",
      "Epoch 256: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 257: -- Training loss 0.5530706 -- Validation loss:0.5342303 -- Test loss 0.5383897\n",
      "Epoch 257: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 258: -- Training loss 0.5523219 -- Validation loss:0.5334788 -- Test loss 0.53766453\n",
      "Epoch 258: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 259: -- Training loss 0.55158055 -- Validation loss:0.532736 -- Test loss 0.5369474\n",
      "Epoch 259: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 260: -- Training loss 0.5508464 -- Validation loss:0.53200144 -- Test loss 0.536238\n",
      "Epoch 260: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 261: -- Training loss 0.55011904 -- Validation loss:0.5312751 -- Test loss 0.53553617\n",
      "Epoch 261: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 262: -- Training loss 0.54939836 -- Validation loss:0.5305566 -- Test loss 0.5348417\n",
      "Epoch 262: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 263: -- Training loss 0.5486841 -- Validation loss:0.5298459 -- Test loss 0.5341543\n",
      "Epoch 263: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 264: -- Training loss 0.5479762 -- Validation loss:0.52914256 -- Test loss 0.5334737\n",
      "Epoch 264: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 265: -- Training loss 0.5472742 -- Validation loss:0.5284465 -- Test loss 0.5327998\n",
      "Epoch 265: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 266: -- Training loss 0.54657805 -- Validation loss:0.52775747 -- Test loss 0.5321323\n",
      "Epoch 266: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 267: -- Training loss 0.5458873 -- Validation loss:0.5270753 -- Test loss 0.5314711\n",
      "Epoch 267: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 268: -- Training loss 0.54520184 -- Validation loss:0.5263997 -- Test loss 0.5308158\n",
      "Epoch 268: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 269: -- Training loss 0.5445216 -- Validation loss:0.5257305 -- Test loss 0.5301664\n",
      "Epoch 269: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 270: -- Training loss 0.5438461 -- Validation loss:0.5250675 -- Test loss 0.5295224\n",
      "Epoch 270: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 271: -- Training loss 0.5431753 -- Validation loss:0.5244105 -- Test loss 0.528884\n",
      "Epoch 271: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 272: -- Training loss 0.54250884 -- Validation loss:0.5237593 -- Test loss 0.52825063\n",
      "Epoch 272: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 273: -- Training loss 0.5418467 -- Validation loss:0.52311367 -- Test loss 0.5276223\n",
      "Epoch 273: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 274: -- Training loss 0.5411885 -- Validation loss:0.5224735 -- Test loss 0.5269987\n",
      "Epoch 274: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 275: -- Training loss 0.540534 -- Validation loss:0.52183855 -- Test loss 0.5263797\n",
      "Epoch 275: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 276: -- Training loss 0.5398832 -- Validation loss:0.52120847 -- Test loss 0.5257651\n",
      "Epoch 276: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 277: -- Training loss 0.5392356 -- Validation loss:0.5205833 -- Test loss 0.52515453\n",
      "Epoch 277: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 278: -- Training loss 0.53859115 -- Validation loss:0.5199627 -- Test loss 0.52454805\n",
      "Epoch 278: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 279: -- Training loss 0.5379495 -- Validation loss:0.51934654 -- Test loss 0.5239453\n",
      "Epoch 279: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 280: -- Training loss 0.53731066 -- Validation loss:0.51873463 -- Test loss 0.523346\n",
      "Epoch 280: -- Training acc  0.6619718309859155 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 281: -- Training loss 0.5366742 -- Validation loss:0.5181268 -- Test loss 0.52275014\n",
      "Epoch 281: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 282: -- Training loss 0.5360399 -- Validation loss:0.5175228 -- Test loss 0.52215743\n",
      "Epoch 282: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 283: -- Training loss 0.53540766 -- Validation loss:0.51692235 -- Test loss 0.5215677\n",
      "Epoch 283: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 284: -- Training loss 0.5347772 -- Validation loss:0.5163255 -- Test loss 0.5209806\n",
      "Epoch 284: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 285: -- Training loss 0.5341482 -- Validation loss:0.51573193 -- Test loss 0.52039605\n",
      "Epoch 285: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 286: -- Training loss 0.53352064 -- Validation loss:0.5151415 -- Test loss 0.5198138\n",
      "Epoch 286: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 287: -- Training loss 0.5328939 -- Validation loss:0.5145537 -- Test loss 0.5192336\n",
      "Epoch 287: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 288: -- Training loss 0.53226817 -- Validation loss:0.51396877 -- Test loss 0.5186554\n",
      "Epoch 288: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 289: -- Training loss 0.5316427 -- Validation loss:0.51338625 -- Test loss 0.51807874\n",
      "Epoch 289: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 290: -- Training loss 0.5310178 -- Validation loss:0.51280606 -- Test loss 0.51750356\n",
      "Epoch 290: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 291: -- Training loss 0.53039294 -- Validation loss:0.51222795 -- Test loss 0.51692945\n",
      "Epoch 291: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 292: -- Training loss 0.5297679 -- Validation loss:0.5116517 -- Test loss 0.51635647\n",
      "Epoch 292: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 293: -- Training loss 0.5291424 -- Validation loss:0.51107717 -- Test loss 0.5157842\n",
      "Epoch 293: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 294: -- Training loss 0.5285161 -- Validation loss:0.51050407 -- Test loss 0.51521236\n",
      "Epoch 294: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 295: -- Training loss 0.5278889 -- Validation loss:0.5099321 -- Test loss 0.51464075\n",
      "Epoch 295: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 296: -- Training loss 0.5272605 -- Validation loss:0.50936145 -- Test loss 0.5140693\n",
      "Epoch 296: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 297: -- Training loss 0.52663034 -- Validation loss:0.5087914 -- Test loss 0.51349753\n",
      "Epoch 297: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 298: -- Training loss 0.52599853 -- Validation loss:0.50822204 -- Test loss 0.5129254\n",
      "Epoch 298: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 299: -- Training loss 0.5253644 -- Validation loss:0.50765294 -- Test loss 0.5123523\n",
      "Epoch 299: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 300: -- Training loss 0.52472806 -- Validation loss:0.5070842 -- Test loss 0.5117782\n",
      "Epoch 300: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 301: -- Training loss 0.5240888 -- Validation loss:0.5065153 -- Test loss 0.5112028\n",
      "Epoch 301: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 302: -- Training loss 0.52344656 -- Validation loss:0.50594604 -- Test loss 0.5106259\n",
      "Epoch 302: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 303: -- Training loss 0.522801 -- Validation loss:0.5053762 -- Test loss 0.5100471\n",
      "Epoch 303: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 304: -- Training loss 0.52215165 -- Validation loss:0.5048056 -- Test loss 0.509466\n",
      "Epoch 304: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 305: -- Training loss 0.5214983 -- Validation loss:0.5042339 -- Test loss 0.5088825\n",
      "Epoch 305: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 306: -- Training loss 0.52084064 -- Validation loss:0.50366104 -- Test loss 0.50829625\n",
      "Epoch 306: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 307: -- Training loss 0.52017814 -- Validation loss:0.50308645 -- Test loss 0.5077067\n",
      "Epoch 307: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 308: -- Training loss 0.5195106 -- Validation loss:0.50251013 -- Test loss 0.5071139\n",
      "Epoch 308: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 309: -- Training loss 0.5188376 -- Validation loss:0.5019316 -- Test loss 0.50651723\n",
      "Epoch 309: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 310: -- Training loss 0.5181588 -- Validation loss:0.5013508 -- Test loss 0.50591654\n",
      "Epoch 310: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 311: -- Training loss 0.51747376 -- Validation loss:0.50076735 -- Test loss 0.5053113\n",
      "Epoch 311: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 312: -- Training loss 0.5167821 -- Validation loss:0.500181 -- Test loss 0.5047013\n",
      "Epoch 312: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 313: -- Training loss 0.5160835 -- Validation loss:0.49959126 -- Test loss 0.50408614\n",
      "Epoch 313: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 314: -- Training loss 0.5153774 -- Validation loss:0.49899802 -- Test loss 0.5034654\n",
      "Epoch 314: -- Training acc  0.7464788732394366 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 315: -- Training loss 0.5146635 -- Validation loss:0.49840108 -- Test loss 0.5028387\n",
      "Epoch 315: -- Training acc  0.7464788732394366 -- Validation acc: 0.6666666666666666 -- Test acc  0.76\n",
      "Epoch 316: -- Training loss 0.5139414 -- Validation loss:0.4977999 -- Test loss 0.5022057\n",
      "Epoch 316: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.76\n",
      "Epoch 317: -- Training loss 0.5132108 -- Validation loss:0.49719438 -- Test loss 0.50156605\n",
      "Epoch 317: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.76\n",
      "Epoch 318: -- Training loss 0.51247084 -- Validation loss:0.49658394 -- Test loss 0.5009192\n",
      "Epoch 318: -- Training acc  0.7887323943661971 -- Validation acc: 0.7083333333333334 -- Test acc  0.76\n",
      "Epoch 319: -- Training loss 0.5117215 -- Validation loss:0.49596837 -- Test loss 0.50026494\n",
      "Epoch 319: -- Training acc  0.7887323943661971 -- Validation acc: 0.7083333333333334 -- Test acc  0.76\n",
      "Epoch 320: -- Training loss 0.51096207 -- Validation loss:0.49534747 -- Test loss 0.49960268\n",
      "Epoch 320: -- Training acc  0.7887323943661971 -- Validation acc: 0.7083333333333334 -- Test acc  0.76\n",
      "Epoch 321: -- Training loss 0.51019245 -- Validation loss:0.4947206 -- Test loss 0.49893212\n",
      "Epoch 321: -- Training acc  0.8028169014084507 -- Validation acc: 0.7083333333333334 -- Test acc  0.76\n",
      "Epoch 322: -- Training loss 0.50941175 -- Validation loss:0.49408782 -- Test loss 0.498253\n",
      "Epoch 322: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.76\n",
      "Epoch 323: -- Training loss 0.5086198 -- Validation loss:0.4934484 -- Test loss 0.49756455\n",
      "Epoch 323: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.76\n",
      "Epoch 324: -- Training loss 0.50781596 -- Validation loss:0.49280217 -- Test loss 0.49686658\n",
      "Epoch 324: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.76\n",
      "Epoch 325: -- Training loss 0.50699985 -- Validation loss:0.4921488 -- Test loss 0.4961586\n",
      "Epoch 325: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.76\n",
      "Epoch 326: -- Training loss 0.5061711 -- Validation loss:0.49148774 -- Test loss 0.49544024\n",
      "Epoch 326: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 327: -- Training loss 0.50532913 -- Validation loss:0.49081862 -- Test loss 0.49471116\n",
      "Epoch 327: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 328: -- Training loss 0.5044735 -- Validation loss:0.49014127 -- Test loss 0.49397078\n",
      "Epoch 328: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 329: -- Training loss 0.50360376 -- Validation loss:0.48945513 -- Test loss 0.49321887\n",
      "Epoch 329: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 330: -- Training loss 0.5027193 -- Validation loss:0.48875985 -- Test loss 0.49245495\n",
      "Epoch 330: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 331: -- Training loss 0.5018199 -- Validation loss:0.4880549 -- Test loss 0.49167854\n",
      "Epoch 331: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 332: -- Training loss 0.5009049 -- Validation loss:0.4873401 -- Test loss 0.4908894\n",
      "Epoch 332: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 333: -- Training loss 0.49997398 -- Validation loss:0.4866148 -- Test loss 0.49008724\n",
      "Epoch 333: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 334: -- Training loss 0.49902666 -- Validation loss:0.48587874 -- Test loss 0.4892716\n",
      "Epoch 334: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.88\n",
      "Epoch 335: -- Training loss 0.49806228 -- Validation loss:0.48513135 -- Test loss 0.48844206\n",
      "Epoch 335: -- Training acc  0.8169014084507042 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 336: -- Training loss 0.4970809 -- Validation loss:0.48437223 -- Test loss 0.48759857\n",
      "Epoch 336: -- Training acc  0.8169014084507042 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 337: -- Training loss 0.49608156 -- Validation loss:0.48360097 -- Test loss 0.48674053\n",
      "Epoch 337: -- Training acc  0.8169014084507042 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 338: -- Training loss 0.4950641 -- Validation loss:0.48281717 -- Test loss 0.4858678\n",
      "Epoch 338: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 339: -- Training loss 0.49402818 -- Validation loss:0.48202023 -- Test loss 0.4849803\n",
      "Epoch 339: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 340: -- Training loss 0.49297327 -- Validation loss:0.48120987 -- Test loss 0.48407733\n",
      "Epoch 340: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 341: -- Training loss 0.49189904 -- Validation loss:0.48038557 -- Test loss 0.48315904\n",
      "Epoch 341: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 342: -- Training loss 0.4908051 -- Validation loss:0.479547 -- Test loss 0.4822249\n",
      "Epoch 342: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 343: -- Training loss 0.48969102 -- Validation loss:0.47869352 -- Test loss 0.48127502\n",
      "Epoch 343: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 344: -- Training loss 0.48855665 -- Validation loss:0.47782493 -- Test loss 0.48030898\n",
      "Epoch 344: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 345: -- Training loss 0.48740172 -- Validation loss:0.47694054 -- Test loss 0.47932675\n",
      "Epoch 345: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 346: -- Training loss 0.48622566 -- Validation loss:0.47604033 -- Test loss 0.4783279\n",
      "Epoch 346: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 347: -- Training loss 0.48502845 -- Validation loss:0.4751236 -- Test loss 0.47731265\n",
      "Epoch 347: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 348: -- Training loss 0.48380974 -- Validation loss:0.4741902 -- Test loss 0.4762805\n",
      "Epoch 348: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 349: -- Training loss 0.4825692 -- Validation loss:0.47323963 -- Test loss 0.47523153\n",
      "Epoch 349: -- Training acc  0.8732394366197183 -- Validation acc: 0.8333333333333334 -- Test acc  0.88\n",
      "Epoch 350: -- Training loss 0.48130697 -- Validation loss:0.47227168 -- Test loss 0.47416547\n",
      "Epoch 350: -- Training acc  0.8873239436619719 -- Validation acc: 0.8333333333333334 -- Test acc  0.88\n",
      "Epoch 351: -- Training loss 0.4800225 -- Validation loss:0.47128597 -- Test loss 0.47308218\n",
      "Epoch 351: -- Training acc  0.8732394366197183 -- Validation acc: 0.8333333333333334 -- Test acc  0.88\n",
      "Epoch 352: -- Training loss 0.47871572 -- Validation loss:0.47028232 -- Test loss 0.4719815\n",
      "Epoch 352: -- Training acc  0.8732394366197183 -- Validation acc: 0.8333333333333334 -- Test acc  0.88\n",
      "Epoch 353: -- Training loss 0.47738662 -- Validation loss:0.46926054 -- Test loss 0.47086343\n",
      "Epoch 353: -- Training acc  0.8732394366197183 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 354: -- Training loss 0.476035 -- Validation loss:0.46822035 -- Test loss 0.46972764\n",
      "Epoch 354: -- Training acc  0.8732394366197183 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 355: -- Training loss 0.47466072 -- Validation loss:0.4671615 -- Test loss 0.46857408\n",
      "Epoch 355: -- Training acc  0.8732394366197183 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 356: -- Training loss 0.47326374 -- Validation loss:0.466084 -- Test loss 0.46740246\n",
      "Epoch 356: -- Training acc  0.8732394366197183 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 357: -- Training loss 0.47184405 -- Validation loss:0.46498764 -- Test loss 0.46621272\n",
      "Epoch 357: -- Training acc  0.8732394366197183 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 358: -- Training loss 0.47040161 -- Validation loss:0.46387228 -- Test loss 0.46500456\n",
      "Epoch 358: -- Training acc  0.8873239436619719 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 359: -- Training loss 0.46893626 -- Validation loss:0.46273807 -- Test loss 0.4637781\n",
      "Epoch 359: -- Training acc  0.8873239436619719 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 360: -- Training loss 0.46744812 -- Validation loss:0.46158472 -- Test loss 0.46253276\n",
      "Epoch 360: -- Training acc  0.8873239436619719 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 361: -- Training loss 0.4659371 -- Validation loss:0.46041214 -- Test loss 0.4612686\n",
      "Epoch 361: -- Training acc  0.9014084507042254 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 362: -- Training loss 0.46440324 -- Validation loss:0.45922062 -- Test loss 0.45998546\n",
      "Epoch 362: -- Training acc  0.9014084507042254 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 363: -- Training loss 0.46284646 -- Validation loss:0.45800993 -- Test loss 0.4586829\n",
      "Epoch 363: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 364: -- Training loss 0.46126696 -- Validation loss:0.45678 -- Test loss 0.45736107\n",
      "Epoch 364: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 365: -- Training loss 0.45966458 -- Validation loss:0.4555311 -- Test loss 0.45601964\n",
      "Epoch 365: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 366: -- Training loss 0.45803934 -- Validation loss:0.45426312 -- Test loss 0.45465833\n",
      "Epoch 366: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 367: -- Training loss 0.45639133 -- Validation loss:0.4529762 -- Test loss 0.45327708\n",
      "Epoch 367: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 368: -- Training loss 0.45472068 -- Validation loss:0.45167032 -- Test loss 0.45187578\n",
      "Epoch 368: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 369: -- Training loss 0.45302722 -- Validation loss:0.45034552 -- Test loss 0.45045415\n",
      "Epoch 369: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 370: -- Training loss 0.4513112 -- Validation loss:0.44900194 -- Test loss 0.44901216\n",
      "Epoch 370: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 371: -- Training loss 0.44957247 -- Validation loss:0.44763982 -- Test loss 0.44754964\n",
      "Epoch 371: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 372: -- Training loss 0.44781125 -- Validation loss:0.4462589 -- Test loss 0.4460665\n",
      "Epoch 372: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 373: -- Training loss 0.44602746 -- Validation loss:0.44485953 -- Test loss 0.4445625\n",
      "Epoch 373: -- Training acc  0.9154929577464789 -- Validation acc: 0.9166666666666666 -- Test acc  0.88\n",
      "Epoch 374: -- Training loss 0.44422135 -- Validation loss:0.44344184 -- Test loss 0.4430377\n",
      "Epoch 374: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 375: -- Training loss 0.4423929 -- Validation loss:0.44200596 -- Test loss 0.44149184\n",
      "Epoch 375: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 376: -- Training loss 0.44054207 -- Validation loss:0.440552 -- Test loss 0.4399251\n",
      "Epoch 376: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 377: -- Training loss 0.43866926 -- Validation loss:0.4390802 -- Test loss 0.4383371\n",
      "Epoch 377: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 378: -- Training loss 0.4367744 -- Validation loss:0.43759063 -- Test loss 0.4367279\n",
      "Epoch 378: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 379: -- Training loss 0.43485767 -- Validation loss:0.43608359 -- Test loss 0.4350976\n",
      "Epoch 379: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 380: -- Training loss 0.43291926 -- Validation loss:0.43455938 -- Test loss 0.43344596\n",
      "Epoch 380: -- Training acc  0.9295774647887324 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 381: -- Training loss 0.43095937 -- Validation loss:0.43301806 -- Test loss 0.43177292\n",
      "Epoch 381: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 382: -- Training loss 0.42897817 -- Validation loss:0.4314601 -- Test loss 0.43007877\n",
      "Epoch 382: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 383: -- Training loss 0.42697588 -- Validation loss:0.42988566 -- Test loss 0.42836308\n",
      "Epoch 383: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 384: -- Training loss 0.42495278 -- Validation loss:0.4282949 -- Test loss 0.42662618\n",
      "Epoch 384: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 385: -- Training loss 0.42290905 -- Validation loss:0.4266884 -- Test loss 0.42486802\n",
      "Epoch 385: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 386: -- Training loss 0.42084512 -- Validation loss:0.4250662 -- Test loss 0.42308873"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 386: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 387: -- Training loss 0.41876122 -- Validation loss:0.42342877 -- Test loss 0.42128822\n",
      "Epoch 387: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 388: -- Training loss 0.41665766 -- Validation loss:0.42177644 -- Test loss 0.41946688\n",
      "Epoch 388: -- Training acc  0.9436619718309859 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 389: -- Training loss 0.41453484 -- Validation loss:0.42010954 -- Test loss 0.41762483\n",
      "Epoch 389: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 390: -- Training loss 0.41239315 -- Validation loss:0.41842845 -- Test loss 0.41576225\n",
      "Epoch 390: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 391: -- Training loss 0.410233 -- Validation loss:0.4167334 -- Test loss 0.41387925\n",
      "Epoch 391: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 392: -- Training loss 0.4080548 -- Validation loss:0.41502485 -- Test loss 0.41197625\n",
      "Epoch 392: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 393: -- Training loss 0.40585902 -- Validation loss:0.41330305 -- Test loss 0.41005367\n",
      "Epoch 393: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 394: -- Training loss 0.40364617 -- Validation loss:0.41156855 -- Test loss 0.40811172\n",
      "Epoch 394: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 395: -- Training loss 0.4014167 -- Validation loss:0.40982166 -- Test loss 0.4061509\n",
      "Epoch 395: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 396: -- Training loss 0.39917114 -- Validation loss:0.40806267 -- Test loss 0.40417165\n",
      "Epoch 396: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 397: -- Training loss 0.3969101 -- Validation loss:0.40629205 -- Test loss 0.40217417\n",
      "Epoch 397: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 398: -- Training loss 0.394634 -- Validation loss:0.40451014 -- Test loss 0.4001594\n",
      "Epoch 398: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 399: -- Training loss 0.39234352 -- Validation loss:0.40271735 -- Test loss 0.39812747\n",
      "Epoch 399: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 400: -- Training loss 0.3900393 -- Validation loss:0.4009143 -- Test loss 0.39607906\n",
      "Epoch 400: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 401: -- Training loss 0.3877218 -- Validation loss:0.39910105 -- Test loss 0.39401466\n",
      "Epoch 401: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 402: -- Training loss 0.38539183 -- Validation loss:0.3972784 -- Test loss 0.3919349\n",
      "Epoch 402: -- Training acc  0.9577464788732394 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 403: -- Training loss 0.38304996 -- Validation loss:0.39544654 -- Test loss 0.38984025\n",
      "Epoch 403: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 404: -- Training loss 0.38069683 -- Validation loss:0.39360595 -- Test loss 0.3877312\n",
      "Epoch 404: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 405: -- Training loss 0.3783331 -- Validation loss:0.39175722 -- Test loss 0.38560852\n",
      "Epoch 405: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 406: -- Training loss 0.37595958 -- Validation loss:0.38990068 -- Test loss 0.3834727\n",
      "Epoch 406: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 407: -- Training loss 0.3735769 -- Validation loss:0.38803682 -- Test loss 0.38132432\n",
      "Epoch 407: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 408: -- Training loss 0.37118575 -- Validation loss:0.38616607 -- Test loss 0.37916404\n",
      "Epoch 408: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 409: -- Training loss 0.3687869 -- Validation loss:0.384289 -- Test loss 0.37699246\n",
      "Epoch 409: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 410: -- Training loss 0.36638102 -- Validation loss:0.382406 -- Test loss 0.3748102\n",
      "Epoch 410: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 411: -- Training loss 0.3639689 -- Validation loss:0.38051748 -- Test loss 0.37261784\n",
      "Epoch 411: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 412: -- Training loss 0.36155128 -- Validation loss:0.3786241 -- Test loss 0.37041613\n",
      "Epoch 412: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 413: -- Training loss 0.35912886 -- Validation loss:0.37672615 -- Test loss 0.36820576\n",
      "Epoch 413: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 414: -- Training loss 0.35670248 -- Validation loss:0.37482426 -- Test loss 0.36598748\n",
      "Epoch 414: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 415: -- Training loss 0.35427272 -- Validation loss:0.3729187 -- Test loss 0.3637618\n",
      "Epoch 415: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 416: -- Training loss 0.35184044 -- Validation loss:0.37101007 -- Test loss 0.36152953\n",
      "Epoch 416: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 417: -- Training loss 0.34940642 -- Validation loss:0.36909875 -- Test loss 0.35929143\n",
      "Epoch 417: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 418: -- Training loss 0.34697133 -- Validation loss:0.36718526 -- Test loss 0.3570482\n",
      "Epoch 418: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 419: -- Training loss 0.34453598 -- Validation loss:0.36527005 -- Test loss 0.3548006\n",
      "Epoch 419: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 420: -- Training loss 0.3421011 -- Validation loss:0.3633537 -- Test loss 0.35254917\n",
      "Epoch 420: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 421: -- Training loss 0.33966732 -- Validation loss:0.36143637 -- Test loss 0.3502948\n",
      "Epoch 421: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 422: -- Training loss 0.33723545 -- Validation loss:0.35951874 -- Test loss 0.34803814\n",
      "Epoch 422: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 423: -- Training loss 0.33480617 -- Validation loss:0.3576012 -- Test loss 0.34577987\n",
      "Epoch 423: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 424: -- Training loss 0.33238026 -- Validation loss:0.35568428 -- Test loss 0.34352058\n",
      "Epoch 424: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 425: -- Training loss 0.3299583 -- Validation loss:0.3537682 -- Test loss 0.34126103\n",
      "Epoch 425: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 426: -- Training loss 0.32754105 -- Validation loss:0.3518536 -- Test loss 0.33900192\n",
      "Epoch 426: -- Training acc  0.9577464788732394 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 427: -- Training loss 0.32512915 -- Validation loss:0.34994087 -- Test loss 0.33674377\n",
      "Epoch 427: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 428: -- Training loss 0.32272324 -- Validation loss:0.34803033 -- Test loss 0.33448738\n",
      "Epoch 428: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 429: -- Training loss 0.3203241 -- Validation loss:0.34612253 -- Test loss 0.33223325\n",
      "Epoch 429: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 430: -- Training loss 0.3179322 -- Validation loss:0.34421778 -- Test loss 0.32998198\n",
      "Epoch 430: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 431: -- Training loss 0.31554815 -- Validation loss:0.34231648 -- Test loss 0.3277343\n",
      "Epoch 431: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 432: -- Training loss 0.3131727 -- Validation loss:0.34041908 -- Test loss 0.32549077\n",
      "Epoch 432: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 433: -- Training loss 0.3108063 -- Validation loss:0.33852592 -- Test loss 0.323252\n",
      "Epoch 433: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 434: -- Training loss 0.30844954 -- Validation loss:0.33663738 -- Test loss 0.32101858\n",
      "Epoch 434: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 435: -- Training loss 0.30610302 -- Validation loss:0.33475375 -- Test loss 0.3187911\n",
      "Epoch 435: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 436: -- Training loss 0.30376723 -- Validation loss:0.33287546 -- Test loss 0.31657013\n",
      "Epoch 436: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 437: -- Training loss 0.30144268 -- Validation loss:0.33100274 -- Test loss 0.3143562\n",
      "Epoch 437: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 438: -- Training loss 0.2991299 -- Validation loss:0.32913604 -- Test loss 0.31214988\n",
      "Epoch 438: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 439: -- Training loss 0.29682925 -- Validation loss:0.32727566 -- Test loss 0.3099517\n",
      "Epoch 439: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 440: -- Training loss 0.2945413 -- Validation loss:0.32542175 -- Test loss 0.30776224\n",
      "Epoch 440: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 441: -- Training loss 0.2922665 -- Validation loss:0.32357475 -- Test loss 0.30558187\n",
      "Epoch 441: -- Training acc  0.9859154929577465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 442: -- Training loss 0.29000515 -- Validation loss:0.32173494 -- Test loss 0.30341104\n",
      "Epoch 442: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 443: -- Training loss 0.28775772 -- Validation loss:0.31990242 -- Test loss 0.30125022\n",
      "Epoch 443: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 444: -- Training loss 0.28552458 -- Validation loss:0.31807765 -- Test loss 0.29909995\n",
      "Epoch 444: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 445: -- Training loss 0.28330615 -- Validation loss:0.31626084 -- Test loss 0.29696047\n",
      "Epoch 445: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 446: -- Training loss 0.28110266 -- Validation loss:0.31445202 -- Test loss 0.29483226\n",
      "Epoch 446: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 447: -- Training loss 0.27891442 -- Validation loss:0.31265175 -- Test loss 0.29271573\n",
      "Epoch 447: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 448: -- Training loss 0.2767419 -- Validation loss:0.31085995 -- Test loss 0.29061124\n",
      "Epoch 448: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 449: -- Training loss 0.27458516 -- Validation loss:0.30907694 -- Test loss 0.28851897\n",
      "Epoch 449: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 450: -- Training loss 0.2724446 -- Validation loss:0.3073028 -- Test loss 0.28643945\n",
      "Epoch 450: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 451: -- Training loss 0.27032048 -- Validation loss:0.30553788 -- Test loss 0.28437284\n",
      "Epoch 451: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 452: -- Training loss 0.2682129 -- Validation loss:0.3037822 -- Test loss 0.28231964\n",
      "Epoch 452: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 453: -- Training loss 0.26612216 -- Validation loss:0.30203596 -- Test loss 0.28027993\n",
      "Epoch 453: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 454: -- Training loss 0.2640485 -- Validation loss:0.30029935 -- Test loss 0.27825403\n",
      "Epoch 454: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 455: -- Training loss 0.26199195 -- Validation loss:0.2985723 -- Test loss 0.27624226\n",
      "Epoch 455: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 456: -- Training loss 0.2599528 -- Validation loss:0.29685512 -- Test loss 0.27424482\n",
      "Epoch 456: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 457: -- Training loss 0.2579311 -- Validation loss:0.29514793 -- Test loss 0.27226186\n",
      "Epoch 457: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 458: -- Training loss 0.2559271 -- Validation loss:0.29345074 -- Test loss 0.27029368\n",
      "Epoch 458: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 459: -- Training loss 0.25394076 -- Validation loss:0.2917637 -- Test loss 0.26834035\n",
      "Epoch 459: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 460: -- Training loss 0.2519723 -- Validation loss:0.29008678 -- Test loss 0.2664021\n",
      "Epoch 460: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 461: -- Training loss 0.25002167 -- Validation loss:0.2884202 -- Test loss 0.26447892\n",
      "Epoch 461: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 462: -- Training loss 0.248089 -- Validation loss:0.28676397 -- Test loss 0.26257116\n",
      "Epoch 462: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 463: -- Training loss 0.24617434 -- Validation loss:0.2851182 -- Test loss 0.26067886\n",
      "Epoch 463: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 464: -- Training loss 0.24427779 -- Validation loss:0.28348276 -- Test loss 0.25880203\n",
      "Epoch 464: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 465: -- Training loss 0.24239929 -- Validation loss:0.28185782 -- Test loss 0.2569408\n",
      "Epoch 465: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 466: -- Training loss 0.24053894 -- Validation loss:0.28024346 -- Test loss 0.2550952\n",
      "Epoch 466: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 467: -- Training loss 0.23869671 -- Validation loss:0.27863967 -- Test loss 0.25326547\n",
      "Epoch 467: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 468: -- Training loss 0.23687246 -- Validation loss:0.2770464 -- Test loss 0.25145155\n",
      "Epoch 468: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 469: -- Training loss 0.2350664 -- Validation loss:0.2754638 -- Test loss 0.24965343\n",
      "Epoch 469: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 470: -- Training loss 0.23327833 -- Validation loss:0.27389178 -- Test loss 0.2478712\n",
      "Epoch 470: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 471: -- Training loss 0.23150828 -- Validation loss:0.27233034 -- Test loss 0.24610485\n",
      "Epoch 471: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 472: -- Training loss 0.2297562 -- Validation loss:0.2707796 -- Test loss 0.24435437\n",
      "Epoch 472: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 473: -- Training loss 0.22802208 -- Validation loss:0.26923946 -- Test loss 0.24261981\n",
      "Epoch 473: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 474: -- Training loss 0.22630575 -- Validation loss:0.26770997 -- Test loss 0.24090111\n",
      "Epoch 474: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 475: -- Training loss 0.2246073 -- Validation loss:0.2661911 -- Test loss 0.23919827\n",
      "Epoch 475: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 476: -- Training loss 0.22292645 -- Validation loss:0.26468274 -- Test loss 0.23751125\n",
      "Epoch 476: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 477: -- Training loss 0.22126327 -- Validation loss:0.26318502 -- Test loss 0.23583998\n",
      "Epoch 477: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 478: -- Training loss 0.21961756 -- Validation loss:0.26169792 -- Test loss 0.23418444\n",
      "Epoch 478: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 479: -- Training loss 0.2179893 -- Validation loss:0.26022124 -- Test loss 0.23254448\n",
      "Epoch 479: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 480: -- Training loss 0.21637835 -- Validation loss:0.25875512 -- Test loss 0.2309202\n",
      "Epoch 480: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 481: -- Training loss 0.21478459 -- Validation loss:0.25729945 -- Test loss 0.2293114\n",
      "Epoch 481: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 482: -- Training loss 0.21320798 -- Validation loss:0.25585434 -- Test loss 0.227718\n",
      "Epoch 482: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 483: -- Training loss 0.2116483 -- Validation loss:0.25441962 -- Test loss 0.22613998\n",
      "Epoch 483: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 484: -- Training loss 0.21010548 -- Validation loss:0.25299534 -- Test loss 0.22457723\n",
      "Epoch 484: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 485: -- Training loss 0.20857935 -- Validation loss:0.2515814 -- Test loss 0.22302966\n",
      "Epoch 485: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 486: -- Training loss 0.20706981 -- Validation loss:0.2501778 -- Test loss 0.22149707\n",
      "Epoch 486: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 487: -- Training loss 0.20557673 -- Validation loss:0.24878447 -- Test loss 0.21997954\n",
      "Epoch 487: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 488: -- Training loss 0.20409998 -- Validation loss:0.24740143 -- Test loss 0.21847676\n",
      "Epoch 488: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 489: -- Training loss 0.20263939 -- Validation loss:0.24602859 -- Test loss 0.21698871\n",
      "Epoch 489: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 490: -- Training loss 0.20119484 -- Validation loss:0.24466598 -- Test loss 0.21551533\n",
      "Epoch 490: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 491: -- Training loss 0.19976613 -- Validation loss:0.24331343 -- Test loss 0.21405643\n",
      "Epoch 491: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 492: -- Training loss 0.19835319 -- Validation loss:0.24197106 -- Test loss 0.21261182\n",
      "Epoch 492: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 493: -- Training loss 0.19695584 -- Validation loss:0.24063875 -- Test loss 0.21118155\n",
      "Epoch 493: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 494: -- Training loss 0.1955739 -- Validation loss:0.23931646 -- Test loss 0.20976529\n",
      "Epoch 494: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 495: -- Training loss 0.19420722 -- Validation loss:0.23800407 -- Test loss 0.20836306\n",
      "Epoch 495: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 496: -- Training loss 0.19285569 -- Validation loss:0.23670174 -- Test loss 0.20697471\n",
      "Epoch 496: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.96\n",
      "Epoch 497: -- Training loss 0.19151913 -- Validation loss:0.23540924 -- Test loss 0.20559998\n",
      "Epoch 497: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Test acc  0.96\n",
      "Epoch 498: -- Training loss 0.19019733 -- Validation loss:0.23412663 -- Test loss 0.20423888\n",
      "Epoch 498: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 499: -- Training loss 0.18889022 -- Validation loss:0.23285384 -- Test loss 0.2028911\n",
      "Epoch 499: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 500: -- Training loss 0.1875976 -- Validation loss:0.23159085 -- Test loss 0.20155667\n",
      "Epoch 500: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 501: -- Training loss 0.1863193 -- Validation loss:0.23033749 -- Test loss 0.2002353\n",
      "Epoch 501: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 502: -- Training loss 0.18505518 -- Validation loss:0.22909385 -- Test loss 0.198927\n",
      "Epoch 502: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 503: -- Training loss 0.18380511 -- Validation loss:0.22785993 -- Test loss 0.19763145\n",
      "Epoch 503: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 504: -- Training loss 0.18256885 -- Validation loss:0.22663552 -- Test loss 0.19634873\n",
      "Epoch 504: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 505: -- Training loss 0.18134631 -- Validation loss:0.22542082 -- Test loss 0.19507849\n",
      "Epoch 505: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 506: -- Training loss 0.1801373 -- Validation loss:0.2242155 -- Test loss 0.19382067\n",
      "Epoch 506: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 507: -- Training loss 0.17894173 -- Validation loss:0.22301973 -- Test loss 0.19257517\n",
      "Epoch 507: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 508: -- Training loss 0.1777593 -- Validation loss:0.22183341 -- Test loss 0.19134173\n",
      "Epoch 508: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 509: -- Training loss 0.17659 -- Validation loss:0.22065647 -- Test loss 0.19012031\n",
      "Epoch 509: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 510: -- Training loss 0.1754336 -- Validation loss:0.21948887 -- Test loss 0.18891075\n",
      "Epoch 510: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 511: -- Training loss 0.17428996 -- Validation loss:0.21833067 -- Test loss 0.18771286\n",
      "Epoch 511: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 512: -- Training loss 0.17315891 -- Validation loss:0.21718173 -- Test loss 0.1865265\n",
      "Epoch 512: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 513: -- Training loss 0.17204034 -- Validation loss:0.21604198 -- Test loss 0.1853516\n",
      "Epoch 513: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 514: -- Training loss 0.17093407 -- Validation loss:0.21491145 -- Test loss 0.18418789\n",
      "Epoch 514: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 515: -- Training loss 0.1698399 -- Validation loss:0.21379007 -- Test loss 0.18303536\n",
      "Epoch 515: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 516: -- Training loss 0.16875774 -- Validation loss:0.21267784 -- Test loss 0.18189383\n",
      "Epoch 516: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 517: -- Training loss 0.1676874 -- Validation loss:0.21157467 -- Test loss 0.18076311\n",
      "Epoch 517: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 518: -- Training loss 0.16662878 -- Validation loss:0.21048059 -- Test loss 0.17964308\n",
      "Epoch 518: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 519: -- Training loss 0.16558169 -- Validation loss:0.20939551 -- Test loss 0.17853367\n",
      "Epoch 519: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.96\n",
      "Epoch 520: -- Training loss 0.16454601 -- Validation loss:0.20831932 -- Test loss 0.17743473\n",
      "Epoch 520: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 521: -- Training loss 0.16352156 -- Validation loss:0.20725209 -- Test loss 0.17634603\n",
      "Epoch 521: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 522: -- Training loss 0.16250823 -- Validation loss:0.20619375 -- Test loss 0.17526758\n",
      "Epoch 522: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 523: -- Training loss 0.16150588 -- Validation loss:0.20514424 -- Test loss 0.17419916\n",
      "Epoch 523: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 524: -- Training loss 0.16051435 -- Validation loss:0.20410354 -- Test loss 0.17314062\n",
      "Epoch 524: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 525: -- Training loss 0.1595335 -- Validation loss:0.20307164 -- Test loss 0.17209198\n",
      "Epoch 525: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 526: -- Training loss 0.15856318 -- Validation loss:0.20204848 -- Test loss 0.17105287\n",
      "Epoch 526: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 527: -- Training loss 0.15760328 -- Validation loss:0.20103396 -- Test loss 0.17002344\n",
      "Epoch 527: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 528: -- Training loss 0.15665364 -- Validation loss:0.20002808 -- Test loss 0.16900335\n",
      "Epoch 528: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 529: -- Training loss 0.15571417 -- Validation loss:0.19903083 -- Test loss 0.1679926\n",
      "Epoch 529: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 530"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": -- Training loss 0.15478466 -- Validation loss:0.19804227 -- Test loss 0.16699108\n",
      "Epoch 530: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 531: -- Training loss 0.15386507 -- Validation loss:0.19706209 -- Test loss 0.16599858\n",
      "Epoch 531: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 532: -- Training loss 0.15295517 -- Validation loss:0.19609046 -- Test loss 0.16501503\n",
      "Epoch 532: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 533: -- Training loss 0.15205494 -- Validation loss:0.19512726 -- Test loss 0.16404036\n",
      "Epoch 533: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 534: -- Training loss 0.15116413 -- Validation loss:0.19417252 -- Test loss 0.1630744\n",
      "Epoch 534: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 535: -- Training loss 0.15028273 -- Validation loss:0.19322614 -- Test loss 0.1621171\n",
      "Epoch 535: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 536: -- Training loss 0.14941053 -- Validation loss:0.19228806 -- Test loss 0.16116825\n",
      "Epoch 536: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 537: -- Training loss 0.14854744 -- Validation loss:0.19135828 -- Test loss 0.16022792\n",
      "Epoch 537: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 538: -- Training loss 0.14769338 -- Validation loss:0.19043684 -- Test loss 0.15929586\n",
      "Epoch 538: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 539: -- Training loss 0.14684814 -- Validation loss:0.18952353 -- Test loss 0.15837197\n",
      "Epoch 539: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 540: -- Training loss 0.14601168 -- Validation loss:0.18861847 -- Test loss 0.15745625\n",
      "Epoch 540: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 541: -- Training loss 0.14518383 -- Validation loss:0.18772148 -- Test loss 0.1565485\n",
      "Epoch 541: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 542: -- Training loss 0.14436449 -- Validation loss:0.18683262 -- Test loss 0.15564865\n",
      "Epoch 542: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 543: -- Training loss 0.14355363 -- Validation loss:0.18595178 -- Test loss 0.1547567\n",
      "Epoch 543: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 544: -- Training loss 0.14275095 -- Validation loss:0.185079 -- Test loss 0.15387243\n",
      "Epoch 544: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 545: -- Training loss 0.14195652 -- Validation loss:0.18421419 -- Test loss 0.15299587\n",
      "Epoch 545: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 546: -- Training loss 0.14117014 -- Validation loss:0.18335728 -- Test loss 0.15212688\n",
      "Epoch 546: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 547: -- Training loss 0.14039169 -- Validation loss:0.18250827 -- Test loss 0.15126526\n",
      "Epoch 547: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 548: -- Training loss 0.1396211 -- Validation loss:0.18166713 -- Test loss 0.15041105\n",
      "Epoch 548: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 549: -- Training loss 0.13885827 -- Validation loss:0.1808338 -- Test loss 0.14956415\n",
      "Epoch 549: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 550: -- Training loss 0.13810302 -- Validation loss:0.18000822 -- Test loss 0.1487245\n",
      "Epoch 550: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 551: -- Training loss 0.1373554 -- Validation loss:0.17919038 -- Test loss 0.1478919\n",
      "Epoch 551: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 552: -- Training loss 0.13661513 -- Validation loss:0.17838025 -- Test loss 0.14706641\n",
      "Epoch 552: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 553: -- Training loss 0.13588221 -- Validation loss:0.17757775 -- Test loss 0.14624794\n",
      "Epoch 553: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 554: -- Training loss 0.13515656 -- Validation loss:0.17678279 -- Test loss 0.14543636\n",
      "Epoch 554: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 555: -- Training loss 0.13443804 -- Validation loss:0.17599542 -- Test loss 0.14463161\n",
      "Epoch 555: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 556: -- Training loss 0.13372654 -- Validation loss:0.1752156 -- Test loss 0.14383365\n",
      "Epoch 556: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 557: -- Training loss 0.13302197 -- Validation loss:0.17444326 -- Test loss 0.14304239\n",
      "Epoch 557: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 558: -- Training loss 0.13232428 -- Validation loss:0.17367826 -- Test loss 0.14225774\n",
      "Epoch 558: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 559: -- Training loss 0.13163333 -- Validation loss:0.17292078 -- Test loss 0.14147969\n",
      "Epoch 559: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 560: -- Training loss 0.1309491 -- Validation loss:0.17217056 -- Test loss 0.14070809\n",
      "Epoch 560: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 561: -- Training loss 0.13027135 -- Validation loss:0.17142767 -- Test loss 0.139943\n",
      "Epoch 561: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 562: -- Training loss 0.12960018 -- Validation loss:0.17069198 -- Test loss 0.13918419\n",
      "Epoch 562: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 563: -- Training loss 0.12893532 -- Validation loss:0.1699636 -- Test loss 0.13843174\n",
      "Epoch 563: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 564: -- Training loss 0.12827684 -- Validation loss:0.16924234 -- Test loss 0.13768548\n",
      "Epoch 564: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 565: -- Training loss 0.12762457 -- Validation loss:0.1685282 -- Test loss 0.13694544\n",
      "Epoch 565: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 566: -- Training loss 0.12697846 -- Validation loss:0.16782118 -- Test loss 0.13621154\n",
      "Epoch 566: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 567: -- Training loss 0.12633836 -- Validation loss:0.16712113 -- Test loss 0.13548373\n",
      "Epoch 567: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 568: -- Training loss 0.12570429 -- Validation loss:0.16642816 -- Test loss 0.13476196\n",
      "Epoch 568: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 569: -- Training loss 0.1250761 -- Validation loss:0.16574211 -- Test loss 0.13404617\n",
      "Epoch 569: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 570: -- Training loss 0.12445376 -- Validation loss:0.165063 -- Test loss 0.13333622\n",
      "Epoch 570: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 571: -- Training loss 0.123837166 -- Validation loss:0.16439073 -- Test loss 0.13263224\n",
      "Epoch 571: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 572: -- Training loss 0.12322623 -- Validation loss:0.16372527 -- Test loss 0.13193399\n",
      "Epoch 572: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 573: -- Training loss 0.1226209 -- Validation loss:0.1630666 -- Test loss 0.13124159\n",
      "Epoch 573: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 574: -- Training loss 0.12202106 -- Validation loss:0.16241466 -- Test loss 0.13055487\n",
      "Epoch 574: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 575: -- Training loss 0.1214267 -- Validation loss:0.16176946 -- Test loss 0.12987384\n",
      "Epoch 575: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 576: -- Training loss 0.12083771 -- Validation loss:0.16113089 -- Test loss 0.12919849\n",
      "Epoch 576: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 577: -- Training loss 0.12025403 -- Validation loss:0.1604989 -- Test loss 0.12852871\n",
      "Epoch 577: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 578: -- Training loss 0.1196756 -- Validation loss:0.15987349 -- Test loss 0.12786448\n",
      "Epoch 578: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 579: -- Training loss 0.119102314 -- Validation loss:0.1592546 -- Test loss 0.12720571\n",
      "Epoch 579: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 580: -- Training loss 0.118534125 -- Validation loss:0.15864216 -- Test loss 0.12655243\n",
      "Epoch 580: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 581: -- Training loss 0.117971 -- Validation loss:0.15803616 -- Test loss 0.12590455\n",
      "Epoch 581: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 582: -- Training loss 0.11741285 -- Validation loss:0.15743658 -- Test loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12526207\n",
      "Epoch 582: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 583: -- Training loss 0.11685957 -- Validation loss:0.15684326 -- Test loss 0.12462491\n",
      "Epoch 583: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 584: -- Training loss 0.11631117 -- Validation loss:0.15625632 -- Test loss 0.12399309\n",
      "Epoch 584: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 585: -- Training loss 0.11576753 -- Validation loss:0.15567558 -- Test loss 0.12336662\n",
      "Epoch 585: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 586: -- Training loss 0.11522864 -- Validation loss:0.1551011 -- Test loss 0.122745275\n",
      "Epoch 586: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 587: -- Training loss 0.114694394 -- Validation loss:0.15453272 -- Test loss 0.12212916\n",
      "Epoch 587: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 588: -- Training loss 0.11416474 -- Validation loss:0.15397052 -- Test loss 0.12151823\n",
      "Epoch 588: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 589: -- Training loss 0.11363966 -- Validation loss:0.15341432 -- Test loss 0.12091244\n",
      "Epoch 589: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 590: -- Training loss 0.11311906 -- Validation loss:0.15286423 -- Test loss 0.12031166\n",
      "Epoch 590: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 591: -- Training loss 0.11260289 -- Validation loss:0.1523201 -- Test loss 0.119716026\n",
      "Epoch 591: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 592: -- Training loss 0.11209112 -- Validation loss:0.15178193 -- Test loss 0.11912537\n",
      "Epoch 592: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 593: -- Training loss 0.11158365 -- Validation loss:0.15124969 -- Test loss 0.118539736\n",
      "Epoch 593: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 594: -- Training loss 0.11108045 -- Validation loss:0.1507233 -- Test loss 0.11795916\n",
      "Epoch 594: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 595: -- Training loss 0.110581495 -- Validation loss:0.15020266 -- Test loss 0.11738351\n",
      "Epoch 595: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 596: -- Training loss 0.110086694 -- Validation loss:0.14968784 -- Test loss 0.11681268\n",
      "Epoch 596: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 597: -- Training loss 0.109596014 -- Validation loss:0.14917876 -- Test loss 0.116246805\n",
      "Epoch 597: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 598: -- Training loss 0.10910942 -- Validation loss:0.14867534 -- Test loss 0.11568574\n",
      "Epoch 598: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 599: -- Training loss 0.10862683 -- Validation loss:0.14817758 -- Test loss 0.11512948\n",
      "Epoch 599: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 600: -- Training loss 0.10814822 -- Validation loss:0.14768542 -- Test loss 0.1145781\n",
      "Epoch 600: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 601: -- Training loss 0.10767355 -- Validation loss:0.1471988 -- Test loss 0.11403144\n",
      "Epoch 601: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 602: -- Training loss 0.107202746 -- Validation loss:0.14671768 -- Test loss 0.113489516\n",
      "Epoch 602: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 603: -- Training loss 0.10673579 -- Validation loss:0.14624211 -- Test loss 0.11295233\n",
      "Epoch 603: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 604: -- Training loss 0.10627261 -- Validation loss:0.14577185 -- Test loss 0.112419814\n",
      "Epoch 604: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 605: -- Training loss 0.10581319 -- Validation loss:0.14530702 -- Test loss 0.111891925\n",
      "Epoch 605: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 606: -- Training loss 0.105357476 -- Validation loss:0.14484759 -- Test loss 0.1113687\n",
      "Epoch 606: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 607: -- Training loss 0.104905434 -- Validation loss:0.14439343 -- Test loss 0.11085017\n",
      "Epoch 607: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 608: -- Training loss 0.10445696 -- Validation loss:0.14394456 -- Test loss 0.110336155\n",
      "Epoch 608: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 609: -- Training loss 0.104012124 -- Validation loss:0.14350083 -- Test loss 0.109826766\n",
      "Epoch 609: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 610: -- Training loss 0.10357081 -- Validation loss:0.14306232 -- Test loss 0.10932187\n",
      "Epoch 610: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 611: -- Training loss 0.10313298 -- Validation loss:0.14262895 -- Test loss 0.108821526\n",
      "Epoch 611: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 612: -- Training loss 0.10269863 -- Validation loss:0.14220066 -- Test loss 0.10832561\n",
      "Epoch 612: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 613: -- Training loss 0.10226772 -- Validation loss:0.1417774 -- Test loss 0.1078342\n",
      "Epoch 613: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 614: -- Training loss 0.10184015 -- Validation loss:0.14135914 -- Test loss 0.107347205\n",
      "Epoch 614: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 615: -- Training loss 0.10141596 -- Validation loss:0.1409459 -- Test loss 0.10686469\n",
      "Epoch 615: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 616: -- Training loss 0.10099506 -- Validation loss:0.14053752 -- Test loss 0.10638653\n",
      "Epoch 616: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 617: -- Training loss 0.10057746 -- Validation loss:0.14013408 -- Test loss 0.10591276\n",
      "Epoch 617: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 618: -- Training loss 0.10016308 -- Validation loss:0.13973542 -- Test loss 0.10544334\n",
      "Epoch 618: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 619: -- Training loss 0.09975189 -- Validation loss:0.13934164 -- Test loss 0.10497826\n",
      "Epoch 619: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 620: -- Training loss 0.099343896 -- Validation loss:0.13895257 -- Test loss 0.10451744\n",
      "Epoch 620: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 621: -- Training loss 0.09893904 -- Validation loss:0.13856813 -- Test loss 0.10406096\n",
      "Epoch 621: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 622: -- Training loss 0.09853727 -- Validation loss:0.13818856 -- Test loss 0.103608675\n",
      "Epoch 622: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 623: -- Training loss 0.09813857 -- Validation loss:0.13781345 -- Test loss 0.10316066\n",
      "Epoch 623: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 624: -- Training loss 0.09774289 -- Validation loss:0.13744305 -- Test loss 0.10271683\n",
      "Epoch 624: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 625: -- Training loss 0.09735023 -- Validation loss:0.13707718 -- Test loss 0.102277234\n",
      "Epoch 625: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 626: -- Training loss 0.09696054 -- Validation loss:0.13671577 -- Test loss 0.10184175\n",
      "Epoch 626: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 627: -- Training loss 0.0965738 -- Validation loss:0.1363589 -- Test loss 0.101410426\n",
      "Epoch 627: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 628: -- Training loss 0.09618997 -- Validation loss:0.13600643 -- Test loss 0.10098321\n",
      "Epoch 628: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 629: -- Training loss 0.09580901 -- Validation loss:0.13565843 -- Test loss 0.10056012\n",
      "Epoch 629: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 630: -- Training loss 0.09543089 -- Validation loss:0.13531469 -- Test loss 0.10014108\n",
      "Epoch 630: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 631: -- Training loss 0.095055595 -- Validation loss:0.13497533 -- Test loss 0.099726096\n",
      "Epoch 631: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 632: -- Training loss 0.09468308 -- Validation loss:0.13464023 -- Test loss 0.09931513\n",
      "Epoch 632: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 633: -- Training loss 0.09431334 -- Validation loss:0.13430946 -- Test loss 0.09890816\n",
      "Epoch 633: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 634: -- Training loss 0.093946315 -- Validation loss:0.13398282 -- Test loss 0.098505236\n",
      "Epoch 634: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 635: -- Training loss 0.09358198 -- Validation loss:0.13366039 -- Test loss 0.09810622\n",
      "Epoch 635: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 636: -- Training loss 0.093220346 -- Validation loss:0.1333421 -- Test loss 0.09771109\n",
      "Epoch 636: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 637: -- Training loss 0.092861325 -- Validation loss:0.1330278 -- Test loss 0.097319946\n",
      "Epoch 637: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 638: -- Training loss 0.09250494 -- Validation loss:0.13271767 -- Test loss 0.09693259\n",
      "Epoch 638: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 639: -- Training loss 0.09215115 -- Validation loss:0.13241152 -- Test loss 0.09654913\n",
      "Epoch 639: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 640: -- Training loss 0.09179991 -- Validation loss:0.13210936 -- Test loss 0.09616948\n",
      "Epoch 640: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 641: -- Training loss 0.09145118 -- Validation loss:0.13181116 -- Test loss 0.09579366\n",
      "Epoch 641: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 642: -- Training loss 0.091105 -- Validation loss:0.13151683 -- Test loss 0.0954216\n",
      "Epoch 642: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 643: -- Training loss 0.090761304 -- Validation loss:0.13122644 -- Test loss 0.095053285\n",
      "Epoch 643: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 644: -- Training loss 0.09042003 -- Validation loss:0.13093983 -- Test loss 0.09468879\n",
      "Epoch 644: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 645: -- Training loss 0.09008119 -- Validation loss:0.13065708 -- Test loss 0.09432795\n",
      "Epoch 645: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 646: -- Training loss 0.089744754 -- Validation loss:0.1303781 -- Test loss 0.093970805\n",
      "Epoch 646: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 647: -- Training loss 0.08941071 -- Validation loss:0.13010283 -- Test loss 0.093617305\n",
      "Epoch 647: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 648: -- Training loss 0.08907904 -- Validation loss:0.12983136 -- Test loss 0.09326747\n",
      "Epoch 648: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 649: -- Training loss 0.08874963 -- Validation loss:0.12956347 -- Test loss 0.0929212\n",
      "Epoch 649: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 650: -- Training loss 0.08842259 -- Validation loss:0.12929924 -- Test loss 0.09257852\n",
      "Epoch 650: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 651: -- Training loss 0.088097796 -- Validation loss:0.12903862 -- Test loss 0.09223938\n",
      "Epoch 651: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 652: -- Training loss 0.08777525 -- Validation loss:0.12878157 -- Test loss 0.091903746\n",
      "Epoch 652: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 653: -- Training loss 0.08745497 -- Validation loss:0.12852806 -- Test loss 0.09157159\n",
      "Epoch 653: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 654: -- Training loss 0.08713685 -- Validation loss:0.12827809 -- Test loss 0.091242924\n",
      "Epoch 654: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 655: -- Training loss 0.086820915 -- Validation loss:0.12803158 -- Test loss 0.09091768\n",
      "Epoch 655: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 656: -- Training loss 0.08650718 -- Validation loss:0.12778853 -- Test loss 0.09059589\n",
      "Epoch 656: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 657: -- Training loss 0.086195536 -- Validation loss:0.12754886 -- Test loss 0.09027751\n",
      "Epoch 657: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 658: -- Training loss 0.08588604 -- Validation loss:0.12731266 -- Test loss 0.08996245\n",
      "Epoch 658: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 659: -- Training loss 0.08557862 -- Validation loss:0.12707971 -- Test loss 0.08965083\n",
      "Epoch 659: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 660: -- Training loss 0.08527325 -- Validation loss:0.12685019 -- Test loss 0.089342415\n",
      "Epoch 660: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 661: -- Training loss 0.08496995 -- Validation loss:0.12662393 -- Test loss 0.08903728\n",
      "Epoch 661: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 662: -- Training loss 0.084668666 -- Validation loss:0.12640096 -- Test loss 0.08873541\n",
      "Epoch 662: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 663: -- Training loss 0.08436937 -- Validation loss:0.1261812 -- Test loss 0.088436715\n",
      "Epoch 663: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 664: -- Training loss 0.084072046 -- Validation loss:0.12596464 -- Test loss 0.08814125\n",
      "Epoch 664: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 665: -- Training loss 0.0837767 -- Validation loss:0.1257513 -- Test loss 0.08784897\n",
      "Epoch 665: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 666: -- Training loss 0.0834833 -- Validation loss:0.1255411 -- Test loss 0.087559834\n",
      "Epoch 666: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 667: -- Training loss 0.083191834 -- Validation loss:0.1253341 -- Test loss 0.08727377\n",
      "Epoch 667: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 668: -- Training loss 0.0829022 -- Validation loss:0.12513019 -- Test loss 0.08699083\n",
      "Epoch 668: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 669: -- Training loss 0.082614504 -- Validation loss:0.12492931 -- Test loss 0.08671091\n",
      "Epoch 669: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 670: -- Training loss 0.08232864 -- Validation loss:0.12473151 -- Test loss 0.086434014\n",
      "Epoch 670: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 671: -- Training loss 0.08204462 -- Validation loss:0.12453673 -- Test loss 0.086160176\n",
      "Epoch 671: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 672: -- Training loss 0.08176238 -- Validation loss:0.124345005 -- Test loss 0.0858893\n",
      "Epoch 672: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 673: -- Training loss 0.08148197 -- Validation loss:0.124156244 -- Test loss 0.08562131\n",
      "Epoch 673: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 674: -- Training loss 0.08120332 -- Validation loss:0.1239704 -- Test loss 0.08535616\n",
      "Epoch 674: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 675: -- Training loss 0.08092642 -- Validation loss:0.12378749 -- Test loss 0.08509398\n",
      "Epoch 675: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 676: -- Training loss 0.080651276 -- Validation loss:0.12360755 -- Test loss 0.084834546\n",
      "Epoch 676: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 677: -- Training loss 0.08037787 -- Validation loss:0.12343045 -- Test loss 0.084578045\n",
      "Epoch 677: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 678: -- Training loss 0.0801061 -- Validation loss:0.123256214 -- Test loss 0.0843243\n",
      "Epoch 678: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 679: -- Training loss 0.07983606 -- Validation loss:0.12308484 -- Test loss 0.08407331\n",
      "Epoch 679: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 680: -- Training loss 0.079567686 -- Validation loss:0.1229163 -- Test loss 0.08382508\n",
      "Epoch 680: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 681: -- Training loss 0.079300985 -- Validation loss:0.12275046 -- Test loss 0.08357956\n",
      "Epoch 681: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 682: -- Training loss 0.07903586 -- Validation loss:0.122587524 -- Test loss 0.0833367\n",
      "Epoch 682: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 683: -- Training loss 0.07877238 -- Validation loss:0.12242732 -- Test loss 0.08309654\n",
      "Epoch 683: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 684: -- Training loss 0.07851046 -- Validation loss:0.12226982 -- Test loss 0.08285893\n",
      "Epoch 684: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 685: -- Training loss 0.07825013 -- Validation loss:0.12211502 -- Test loss 0.08262389\n",
      "Epoch 685: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 686: -- Training loss 0.07799138 -- Validation loss:0.12196294 -- Test loss 0.08239147\n",
      "Epoch 686: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 687: -- Training loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.077734165 -- Validation loss:0.12181351 -- Test loss 0.0821615\n",
      "Epoch 687: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 688: -- Training loss 0.077478476 -- Validation loss:0.12166677 -- Test loss 0.0819341\n",
      "Epoch 688: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 689: -- Training loss 0.07722431 -- Validation loss:0.12152261 -- Test loss 0.081709154\n",
      "Epoch 689: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 690: -- Training loss 0.07697163 -- Validation loss:0.121381134 -- Test loss 0.081486665\n",
      "Epoch 690: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 691: -- Training loss 0.07672046 -- Validation loss:0.121242225 -- Test loss 0.08126662\n",
      "Epoch 691: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 692: -- Training loss 0.07647071 -- Validation loss:0.12110588 -- Test loss 0.08104897\n",
      "Epoch 692: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 693: -- Training loss 0.07622246 -- Validation loss:0.120972104 -- Test loss 0.0808337\n",
      "Epoch 693: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 694: -- Training loss 0.07597562 -- Validation loss:0.120840915 -- Test loss 0.08062076\n",
      "Epoch 694: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 695: -- Training loss 0.07573019 -- Validation loss:0.12071222 -- Test loss 0.08041005\n",
      "Epoch 695: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 696: -- Training loss 0.0754862 -- Validation loss:0.12058604 -- Test loss 0.0802017\n",
      "Epoch 696: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 697: -- Training loss 0.07524357 -- Validation loss:0.120462306 -- Test loss 0.079995506\n",
      "Epoch 697: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 698: -- Training loss 0.07500234 -- Validation loss:0.12034106 -- Test loss 0.07979169\n",
      "Epoch 698: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 699: -- Training loss 0.07476245 -- Validation loss:0.12022232 -- Test loss 0.07958993\n",
      "Epoch 699: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 700: -- Training loss 0.0745239 -- Validation loss:0.12010593 -- Test loss 0.079390384\n",
      "Epoch 700: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 701: -- Training loss 0.07428672 -- Validation loss:0.11999207 -- Test loss 0.07919304\n",
      "Epoch 701: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 702: -- Training loss 0.07405087 -- Validation loss:0.11988061 -- Test loss 0.07899774\n",
      "Epoch 702: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 703: -- Training loss 0.07381633 -- Validation loss:0.11977145 -- Test loss 0.078804635\n",
      "Epoch 703: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 704: -- Training loss 0.07358307 -- Validation loss:0.11966479 -- Test loss 0.07861355\n",
      "Epoch 704: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 705: -- Training loss 0.073351115 -- Validation loss:0.11956039 -- Test loss 0.07842455\n",
      "Epoch 705: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 706: -- Training loss 0.0731204 -- Validation loss:0.11945838 -- Test loss 0.0782375\n",
      "Epoch 706: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 707: -- Training loss 0.072890975 -- Validation loss:0.11935866 -- Test loss 0.07805253\n",
      "Epoch 707: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 708: -- Training loss 0.07266277 -- Validation loss:0.11926127 -- Test loss 0.07786944\n",
      "Epoch 708: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 709: -- Training loss 0.072435826 -- Validation loss:0.11916625 -- Test loss 0.077688314\n",
      "Epoch 709: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 710: -- Training loss 0.072210096 -- Validation loss:0.11907341 -- Test loss 0.077509105\n",
      "Epoch 710: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 711: -- Training loss 0.07198559 -- Validation loss:0.11898295 -- Test loss 0.07733171\n",
      "Epoch 711: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 712: -- Training loss 0.07176225 -- Validation loss:0.11889463 -- Test loss 0.07715628\n",
      "Epoch 712: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 713: -- Training loss 0.07154012 -- Validation loss:0.11880863 -- Test loss 0.07698271\n",
      "Epoch 713: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 714: -- Training loss 0.071319155 -- Validation loss:0.118724875 -- Test loss 0.076810986\n",
      "Epoch 714: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 715: -- Training loss 0.07109939 -- Validation loss:0.118643366 -- Test loss 0.07664109\n",
      "Epoch 715: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 716: -- Training loss 0.070880786 -- Validation loss:0.11856387 -- Test loss 0.076472886\n",
      "Epoch 716: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 717: -- Training loss 0.07066328 -- Validation loss:0.118486725 -- Test loss 0.07630646\n",
      "Epoch 717: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 718: -- Training loss 0.070446916 -- Validation loss:0.11841175 -- Test loss 0.07614181\n",
      "Epoch 718: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 719: -- Training loss 0.070231676 -- Validation loss:0.118338935 -- Test loss 0.07597882\n",
      "Epoch 719: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 720: -- Training loss 0.07001756 -- Validation loss:0.11826823 -- Test loss 0.07581754\n",
      "Epoch 720: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 721: -- Training loss 0.06980457 -- Validation loss:0.118199684 -- Test loss 0.07565787\n",
      "Epoch 721: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 722: -- Training loss 0.06959263 -- Validation loss:0.11813321 -- Test loss 0.07549989\n",
      "Epoch 722: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 723: -- Training loss 0.069381796 -- Validation loss:0.11806888 -- Test loss 0.07534352\n",
      "Epoch 723: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 724: -- Training loss 0.06917205 -- Validation loss:0.11800661 -- Test loss 0.07518878\n",
      "Epoch 724: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 725: -- Training loss 0.068963334 -- Validation loss:0.117946446 -- Test loss 0.0750356\n",
      "Epoch 725: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 726: -- Training loss 0.06875567 -- Validation loss:0.11788842 -- Test loss 0.074884064\n",
      "Epoch 726: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 727: -- Training loss 0.068549104 -- Validation loss:0.117832385 -- Test loss 0.074734084\n",
      "Epoch 727: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 728: -- Training loss 0.06834352 -- Validation loss:0.1177785 -- Test loss 0.074585564\n",
      "Epoch 728: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 729: -- Training loss 0.068138994 -- Validation loss:0.117726505 -- Test loss 0.07443863\n",
      "Epoch 729: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 730: -- Training loss 0.06793547 -- Validation loss:0.11767662 -- Test loss 0.074293084\n",
      "Epoch 730: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 731: -- Training loss 0.06773292 -- Validation loss:0.117628686 -- Test loss 0.07414901\n",
      "Epoch 731: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 732: -- Training loss 0.06753141 -- Validation loss:0.11758277 -- Test loss 0.07400638\n",
      "Epoch 732: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 733: -- Training loss 0.06733088 -- Validation loss:0.11753885 -- Test loss 0.07386517\n",
      "Epoch 733: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 734: -- Training loss 0.06713133 -- Validation loss:0.11749688 -- Test loss 0.07372542\n",
      "Epoch 734: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 735: -- Training loss 0.06693276 -- Validation loss:0.11745685 -- Test loss 0.07358705\n",
      "Epoch 735: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 736: -- Training loss 0.06673514 -- Validation loss:0.11741885 -- Test loss 0.073450066\n",
      "Epoch 736: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 737: -- Training loss 0.06653848 -- Validation loss:0.11738277 -- Test loss 0.07331449\n",
      "Epoch 737: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 738: -- Training loss 0.06634276 -- Validation loss:0.11734858 -- Test loss 0.07318024\n",
      "Epoch 738: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 739: -- Training loss 0.06614801 -- Validation loss:0.11731634 -- Test loss 0.07304734\n",
      "Epoch 739: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 740: -- Training loss 0.06595418 -- Validation loss:0.11728596 -- Test loss 0.072915785\n",
      "Epoch 740: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 741: -- Training loss 0.06576126 -- Validation loss:0.117257506 -- Test loss 0.072785474\n",
      "Epoch "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 742: -- Training loss 0.065569244 -- Validation loss:0.11723096 -- Test loss 0.07265642\n",
      "Epoch 742: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 743: -- Training loss 0.06537818 -- Validation loss:0.117206246 -- Test loss 0.072528645\n",
      "Epoch 743: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 744: -- Training loss 0.065188006 -- Validation loss:0.11718339 -- Test loss 0.072402105\n",
      "Epoch 744: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 745: -- Training loss 0.06499871 -- Validation loss:0.11716237 -- Test loss 0.0722768\n",
      "Epoch 745: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 746: -- Training loss 0.06481029 -- Validation loss:0.117143184 -- Test loss 0.07215278\n",
      "Epoch 746: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 747: -- Training loss 0.064622775 -- Validation loss:0.11712583 -- Test loss 0.07202989\n",
      "Epoch 747: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 748: -- Training loss 0.06443612 -- Validation loss:0.11711035 -- Test loss 0.07190829\n",
      "Epoch 748: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 749: -- Training loss 0.06425031 -- Validation loss:0.11709661 -- Test loss 0.071787864\n",
      "Epoch 749: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 750: -- Training loss 0.06406538 -- Validation loss:0.117084675 -- Test loss 0.07166855\n",
      "Epoch 750: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 751: -- Training loss 0.06388131 -- Validation loss:0.11707458 -- Test loss 0.07155044\n",
      "Epoch 751: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 752: -- Training loss 0.063698076 -- Validation loss:0.11706615 -- Test loss 0.07143347\n",
      "Epoch 752: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 753: -- Training loss 0.06351569 -- Validation loss:0.117059596 -- Test loss 0.07131757\n",
      "Epoch 753: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 754: -- Training loss 0.06333409 -- Validation loss:0.11705469 -- Test loss 0.0712028\n",
      "Epoch 754: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 755: -- Training loss 0.063153364 -- Validation loss:0.11705151 -- Test loss 0.07108914\n",
      "Epoch 755: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 756: -- Training loss 0.06297341 -- Validation loss:0.11705012 -- Test loss 0.07097657\n",
      "Epoch 756: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 757: -- Training loss 0.062794305 -- Validation loss:0.11705041 -- Test loss 0.07086515\n",
      "Epoch 757: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 758: -- Training loss 0.062615976 -- Validation loss:0.11705244 -- Test loss 0.07075471\n",
      "Epoch 758: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 759: -- Training loss 0.062438473 -- Validation loss:0.11705611 -- Test loss 0.07064539\n",
      "Epoch 759: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 760: -- Training loss 0.06226173 -- Validation loss:0.117061555 -- Test loss 0.07053702\n",
      "Epoch 760: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 761: -- Training loss 0.06208577 -- Validation loss:0.117068596 -- Test loss 0.070429765\n",
      "Epoch 761: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 762: -- Training loss 0.061910603 -- Validation loss:0.11707735 -- Test loss 0.07032351\n",
      "Epoch 762: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 763: -- Training loss 0.061736222 -- Validation loss:0.117087744 -- Test loss 0.07021827\n",
      "Epoch 763: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 764: -- Training loss 0.061562613 -- Validation loss:0.11709979 -- Test loss 0.07011402\n",
      "Epoch 764: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 765: -- Training loss 0.061389722 -- Validation loss:0.11711348 -- Test loss 0.07001078\n",
      "Epoch 765: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 766: -- Training loss 0.061217632 -- Validation loss:0.11712875 -- Test loss 0.0699085\n",
      "Epoch 766: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 767: -- Training loss 0.061046284 -- Validation loss:0.117145665 -- Test loss 0.06980725\n",
      "Epoch 767: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 768: -- Training loss 0.060875673 -- Validation loss:0.11716417 -- Test loss 0.069706894\n",
      "Epoch 768: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 769: -- Training loss 0.06070579 -- Validation loss:0.117184244 -- Test loss 0.0696075\n",
      "Epoch 769: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 770: -- Training loss 0.060536675 -- Validation loss:0.11720603 -- Test loss 0.06950906\n",
      "Epoch 770: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 771: -- Training loss 0.060368244 -- Validation loss:0.11722925 -- Test loss 0.06941154\n",
      "Epoch 771: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 772: -- Training loss 0.060200557 -- Validation loss:0.11725407 -- Test loss 0.06931491\n",
      "Epoch 772: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 773: -- Training loss 0.060033564 -- Validation loss:0.11728046 -- Test loss 0.06921926\n",
      "Epoch 773: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 774: -- Training loss 0.0598673 -- Validation loss:0.117308445 -- Test loss 0.06912447\n",
      "Epoch 774: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 775: -- Training loss 0.059701744 -- Validation loss:0.11733788 -- Test loss 0.06903061\n",
      "Epoch 775: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 776: -- Training loss 0.059536893 -- Validation loss:0.11736882 -- Test loss 0.068937644\n",
      "Epoch 776: -- Training acc  1.0 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Early stopped: Validation loss hasn't improved in  20 epochs.\n",
      "Epoch "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -- Training loss 1.0861715 -- Validation loss:1.1355492 -- Test loss 1.1038504\n",
      "Epoch 1: -- Training loss 1.0836545 -- Validation loss:1.1290071 -- Test loss 1.1002014\n",
      "Epoch 1: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 2: -- Training loss 1.081628 -- Validation loss:1.1235787 -- Test loss 1.0972536\n",
      "Epoch 2: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 3: -- Training loss 1.0799593 -- Validation loss:1.1188927 -- Test loss 1.0947721\n",
      "Epoch 3: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 4: -- Training loss 1.0785555 -- Validation loss:1.1147991 -- Test loss 1.0926465\n",
      "Epoch 4: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 5: -- Training loss 1.0773343 -- Validation loss:1.111416 -- Test loss 1.0908643\n",
      "Epoch 5: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 6: -- Training loss 1.0761945 -- Validation loss:1.1087745 -- Test loss 1.0893669\n",
      "Epoch 6: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 7: -- Training loss 1.075034 -- Validation loss:1.1068021 -- Test loss 1.0880567\n",
      "Epoch 7: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 8: -- Training loss 1.0737703 -- Validation loss:1.1053544 -- Test loss 1.0868258\n",
      "Epoch 8: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 9: -- Training loss 1.0723555 -- Validation loss:1.1042643 -- Test loss 1.0855851\n",
      "Epoch 9: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 10: -- Training loss 1.0707755 -- Validation loss:1.1033822 -- Test loss 1.0842754\n",
      "Epoch 10: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 11: -- Training loss 1.0690397 -- Validation loss:1.1025888 -- Test loss 1.0828649\n",
      "Epoch 11: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 12: -- Training loss 1.0671695 -- Validation loss:1.1017905 -- Test loss 1.0813401\n",
      "Epoch 12: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 13: -- Training loss 1.0651876 -- Validation loss:1.1009115 -- Test loss 1.079694\n",
      "Epoch 13: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 14: -- Training loss 1.063114 -- Validation loss:1.0998857 -- Test loss 1.0779219\n",
      "Epoch 14: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 15: -- Training loss 1.0609602 -- Validation loss:1.0986522 -- Test loss 1.0760142\n",
      "Epoch 15: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 16: -- Training loss 1.0587292 -- Validation loss:1.0971564 -- Test loss 1.0739584\n",
      "Epoch 16: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 17: -- Training loss 1.0564159 -- Validation loss:1.0953547 -- Test loss 1.0717407\n",
      "Epoch 17: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 18: -- Training loss 1.0540093 -- Validation loss:1.093218 -- Test loss 1.0693479\n",
      "Epoch 18: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 19: -- Training loss 1.0514947 -- Validation loss:1.0907371 -- Test loss 1.0667702\n",
      "Epoch 19: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 20: -- Training loss 1.0488567 -- Validation loss:1.0879227 -- Test loss 1.0640044\n",
      "Epoch 20: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 21: -- Training loss 1.0460807 -- Validation loss:1.0848013 -- Test loss 1.0610528\n",
      "Epoch 21: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 22: -- Training loss 1.0431552 -- Validation loss:1.0814104 -- Test loss 1.0579227\n",
      "Epoch 22: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 23: -- Training loss 1.0400729 -- Validation loss:1.0777929 -- Test loss 1.0546237\n",
      "Epoch 23: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 24: -- Training loss 1.036829 -- Validation loss:1.0739911 -- Test loss 1.0511684\n",
      "Epoch 24: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 25: -- Training loss 1.0334227 -- Validation loss:1.0700423 -- Test loss 1.0475668\n",
      "Epoch 25: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 26: -- Training loss 1.0298538 -- Validation loss:1.0659767 -- Test loss 1.0438273\n",
      "Epoch 26: -- Training acc  0.38028169014084506 -- Validation acc: 0.20833333333333334 -- Test acc  0.32\n",
      "Epoch 27: -- Training loss 1.0261225 -- Validation loss:1.0618142 -- Test loss 1.0399549\n",
      "Epoch 27: -- Training acc  0.39436619718309857 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 28: -- Training loss 1.0222288 -- Validation loss:1.0575631 -- Test loss 1.035949\n",
      "Epoch 28: -- Training acc  0.4084507042253521 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 29: -- Training loss 1.0181708 -- Validation loss:1.05322 -- Test loss 1.0318038\n",
      "Epoch 29: -- Training acc  0.4084507042253521 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 30: -- Training loss 1.0139447 -- Validation loss:1.0487716 -- Test loss 1.0275096\n",
      "Epoch 30: -- Training acc  0.4647887323943662 -- Validation acc: 0.2916666666666667 -- Test acc  0.36\n",
      "Epoch 31: -- Training loss 1.0095453 -- Validation loss:1.0441967 -- Test loss 1.0230519\n",
      "Epoch 31: -- Training acc  0.49295774647887325 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 32: -- Training loss 1.0049672 -- Validation loss:1.0394706 -- Test loss 1.018415\n",
      "Epoch 32: -- Training acc  0.5211267605633803 -- Validation acc: 0.375 -- Test acc  0.44\n",
      "Epoch 33: -- Training loss 1.0002035 -- Validation loss:1.0345663 -- Test loss 1.0135838\n",
      "Epoch 33: -- Training acc  0.5915492957746479 -- Validation acc: 0.4583333333333333 -- Test acc  0.48\n",
      "Epoch 34: -- Training loss 0.9952489 -- Validation loss:1.0294596 -- Test loss 1.008544\n",
      "Epoch 34: -- Training acc  0.6338028169014085 -- Validation acc: 0.5 -- Test acc  0.6\n",
      "Epoch 35: -- Training loss 0.9900993 -- Validation loss:1.0241296 -- Test loss 1.0032843\n",
      "Epoch 35: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 36: -- Training loss 0.9847518 -- Validation loss:1.0185605 -- Test loss 0.9977975\n",
      "Epoch 36: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 37: -- Training loss 0.9792055 -- Validation loss:1.0127419 -- Test loss 0.99207926\n",
      "Epoch 37: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 38: -- Training loss 0.9734608 -- Validation loss:1.0066693 -- Test loss 0.98612875\n",
      "Epoch 38: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 39: -- Training loss 0.967519 -- Validation loss:1.0003427 -- Test loss 0.9799484\n",
      "Epoch 39: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 40: -- Training loss 0.96138227 -- Validation loss:0.9937665 -- Test loss 0.9735426\n",
      "Epoch 40: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 41: -- Training loss 0.9550531 -- Validation loss:0.9869482 -- Test loss 0.96691775\n",
      "Epoch 41: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 42: -- Training loss 0.94853455 -- Validation loss:0.9798978 -- Test loss 0.96008134\n",
      "Epoch 42: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 43: -- Training loss 0.9418294 -- Validation loss:0.97262627 -- Test loss 0.9530417\n",
      "Epoch 43: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 44: -- Training loss 0.93494135 -- Validation loss:0.96514535 -- Test loss 0.9458074\n",
      "Epoch 44: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 45: -- Training loss 0.9278749 -- Validation loss:0.9574651 -- Test loss 0.93838716\n",
      "Epoch 45: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 46: -- Training loss 0.92063475 -- Validation loss:0.94959426 -- Test loss 0.9307891\n",
      "Epoch 46: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 47: -- Training loss 0.91322714 -- Validation loss:0.94153905 -- Test loss 0.9230205\n",
      "Epoch 47: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 48: -- Training loss 0.9056601 -- Validation loss:0.93330216 -- Test loss 0.9150879\n",
      "Epoch 48: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 49: -- Training loss 0.89794207 -- Validation loss:0.9248855 -- Test loss 0.9069975\n",
      "Epoch 49: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 50: -- Training loss 0.8900837 -- Validation loss:0.91628903 -- Test loss 0.8987543\n",
      "Epoch 50: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 51: -- Training loss 0.88209516 -- Validation loss:0.9075133 -- Test loss 0.89036393\n",
      "Epoch 51: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 52: -- Training loss 0.8739883 -- Validation loss:0.89856124 -- Test loss 0.8818327\n",
      "Epoch 52: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 53: -- Training loss 0.8657745 -- Validation loss:0.88943934 -- Test loss 0.87316823\n",
      "Epoch 53: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 54: -- Training loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8574662 -- Validation loss:0.8801586 -- Test loss 0.8643808\n",
      "Epoch 54: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 55: -- Training loss 0.8490762 -- Validation loss:0.8707363 -- Test loss 0.8554832\n",
      "Epoch 55: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 56: -- Training loss 0.84061795 -- Validation loss:0.86119527 -- Test loss 0.8464916\n",
      "Epoch 56: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 57: -- Training loss 0.8321055 -- Validation loss:0.8515629 -- Test loss 0.8374255\n",
      "Epoch 57: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 58: -- Training loss 0.8235533 -- Validation loss:0.8418688 -- Test loss 0.8283064\n",
      "Epoch 58: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 59: -- Training loss 0.81497645 -- Validation loss:0.8321441 -- Test loss 0.8191563\n",
      "Epoch 59: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 60: -- Training loss 0.8063897 -- Validation loss:0.82241774 -- Test loss 0.80999845\n",
      "Epoch 60: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 61: -- Training loss 0.79780823 -- Validation loss:0.81271654 -- Test loss 0.8008546\n",
      "Epoch 61: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 62: -- Training loss 0.78924644 -- Validation loss:0.8030625 -- Test loss 0.79174507\n",
      "Epoch 62: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 63: -- Training loss 0.78071946 -- Validation loss:0.79347324 -- Test loss 0.7826874\n",
      "Epoch 63: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 64: -- Training loss 0.77224094 -- Validation loss:0.7839605 -- Test loss 0.7736976\n",
      "Epoch 64: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 65: -- Training loss 0.7638251 -- Validation loss:0.77453214 -- Test loss 0.76478773\n",
      "Epoch 65: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 66: -- Training loss 0.75548553 -- Validation loss:0.76519203 -- Test loss 0.75596833\n",
      "Epoch 66: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 67: -- Training loss 0.7472349 -- Validation loss:0.7559419 -- Test loss 0.747247\n",
      "Epoch 67: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 68: -- Training loss 0.7390856 -- Validation loss:0.74678344 -- Test loss 0.7386317\n",
      "Epoch 68: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 69: -- Training loss 0.7310488 -- Validation loss:0.7377191 -- Test loss 0.7301293\n",
      "Epoch 69: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 70: -- Training loss 0.72313505 -- Validation loss:0.7287536 -- Test loss 0.721747\n",
      "Epoch 70: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 71: -- Training loss 0.71535414 -- Validation loss:0.7198947 -- Test loss 0.7134934\n",
      "Epoch 71: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 72: -- Training loss 0.70771486 -- Validation loss:0.71115357 -- Test loss 0.70537835\n",
      "Epoch 72: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 73: -- Training loss 0.7002254 -- Validation loss:0.70254326 -- Test loss 0.6974122\n",
      "Epoch 73: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 74: -- Training loss 0.6928928 -- Validation loss:0.6940786 -- Test loss 0.6896063\n",
      "Epoch 74: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 75: -- Training loss 0.6857232 -- Validation loss:0.6857745 -- Test loss 0.6819716\n",
      "Epoch 75: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 76: -- Training loss 0.678722 -- Validation loss:0.6776457 -- Test loss 0.67451787\n",
      "Epoch 76: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 77: -- Training loss 0.67189354 -- Validation loss:0.669705 -- Test loss 0.66725427\n",
      "Epoch 77: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 78: -- Training loss 0.66524094 -- Validation loss:0.66196257 -- Test loss 0.66018695\n",
      "Epoch 78: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 79: -- Training loss 0.6587666 -- Validation loss:0.654426 -- Test loss 0.65332055\n",
      "Epoch 79: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 80: -- Training loss 0.6524721 -- Validation loss:0.64710015 -- Test loss 0.6466572\n",
      "Epoch 80: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 81: -- Training loss 0.64635813 -- Validation loss:0.6399871 -- Test loss 0.64019746\n",
      "Epoch 81: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 82: -- Training loss 0.64042443 -- Validation loss:0.63308674 -- Test loss 0.63394016\n",
      "Epoch 82: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 83: -- Training loss 0.63467026 -- Validation loss:0.62639767 -- Test loss 0.62788236\n",
      "Epoch 83: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 84: -- Training loss 0.62909406 -- Validation loss:0.6199168 -- Test loss 0.62202144\n",
      "Epoch 84: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 85: -- Training loss 0.62369347 -- Validation loss:0.6136407 -- Test loss 0.6163533\n",
      "Epoch 85: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 86: -- Training loss 0.6184657 -- Validation loss:0.60756546 -- Test loss 0.61087453\n",
      "Epoch 86: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 87: -- Training loss 0.6134077 -- Validation loss:0.6016868 -- Test loss 0.60558146\n",
      "Epoch 87: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 88: -- Training loss 0.60851556 -- Validation loss:0.59600043 -- Test loss 0.60047\n",
      "Epoch 88: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 89: -- Training loss 0.60378546 -- Validation loss:0.59050155 -- Test loss 0.5955366\n",
      "Epoch 89: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 90: -- Training loss 0.59921277 -- Validation loss:0.58518547 -- Test loss 0.5907768\n",
      "Epoch 90: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 91: -- Training loss 0.59479284 -- Validation loss:0.580047 -- Test loss 0.58618647\n",
      "Epoch 91: -- Training acc  0.6901408450704225 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 92: -- Training loss 0.5905208 -- Validation loss:0.57508045 -- Test loss 0.58176017\n",
      "Epoch 92: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.64\n",
      "Epoch 93: -- Training loss 0.5863914 -- Validation loss:0.5702799 -- Test loss 0.5774929\n",
      "Epoch 93: -- Training acc  0.6901408450704225 -- Validation acc: 0.7083333333333334 -- Test acc  0.64\n",
      "Epoch 94: -- Training loss 0.5823993 -- Validation loss:0.5656392 -- Test loss 0.57337874\n",
      "Epoch 94: -- Training acc  0.704225352112676 -- Validation acc: 0.7083333333333334 -- Test acc  0.64\n",
      "Epoch 95: -- Training loss 0.5785394 -- Validation loss:0.5611519 -- Test loss 0.56941146\n",
      "Epoch 95: -- Training acc  0.704225352112676 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 96: -- Training loss 0.57480586 -- Validation loss:0.55681175 -- Test loss 0.56558496\n",
      "Epoch 96: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 97: -- Training loss 0.57119334 -- Validation loss:0.5526125 -- Test loss 0.56189257\n",
      "Epoch 97: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 98: -- Training loss 0.56769633 -- Validation loss:0.548548 -- Test loss 0.55832803\n",
      "Epoch 98: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 99: -- Training loss 0.56430954 -- Validation loss:0.5446128 -- Test loss 0.5548854\n",
      "Epoch 99: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 100: -- Training loss 0.5610271 -- Validation loss:0.5408019 -- Test loss 0.5515586\n",
      "Epoch 100: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 101: -- Training loss 0.55784404 -- Validation loss:0.5371099 -- Test loss 0.5483422\n",
      "Epoch 101: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 102: -- Training loss 0.55475473 -- Validation loss:0.5335324 -- Test loss 0.54523087\n",
      "Epoch 102: -- Training acc  0.7183098591549296 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 103: -- Training loss 0.55175424 -- Validation loss:0.530065 -- Test loss 0.5422194\n",
      "Epoch 103: -- Training acc  0.7323943661971831 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 104: -- Training loss 0.54883724 -- Validation loss:0.52670306 -- Test loss 0.53930306\n",
      "Epoch 104: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 105: -- Training loss 0.545999 -- Validation loss:0.5234422 -- Test loss 0.53647697\n",
      "Epoch 105: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 106: -- Training loss 0.5432344 -- Validation loss:0.5202776 -- Test loss 0.53373635\n",
      "Epoch 106: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 107: -- Training loss 0.54053885 -- Validation loss:0.5172045 -- Test loss 0.5310764\n",
      "Epoch 107: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 108: -- Training loss 0.53790784"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Validation loss:0.51421756 -- Test loss 0.52849245\n",
      "Epoch 108: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 109: -- Training loss 0.5353366 -- Validation loss:0.5113116 -- Test loss 0.52597946\n",
      "Epoch 109: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 110: -- Training loss 0.5328212 -- Validation loss:0.5084809 -- Test loss 0.5235326\n",
      "Epoch 110: -- Training acc  0.7887323943661971 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 111: -- Training loss 0.53035736 -- Validation loss:0.5057201 -- Test loss 0.5211474\n",
      "Epoch 111: -- Training acc  0.7887323943661971 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 112: -- Training loss 0.5279409 -- Validation loss:0.5030235 -- Test loss 0.51881886\n",
      "Epoch 112: -- Training acc  0.7887323943661971 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 113: -- Training loss 0.52556837 -- Validation loss:0.50038624 -- Test loss 0.5165426\n",
      "Epoch 113: -- Training acc  0.8028169014084507 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 114: -- Training loss 0.52323574 -- Validation loss:0.49780306 -- Test loss 0.514314\n",
      "Epoch 114: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 115: -- Training loss 0.5209397 -- Validation loss:0.49526978 -- Test loss 0.5121294\n",
      "Epoch 115: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 116: -- Training loss 0.518677 -- Validation loss:0.4927821 -- Test loss 0.50998497\n",
      "Epoch 116: -- Training acc  0.8169014084507042 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 117: -- Training loss 0.516444 -- Validation loss:0.49033666 -- Test loss 0.5078771\n",
      "Epoch 117: -- Training acc  0.8169014084507042 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 118: -- Training loss 0.51423836 -- Validation loss:0.48793018 -- Test loss 0.50580263\n",
      "Epoch 118: -- Training acc  0.8169014084507042 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 119: -- Training loss 0.5120565 -- Validation loss:0.48555994 -- Test loss 0.50375897\n",
      "Epoch 119: -- Training acc  0.8169014084507042 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 120: -- Training loss 0.5098963 -- Validation loss:0.48322347 -- Test loss 0.5017432\n",
      "Epoch 120: -- Training acc  0.8169014084507042 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 121: -- Training loss 0.507755 -- Validation loss:0.48091838 -- Test loss 0.49975297\n",
      "Epoch 121: -- Training acc  0.8309859154929577 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 122: -- Training loss 0.5056302 -- Validation loss:0.4786425 -- Test loss 0.49778596\n",
      "Epoch 122: -- Training acc  0.8309859154929577 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 123: -- Training loss 0.50351965 -- Validation loss:0.47639382 -- Test loss 0.4958399\n",
      "Epoch 123: -- Training acc  0.8309859154929577 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 124: -- Training loss 0.5014215 -- Validation loss:0.47417018 -- Test loss 0.49391267\n",
      "Epoch 124: -- Training acc  0.8309859154929577 -- Validation acc: 0.8333333333333334 -- Test acc  0.76\n",
      "Epoch 125: -- Training loss 0.4993337 -- Validation loss:0.47196937 -- Test loss 0.49200207\n",
      "Epoch 125: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 126: -- Training loss 0.4972545 -- Validation loss:0.4697894 -- Test loss 0.49010617\n",
      "Epoch 126: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 127: -- Training loss 0.49518245 -- Validation loss:0.46762797 -- Test loss 0.48822296\n",
      "Epoch 127: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 128: -- Training loss 0.49311602 -- Validation loss:0.4654831 -- Test loss 0.48635063\n",
      "Epoch 128: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 129: -- Training loss 0.49105388 -- Validation loss:0.4633529 -- Test loss 0.48448727\n",
      "Epoch 129: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 130: -- Training loss 0.488995 -- Validation loss:0.46123537 -- Test loss 0.4826314\n",
      "Epoch 130: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 131: -- Training loss 0.48693815 -- Validation loss:0.45912918 -- Test loss 0.4807814\n",
      "Epoch 131: -- Training acc  0.8309859154929577 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 132: -- Training loss 0.48488277 -- Validation loss:0.45703292 -- Test loss 0.4789363\n",
      "Epoch 132: -- Training acc  0.8450704225352113 -- Validation acc: 0.875 -- Test acc  0.76\n",
      "Epoch 133: -- Training loss 0.4828279 -- Validation loss:0.45494524 -- Test loss 0.4770949\n",
      "Epoch 133: -- Training acc  0.8591549295774648 -- Validation acc: 0.9166666666666666 -- Test acc  0.76\n",
      "Epoch 134: -- Training loss 0.480773 -- Validation loss:0.45286533 -- Test loss 0.47525623\n",
      "Epoch 134: -- Training acc  0.8732394366197183 -- Validation acc: 0.9166666666666666 -- Test acc  0.76\n",
      "Epoch 135: -- Training loss 0.47871754 -- Validation loss:0.4507924 -- Test loss 0.47342002\n",
      "Epoch 135: -- Training acc  0.8732394366197183 -- Validation acc: 0.9166666666666666 -- Test acc  0.76\n",
      "Epoch 136: -- Training loss 0.476661 -- Validation loss:0.4487258 -- Test loss 0.4715851\n",
      "Epoch 136: -- Training acc  0.8732394366197183 -- Validation acc: 0.9583333333333334 -- Test acc  0.76\n",
      "Epoch 137: -- Training loss 0.47460303 -- Validation loss:0.4466649 -- Test loss 0.46975148\n",
      "Epoch 137: -- Training acc  0.8732394366197183 -- Validation acc: 0.9583333333333334 -- Test acc  0.76\n",
      "Epoch 138: -- Training loss 0.4725437 -- Validation loss:0.44460925 -- Test loss 0.4679185\n",
      "Epoch 138: -- Training acc  0.8732394366197183 -- Validation acc: 0.9583333333333334 -- Test acc  0.76\n",
      "Epoch 139: -- Training loss 0.47048253 -- Validation loss:0.4425583 -- Test loss 0.4660857\n",
      "Epoch 139: -- Training acc  0.8732394366197183 -- Validation acc: 0.9583333333333334 -- Test acc  0.8\n",
      "Epoch 140: -- Training loss 0.46841946 -- Validation loss:0.44051144 -- Test loss 0.46425256\n",
      "Epoch 140: -- Training acc  0.8732394366197183 -- Validation acc: 0.9583333333333334 -- Test acc  0.8\n",
      "Epoch 141: -- Training loss 0.4663547 -- Validation loss:0.43846834 -- Test loss 0.46241885\n",
      "Epoch 141: -- Training acc  0.8873239436619719 -- Validation acc: 0.9583333333333334 -- Test acc  0.84\n",
      "Epoch 142: -- Training loss 0.4642881 -- Validation loss:0.4364284 -- Test loss 0.46058398\n",
      "Epoch 142: -- Training acc  0.8873239436619719 -- Validation acc: 0.9583333333333334 -- Test acc  0.84\n",
      "Epoch 143: -- Training loss 0.46221983 -- Validation loss:0.43439117 -- Test loss 0.45874757\n",
      "Epoch 143: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.84\n",
      "Epoch 144: -- Training loss 0.46014985 -- Validation loss:0.43235633 -- Test loss 0.4569093\n",
      "Epoch 144: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.84\n",
      "Epoch 145: -- Training loss 0.45807835 -- Validation loss:0.43032345 -- Test loss 0.4550687\n",
      "Epoch 145: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.84\n",
      "Epoch 146: -- Training loss 0.4560055 -- Validation loss:0.42829248 -- Test loss 0.4532257\n",
      "Epoch 146: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.84\n",
      "Epoch 147: -- Training loss 0.4539315 -- Validation loss:0.4262629 -- Test loss 0.45138037\n",
      "Epoch 147: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 148: -- Training loss 0.45185643 -- Validation loss:0.42423478 -- Test loss 0.44953233\n",
      "Epoch 148: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 149: -- Training loss 0.44978058 -- Validation loss:0.42220783 -- Test loss 0.44768167\n",
      "Epoch 149: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 150: -- Training loss 0.44770393 -- Validation loss:0.42018178 -- Test loss 0.44582817\n",
      "Epoch 150: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 151: -- Training loss 0.44562656 -- Validation loss:0.4181564 -- Test loss 0.44397214\n",
      "Epoch 151: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 152: -- Training loss 0.44354874 -- Validation loss:0.41613087 -- Test loss 0.44211292\n",
      "Epoch 152: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 153: -- Training loss 0.4414704 -- Validation loss:0.4141049 -- Test loss 0.4402504\n",
      "Epoch 153: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 154: -- Training loss 0.43939158 -- Validation loss:0.41207778 -- Test loss 0.4383841\n",
      "Epoch 154: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 155: -- Training loss 0.43731228 -- Validation loss:0.41004884 -- Test loss 0.4365136\n",
      "Epoch 155: -- Training acc  0.9014084507042254 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 156: -- Training loss 0.43523255 -- Validation loss:0.40801728 -- Test loss 0.43463838\n",
      "Epoch 156: -- Training acc  0.9154929577464789 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 157: -- Training loss 0.43315217 -- Validation loss:0.40598235 -- Test loss 0.4327582\n",
      "Epoch 157: -- Training acc  0.9154929577464789 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 158: -- Training loss 0.431071 -- Validation loss:0.4039434 -- Test loss 0.43087247\n",
      "Epoch 158: -- Training acc  0.9154929577464789 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 159: -- Training loss 0.428989 -- Validation loss:0.40189973 -- Test loss 0.42898098\n",
      "Epoch 159: -- Training acc  0.9154929577464789 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 160: -- Training loss 0.4269058 -- Validation loss:0.39985052 -- Test loss 0.42708346\n",
      "Epoch 160: -- Training acc  0.9154929577464789 -- Validation acc: 0.9583333333333334 -- Test acc  0.88\n",
      "Epoch 161: -- Training loss 0.42482132 -- Validation loss:0.3977953 -- Test loss 0.4251794\n",
      "Epoch 161: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154929577464789 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 162: -- Training loss 0.42273518 -- Validation loss:0.39573288 -- Test loss 0.42326862\n",
      "Epoch 162: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 163: -- Training loss 0.42064708 -- Validation loss:0.39366272 -- Test loss 0.4213506\n",
      "Epoch 163: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 164: -- Training loss 0.41855657 -- Validation loss:0.39158392 -- Test loss 0.41942483\n",
      "Epoch 164: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 165: -- Training loss 0.4164634 -- Validation loss:0.38949558 -- Test loss 0.4174905\n",
      "Epoch 165: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 166: -- Training loss 0.4143671 -- Validation loss:0.38739684 -- Test loss 0.41554737\n",
      "Epoch 166: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 167: -- Training loss 0.4122673 -- Validation loss:0.38528678 -- Test loss 0.41359463\n",
      "Epoch 167: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 168: -- Training loss 0.4101635 -- Validation loss:0.3831648 -- Test loss 0.41163173\n",
      "Epoch 168: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 169: -- Training loss 0.40805528 -- Validation loss:0.3810301 -- Test loss 0.40965855\n",
      "Epoch 169: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 170: -- Training loss 0.40594214 -- Validation loss:0.37888214 -- Test loss 0.4076745\n",
      "Epoch 170: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 171: -- Training loss 0.4038236 -- Validation loss:0.37672016 -- Test loss 0.4056792\n",
      "Epoch 171: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 172: -- Training loss 0.4016993 -- Validation loss:0.3745437 -- Test loss 0.4036725\n",
      "Epoch 172: -- Training acc  0.9295774647887324 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 173: -- Training loss 0.39956874 -- Validation loss:0.37235212 -- Test loss 0.4016538\n",
      "Epoch 173: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 174: -- Training loss 0.39743143 -- Validation loss:0.37014508 -- Test loss 0.3996228\n",
      "Epoch 174: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 175: -- Training loss 0.39528707 -- Validation loss:0.36792198 -- Test loss 0.39757904\n",
      "Epoch 175: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 176: -- Training loss 0.3931351 -- Validation loss:0.36568257 -- Test loss 0.39552224\n",
      "Epoch 176: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 177: -- Training loss 0.39097527 -- Validation loss:0.36342624 -- Test loss 0.3934521\n",
      "Epoch 177: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 178: -- Training loss 0.38880712 -- Validation loss:0.36115316 -- Test loss 0.3913681\n",
      "Epoch 178: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 179: -- Training loss 0.3866304 -- Validation loss:0.358863 -- Test loss 0.3892705\n",
      "Epoch 179: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 180: -- Training loss 0.3844449 -- Validation loss:0.35655567 -- Test loss 0.38715893\n",
      "Epoch 180: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 181: -- Training loss 0.38225025 -- Validation loss:0.35423133 -- Test loss 0.38503346\n",
      "Epoch 181: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 182: -- Training loss 0.38004634 -- Validation loss:0.35188997 -- Test loss 0.38289395\n",
      "Epoch 182: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 183: -- Training loss 0.37783298 -- Validation loss:0.34953168 -- Test loss 0.3807404\n",
      "Epoch 183: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 184: -- Training loss 0.37561008 -- Validation loss:0.3471569 -- Test loss 0.37857273\n",
      "Epoch 184: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 185: -- Training loss 0.3733775 -- Validation loss:0.34476563 -- Test loss 0.376391\n",
      "Epoch 185: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 186: -- Training loss 0.37113535 -- Validation loss:0.34235838 -- Test loss 0.3741952\n",
      "Epoch 186: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 187: -- Training loss 0.36888364 -- Validation loss:0.3399355 -- Test loss 0.37198547\n",
      "Epoch 187: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 188: -- Training loss 0.36662236 -- Validation loss:0.33749762 -- Test loss 0.36976206\n",
      "Epoch 188: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 189: -- Training loss 0.36435178 -- Validation loss:0.33504525 -- Test loss 0.3675252\n",
      "Epoch 189: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 190: -- Training loss 0.362072 -- Validation loss:0.33257908 -- Test loss 0.3652751\n",
      "Epoch 190: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 191: -- Training loss 0.3597833 -- Validation loss:0.33009973 -- Test loss 0.3630122\n",
      "Epoch 191: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 192: -- Training loss 0.35748583 -- Validation loss:0.32760796 -- Test loss 0.36073688\n",
      "Epoch 192: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 193: -- Training loss 0.35518014 -- Validation loss:0.3251045 -- Test loss 0.35844922\n",
      "Epoch 193: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 194: -- Training loss 0.3528665 -- Validation loss:0.3225902 -- Test loss 0.3561497\n",
      "Epoch 194: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 195: -- Training loss 0.35054523 -- Validation loss:0.32006598 -- Test loss 0.35383883\n",
      "Epoch 195: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 196: -- Training loss 0.34821692 -- Validation loss:0.31753254 -- Test loss 0.351517\n",
      "Epoch 196: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 197: -- Training loss 0.3458819 -- Validation loss:0.3149909 -- Test loss 0.3491846\n",
      "Epoch 197: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 198: -- Training loss 0.34354088 -- Validation loss:0.31244197 -- Test loss 0.34684232\n",
      "Epoch 198: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 199: -- Training loss 0.34119427 -- Validation loss:0.3098867 -- Test loss 0.3444907\n",
      "Epoch 199: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 200: -- Training loss 0.33884257 -- Validation loss:0.307326 -- Test loss 0.3421302\n",
      "Epoch 200: -- Training acc  0.9436619718309859 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 201: -- Training loss 0.33648664 -- Validation loss:0.30476084 -- Test loss 0.3397615\n",
      "Epoch 201: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 202: -- Training loss 0.33412674 -- Validation loss:0.30219218 -- Test loss 0.33738503\n",
      "Epoch 202: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 203: -- Training loss 0.3317638 -- Validation loss:0.29962078 -- Test loss 0.33500153\n",
      "Epoch 203: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 204: -- Training loss 0.32939833 -- Validation loss:0.2970478 -- Test loss 0.33261162\n",
      "Epoch 204: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 205: -- Training loss 0.327031 -- Validation loss:0.2944739 -- Test loss 0.33021575\n",
      "Epoch 205: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 206: -- Training loss 0.32466248 -- Validation loss:0.2919002 -- Test loss 0.32781482\n",
      "Epoch 206: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 207: -- Training loss 0.32229352 -- Validation loss:0.2893275 -- Test loss 0.32540944\n",
      "Epoch 207: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 208: -- Training loss 0.31992465 -- Validation loss:0.28675663 -- Test loss 0.32300025\n",
      "Epoch 208: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 209: -- Training loss 0.31755674 -- Validation loss:0.28418848 -- Test loss 0.32058793\n",
      "Epoch 209: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 210: -- Training loss 0.3151903 -- Validation loss:0.2816239 -- Test loss 0.31817323\n",
      "Epoch 210: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 211: -- Training loss 0.31282607 -- Validation loss:0.27906355 -- Test loss 0.31575677\n",
      "Epoch 211: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 212: -- Training loss 0.3104647 -- Validation loss:0.2765084 -- Test loss 0.3133392\n",
      "Epoch 212: -- Training acc  0.9436619718309859 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 213: -- Training loss 0.308107 -- Validation loss:0.27395907 -- Test loss 0.3109213\n",
      "Epoch 213: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 214: -- Training loss 0.30575344 -- Validation loss:0.2714164 -- Test loss 0.30850378\n",
      "Epoch 214: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 215: -- Training loss 0.30340478 -- Validation loss:0.26888105"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Test loss 0.30608723\n",
      "Epoch 215: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 216: -- Training loss 0.3010616 -- Validation loss:0.26635376 -- Test loss 0.3036725\n",
      "Epoch 216: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 217: -- Training loss 0.2987246 -- Validation loss:0.26383525 -- Test loss 0.30126026\n",
      "Epoch 217: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 218: -- Training loss 0.29639423 -- Validation loss:0.26132616 -- Test loss 0.2988511\n",
      "Epoch 218: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 219: -- Training loss 0.29407135 -- Validation loss:0.25882718 -- Test loss 0.29644576\n",
      "Epoch 219: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 220: -- Training loss 0.29175624 -- Validation loss:0.25633886 -- Test loss 0.2940448\n",
      "Epoch 220: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 221: -- Training loss 0.28944972 -- Validation loss:0.253862 -- Test loss 0.29164895\n",
      "Epoch 221: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 222: -- Training loss 0.28715217 -- Validation loss:0.25139698 -- Test loss 0.2892589\n",
      "Epoch 222: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 223: -- Training loss 0.28486422 -- Validation loss:0.24894463 -- Test loss 0.28687507\n",
      "Epoch 223: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 224: -- Training loss 0.28258634 -- Validation loss:0.24650533 -- Test loss 0.28449833\n",
      "Epoch 224: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 225: -- Training loss 0.280319 -- Validation loss:0.24407981 -- Test loss 0.2821291\n",
      "Epoch 225: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 226: -- Training loss 0.27806267 -- Validation loss:0.24166846 -- Test loss 0.2797681\n",
      "Epoch 226: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 227: -- Training loss 0.2758179 -- Validation loss:0.23927188 -- Test loss 0.27741572\n",
      "Epoch 227: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 228: -- Training loss 0.27358508 -- Validation loss:0.23689054 -- Test loss 0.2750727\n",
      "Epoch 228: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 229: -- Training loss 0.2713646 -- Validation loss:0.23452498 -- Test loss 0.2727393\n",
      "Epoch 229: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 230: -- Training loss 0.26915684 -- Validation loss:0.23217557 -- Test loss 0.2704163\n",
      "Epoch 230: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 231: -- Training loss 0.2669622 -- Validation loss:0.22984284 -- Test loss 0.26810393\n",
      "Epoch 231: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 232: -- Training loss 0.26478118 -- Validation loss:0.22752719 -- Test loss 0.26580292\n",
      "Epoch 232: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 233: -- Training loss 0.26261395 -- Validation loss:0.22522897 -- Test loss 0.2635136\n",
      "Epoch 233: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 234: -- Training loss 0.2604609 -- Validation loss:0.22294863 -- Test loss 0.26123637\n",
      "Epoch 234: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 235: -- Training loss 0.25832233 -- Validation loss:0.22068645 -- Test loss 0.25897172\n",
      "Epoch 235: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 236: -- Training loss 0.2561986 -- Validation loss:0.21844292 -- Test loss 0.2567199\n",
      "Epoch 236: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 237: -- Training loss 0.25408995 -- Validation loss:0.21621819 -- Test loss 0.25448143\n",
      "Epoch 237: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 238: -- Training loss 0.2519966 -- Validation loss:0.21401267 -- Test loss 0.25225672\n",
      "Epoch 238: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 239: -- Training loss 0.24991886 -- Validation loss:0.2118265 -- Test loss 0.250046\n",
      "Epoch 239: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 240: -- Training loss 0.24785694 -- Validation loss:0.20966007 -- Test loss 0.24784961\n",
      "Epoch 240: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 241: -- Training loss 0.24581103 -- Validation loss:0.20751347 -- Test loss 0.24566793\n",
      "Epoch 241: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 242: -- Training loss 0.24378143 -- Validation loss:0.20538704 -- Test loss 0.24350123\n",
      "Epoch 242: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 243: -- Training loss 0.24176821 -- Validation loss:0.20328094 -- Test loss 0.24134971\n",
      "Epoch 243: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 244: -- Training loss 0.23977153 -- Validation loss:0.20119528 -- Test loss 0.23921369\n",
      "Epoch 244: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 245: -- Training loss 0.2377916 -- Validation loss:0.19913024 -- Test loss 0.23709343\n",
      "Epoch 245: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 246: -- Training loss 0.23582861 -- Validation loss:0.19708599 -- Test loss 0.2349891\n",
      "Epoch 246: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 247: -- Training loss 0.23388264 -- Validation loss:0.19506264 -- Test loss 0.23290105\n",
      "Epoch 247: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.92\n",
      "Epoch 248: -- Training loss 0.2319538 -- Validation loss:0.19306022 -- Test loss 0.23082939\n",
      "Epoch 248: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 249: -- Training loss 0.2300421 -- Validation loss:0.19107895 -- Test loss 0.22877428\n",
      "Epoch 249: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 250: -- Training loss 0.22814785 -- Validation loss:0.18911873 -- Test loss 0.22673601\n",
      "Epoch 250: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 251: -- Training loss 0.22627097 -- Validation loss:0.18717973 -- Test loss 0.22471456\n",
      "Epoch 251: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 252: -- Training loss 0.22441156 -- Validation loss:0.18526196 -- Test loss 0.22271022\n",
      "Epoch 252: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 253: -- Training loss 0.2225697 -- Validation loss:0.18336542 -- Test loss 0.22072308\n",
      "Epoch 253: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 254: -- Training loss 0.2207454 -- Validation loss:0.18149018 -- Test loss 0.21875326\n",
      "Epoch 254: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 255: -- Training loss 0.21893871 -- Validation loss:0.17963624 -- Test loss 0.21680091\n",
      "Epoch 255: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 256: -- Training loss 0.21714966 -- Validation loss:0.1778035 -- Test loss 0.21486598\n",
      "Epoch 256: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 257: -- Training loss 0.21537825 -- Validation loss:0.17599191 -- Test loss 0.21294872\n",
      "Epoch 257: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 258: -- Training loss 0.21362449 -- Validation loss:0.17420161 -- Test loss 0.2110491\n",
      "Epoch 258: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 259: -- Training loss 0.21188839 -- Validation loss:0.17243238 -- Test loss 0.20916723\n",
      "Epoch 259: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 260: -- Training loss 0.21016988 -- Validation loss:0.17068426 -- Test loss 0.2073032\n",
      "Epoch 260: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 261: -- Training loss 0.20846902 -- Validation loss:0.16895707 -- Test loss 0.20545694\n",
      "Epoch 261: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 262: -- Training loss 0.2067857 -- Validation loss:0.16725081 -- Test loss 0.20362848\n",
      "Epoch 262: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 263: -- Training loss 0.20511995 -- Validation loss:0.1655654 -- Test loss 0.20181793\n",
      "Epoch 263: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 264: -- Training loss 0.2034716 -- Validation loss:0.1639006 -- Test loss 0.20002523\n",
      "Epoch 264: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 265: -- Training loss 0.20184077 -- Validation loss:0.16225645 -- Test loss 0.1982505\n",
      "Epoch 265: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 266: -- Training loss 0.20022728 -- Validation loss:0.1606328 -- Test loss 0.19649369\n",
      "Epoch 266: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 267: -- Training loss 0.19863111 -- Validation loss:0.15902945 -- Test loss 0.1947546\n",
      "Epoch 267: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 268: -- Training loss 0.19705214 -- Validation loss:0.15744631 -- Test loss 0.19303337\n",
      "Epoch 268: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 269: -- Training loss 0.19549032 -- Validation loss:0.15588321 -- Test loss 0.19133\n",
      "Epoch 269: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 270: -- Training loss 0.1939456 -- Validation loss:0.15434006 -- Test loss 0.18964438\n",
      "Epoch 270: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 271: -- Training loss 0.19241783 -- Validation loss:0.15281658 -- Test loss 0.18797645\n",
      "Epoch 271: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 272: -- Training loss 0.19090694 -- Validation loss:0.1513127 -- Test loss 0.1863263\n",
      "Epoch 272: -- Training acc  0.971830985915493"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 273: -- Training loss 0.18941283 -- Validation loss:0.14982823 -- Test loss 0.18469377\n",
      "Epoch 273: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 274: -- Training loss 0.1879354 -- Validation loss:0.14836298 -- Test loss 0.18307872\n",
      "Epoch 274: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 275: -- Training loss 0.18647455 -- Validation loss:0.1469168 -- Test loss 0.18148121\n",
      "Epoch 275: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 276: -- Training loss 0.18503012 -- Validation loss:0.14548944 -- Test loss 0.17990114\n",
      "Epoch 276: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 277: -- Training loss 0.18360204 -- Validation loss:0.14408074 -- Test loss 0.17833838\n",
      "Epoch 277: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 278: -- Training loss 0.18219018 -- Validation loss:0.14269052 -- Test loss 0.17679298\n",
      "Epoch 278: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 279: -- Training loss 0.18079443 -- Validation loss:0.14131857 -- Test loss 0.17526472\n",
      "Epoch 279: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 280: -- Training loss 0.17941467 -- Validation loss:0.13996471 -- Test loss 0.1737536\n",
      "Epoch 280: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 281: -- Training loss 0.17805073 -- Validation loss:0.13862868 -- Test loss 0.17225946\n",
      "Epoch 281: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 282: -- Training loss 0.17670254 -- Validation loss:0.1373104 -- Test loss 0.17078221\n",
      "Epoch 282: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 283: -- Training loss 0.17536989 -- Validation loss:0.13600956 -- Test loss 0.16932173\n",
      "Epoch 283: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 284: -- Training loss 0.17405272 -- Validation loss:0.13472594 -- Test loss 0.16787808\n",
      "Epoch 284: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 285: -- Training loss 0.17275088 -- Validation loss:0.13345936 -- Test loss 0.16645107\n",
      "Epoch 285: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 286: -- Training loss 0.17146417 -- Validation loss:0.13220967 -- Test loss 0.16504055\n",
      "Epoch 286: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 287: -- Training loss 0.17019254 -- Validation loss:0.13097659 -- Test loss 0.16364643\n",
      "Epoch 287: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 288: -- Training loss 0.1689358 -- Validation loss:0.12975992 -- Test loss 0.1622685\n",
      "Epoch 288: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 289: -- Training loss 0.16769384 -- Validation loss:0.12855946 -- Test loss 0.16090675\n",
      "Epoch 289: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 290: -- Training loss 0.16646649 -- Validation loss:0.12737498 -- Test loss 0.1595611\n",
      "Epoch 290: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 291: -- Training loss 0.16525364 -- Validation loss:0.12620628 -- Test loss 0.15823147\n",
      "Epoch 291: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 292: -- Training loss 0.16405506 -- Validation loss:0.12505318 -- Test loss 0.15691766\n",
      "Epoch 292: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 293: -- Training loss 0.16287072 -- Validation loss:0.123915434 -- Test loss 0.15561956\n",
      "Epoch 293: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 294: -- Training loss 0.16170038 -- Validation loss:0.12279286 -- Test loss 0.15433699\n",
      "Epoch 294: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 295: -- Training loss 0.16054401 -- Validation loss:0.12168523 -- Test loss 0.15306982\n",
      "Epoch 295: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 296: -- Training loss 0.15940134 -- Validation loss:0.120592356 -- Test loss 0.15181799\n",
      "Epoch 296: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 297: -- Training loss 0.15827227 -- Validation loss:0.119513996 -- Test loss 0.15058145\n",
      "Epoch 297: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 298: -- Training loss 0.1571567 -- Validation loss:0.11844998 -- Test loss 0.14936006\n",
      "Epoch 298: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 299: -- Training loss 0.15605444 -- Validation loss:0.11740006 -- Test loss 0.14815356\n",
      "Epoch 299: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 300: -- Training loss 0.15496534 -- Validation loss:0.11636409 -- Test loss 0.14696184\n",
      "Epoch 300: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 301: -- Training loss 0.15388931 -- Validation loss:0.115341894 -- Test loss 0.14578487\n",
      "Epoch 301: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 302: -- Training loss 0.15282616 -- Validation loss:0.114333205 -- Test loss 0.14462239\n",
      "Epoch 302: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 303: -- Training loss 0.1517757 -- Validation loss:0.11333782 -- Test loss 0.1434744\n",
      "Epoch 303: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 304: -- Training loss 0.15073787 -- Validation loss:0.11235557 -- Test loss 0.14234075\n",
      "Epoch 304: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 305: -- Training loss 0.1497125 -- Validation loss:0.11138627 -- Test loss 0.14122124\n",
      "Epoch 305: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 306: -- Training loss 0.14869942 -- Validation loss:0.11042974 -- Test loss 0.14011581\n",
      "Epoch 306: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 307: -- Training loss 0.14769857 -- Validation loss:0.10948577 -- Test loss 0.13902421\n",
      "Epoch 307: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 308: -- Training loss 0.14670965 -- Validation loss:0.108554214 -- Test loss 0.13794641\n",
      "Epoch 308: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 309: -- Training loss 0.14573269 -- Validation loss:0.10763479 -- Test loss 0.13688225\n",
      "Epoch 309: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 310: -- Training loss 0.14476743 -- Validation loss:0.106727414 -- Test loss 0.13583165\n",
      "Epoch 310: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 311: -- Training loss 0.14381385 -- Validation loss:0.10583186 -- Test loss 0.13479435\n",
      "Epoch 311: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 312: -- Training loss 0.14287165 -- Validation loss:0.10494801 -- Test loss 0.13377036\n",
      "Epoch 312: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 313: -- Training loss 0.14194083 -- Validation loss:0.10407559 -- Test loss 0.13275938\n",
      "Epoch 313: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 314: -- Training loss 0.14102119 -- Validation loss:0.1032145 -- Test loss 0.13176143\n",
      "Epoch 314: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 315: -- Training loss 0.14011256 -- Validation loss:0.10236452 -- Test loss 0.13077632\n",
      "Epoch 315: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 316: -- Training loss 0.13921487 -- Validation loss:0.10152551 -- Test loss 0.12980394\n",
      "Epoch 316: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 317: -- Training loss 0.13832799 -- Validation loss:0.10069736 -- Test loss 0.12884402\n",
      "Epoch 317: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 318: -- Training loss 0.13745178 -- Validation loss:0.099879794 -- Test loss 0.12789665\n",
      "Epoch 318: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 319: -- Training loss 0.13658603 -- Validation loss:0.09907276 -- Test loss 0.12696156\n",
      "Epoch 319: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 320: -- Training loss 0.13573067 -- Validation loss:0.09827599 -- Test loss 0.12603855\n",
      "Epoch 320: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 321: -- Training loss 0.13488555 -- Validation loss:0.097489394 -- Test loss 0.12512767\n",
      "Epoch 321: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 322: -- Training loss 0.13405053 -- Validation loss:0.09671285 -- Test loss 0.12422866\n",
      "Epoch 322: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 323: -- Training loss 0.13322552 -- Validation loss:0.09594616 -- Test loss 0.12334147\n",
      "Epoch 323: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 324: -- Training loss 0.13241039 -- Validation loss:0.09518918 -- Test loss 0.12246583\n",
      "Epoch 324: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 325: -- Training loss 0.13160494 -- Validation loss:0.09444178 -- Test loss 0.12160171\n",
      "Epoch 325: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 326: -- Training loss 0.13080914 -- Validation loss:0.093703784 -- Test loss 0.120749004\n",
      "Epoch 326: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 327: -- Training loss 0.13002273 -- Validation loss:0.09297508 -- Test loss 0.11990757\n",
      "Epoch 327: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 328: -- Training loss 0.12924574 -- Validation loss:0.092255495 -- Test loss 0.119077235\n",
      "Epoch 328: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 329: -- Training loss 0.12847796 -- Validation loss:0.091544904 -- Test loss 0.118257925\n",
      "Epoch 329: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 330: -- Training loss 0.12771925 -- Validation loss:0.09084326 -- Test loss 0.11744941\n",
      "Epoch 330: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 331: -- Training loss 0.12696953 -- Validation loss:0.0901503 -- Test loss 0.11665163\n",
      "Epoch 331: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 332: -- Training loss 0.12622866 -- Validation loss:0.08946595 -- Test loss 0.115864486\n",
      "Epoch 332: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 333: -- Training loss 0.12549649 -- Validation loss:0.08879009 -- Test loss 0.115087815\n",
      "Epoch 333: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 334: -- Training loss 0.12477294 -- Validation loss:0.08812258 -- Test loss 0.114321545\n",
      "Epoch 334: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 335: -- Training loss 0.12405789 -- Validation loss:0.08746331 -- Test loss 0.11356551\n",
      "Epoch 335: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 336: -- Training loss 0.12335123 -- Validation loss:0.086812146 -- Test loss 0.11281946\n",
      "Epoch 336: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 337: -- Training loss 0.12265278 -- Validation loss:0.086169004 -- Test loss 0.112083405\n",
      "Epoch 337: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 338: -- Training loss 0.12196248 -- Validation loss:0.08553371 -- Test loss 0.11135732\n",
      "Epoch 338: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 339: -- Training loss 0.1212802 -- Validation loss:0.08490618 -- Test loss 0.110640906\n",
      "Epoch 339: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 340: -- Training loss 0.12060582 -- Validation loss:0.084286265 -- Test loss 0.10993416\n",
      "Epoch 340: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 341: -- Training loss 0.11993922 -- Validation loss:0.08367389 -- Test loss 0.10923685\n",
      "Epoch 341: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 342: -- Training loss 0.119280346 -- Validation loss:0.08306897 -- Test loss 0.1085489\n",
      "Epoch 342: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 343: -- Training loss 0.11862894 -- Validation loss:0.08247136 -- Test loss 0.10787018\n",
      "Epoch 343: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 344: -- Training loss 0.11798508 -- Validation loss:0.08188098 -- Test loss 0.10720067\n",
      "Epoch 344: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 345: -- Training loss 0.11734851 -- Validation loss:0.08129767 -- Test loss 0.106540166\n",
      "Epoch 345: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 346: -- Training loss 0.116719246 -- Validation loss:0.08072137 -- Test loss 0.10588858\n",
      "Epoch 346: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 347: -- Training loss 0.11609706 -- Validation loss:0.080151975 -- Test loss 0.10524576\n",
      "Epoch 347: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 348: -- Training loss 0.1154819 -- Validation loss:0.07958942 -- Test loss 0.104611605\n",
      "Epoch 348: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 349: -- Training loss 0.114873655 -- Validation loss:0.07903356 -- Test loss 0.10398598\n",
      "Epoch 349: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 350: -- Training loss 0.11427222 -- Validation loss:0.0784843 -- Test loss 0.103368856\n",
      "Epoch 350: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 351: -- Training loss 0.113677524 -- Validation loss:0.07794161 -- Test loss 0.10276001\n",
      "Epoch 351: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 352: -- Training loss 0.11308943 -- Validation loss:0.077405274 -- Test loss 0.10215948\n",
      "Epoch 352: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 353: -- Training loss 0.11250781 -- Validation loss:0.07687535 -- Test loss 0.101566926\n",
      "Epoch 353: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 354: -- Training loss 0.111932665 -- Validation loss:0.07635162 -- Test loss 0.10098242\n",
      "Epoch 354: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 355: -- Training loss 0.11136378 -- Validation loss:0.075834066 -- Test loss 0.10040583\n",
      "Epoch 355: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 356: -- Training loss 0.110801145 -- Validation loss:0.075322606 -- Test loss 0.09983699\n",
      "Epoch 356: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 357: -- Training loss 0.1102446 -- Validation loss:0.07481711 -- Test loss 0.09927583\n",
      "Epoch 357: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 358: -- Training loss 0.109694086 -- Validation loss:0.07431755 -- Test loss 0.09872229\n",
      "Epoch 358: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 359: -- Training loss 0.10914951 -- Validation loss:0.07382377 -- Test loss 0.09817614\n",
      "Epoch 359: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 360: -- Training loss 0.10861079 -- Validation loss:0.073335774 -- Test loss 0.097637355\n",
      "Epoch 360: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 361: -- Training loss 0.10807777 -- Validation loss:0.07285343 -- Test loss 0.09710584\n",
      "Epoch 361: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 362: -- Training loss 0.107550465 -- Validation loss:0.07237667 -- Test loss 0.09658146\n",
      "Epoch 362: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 363: -- Training loss 0.10702872 -- Validation loss:0.07190541 -- Test loss 0.0960641\n",
      "Epoch 363: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 364: -- Training loss 0.10651244 -- Validation loss:0.0714396 -- Test loss 0.09555373\n",
      "Epoch 364: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 365: -- Training loss 0.106001586 -- Validation loss:0.07097911 -- Test loss 0.09505026\n",
      "Epoch 365: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 366: -- Training loss 0.105496034 -- Validation loss:0.07052393 -- Test loss 0.09455343\n",
      "Epoch 366: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 367: -- Training loss 0.10499572 -- Validation loss:0.070073985 -- Test loss 0.09406326\n",
      "Epoch 367: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 368: -- Training loss 0.104500584 -- Validation loss:0.06962912 -- Test loss 0.09357973\n",
      "Epoch 368: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 369: -- Training loss 0.10401047 -- Validation loss:0.06918935 -- Test loss 0.09310257\n",
      "Epoch 369: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 370: -- Training loss 0.10352538 -- Validation loss:0.068754576 -- Test loss 0.09263177\n",
      "Epoch 370: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 371: -- Training loss 0.103045195 -- Validation loss:0.06832469 -- Test loss 0.09216729\n",
      "Epoch 371: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 372: -- Training loss 0.10256985 -- Validation loss:0.06789973 -- Test loss 0.091708966\n",
      "Epoch 372: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 373: -- Training loss 0.10209925 -- Validation loss:0.06747954 -- Test loss 0.09125669\n",
      "Epoch 373: -- Training acc  0.9577464788732394 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 374: -- Training loss 0.10163338 -- Validation loss:0.0670641 -- Test loss 0.09081043\n",
      "Epoch 374: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 375: -- Training loss 0.10117208 -- Validation loss:0.06665327 -- Test loss 0.09037003\n",
      "Epoch 375: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 376: -- Training loss 0.10071534 -- Validation loss:0.06624706 -- Test loss 0.089935474\n",
      "Epoch 376: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 377: -- Training loss 0.100263104 -- Validation loss:0.06584539 -- Test loss 0.089506656\n",
      "Epoch 377: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 378: -- Training loss 0.09981522 -- Validation loss:0.0654482 -- Test loss 0.089083426\n",
      "Epoch 378: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 379: -- Training loss 0.09937167 -- Validation loss:0.06505539 -- Test loss 0.08866569\n",
      "Epoch 379: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 380: -- Training loss 0.09893244 -- Validation loss:0.06466694 -- Test loss 0.088253506\n",
      "Epoch 380: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 381: -- Training loss 0.0984974 -- Validation loss:0.0642828 -- Test loss 0.08784672\n",
      "Epoch 381: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 382: -- Training loss 0.09806647 -- Validation loss:0.06390286 -- Test loss 0.08744513\n",
      "Epoch 382: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 383: -- Training loss 0.09763965 -- Validation loss:0.06352714 -- Test loss 0.0870488\n",
      "Epoch 383: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 384: -- Training loss 0.09721683 -- Validation loss:0.0631555 -- Test loss 0.08665762\n",
      "Epoch 384: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 385: -- Training loss 0.09679794 -- Validation loss:0.06278791 -- Test loss 0.08627146\n",
      "Epoch 385: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 386: -- Training loss 0.09638296 -- Validation loss:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06242435 -- Test loss 0.085890315\n",
      "Epoch 386: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 387: -- Training loss 0.095971815 -- Validation loss:0.062064704 -- Test loss 0.08551398\n",
      "Epoch 387: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 388: -- Training loss 0.09556445 -- Validation loss:0.061708983 -- Test loss 0.085142516\n",
      "Epoch 388: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 389: -- Training loss 0.0951608 -- Validation loss:0.06135711 -- Test loss 0.08477578\n",
      "Epoch 389: -- Training acc  0.971830985915493 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 390: -- Training loss 0.094760805 -- Validation loss:0.06100899 -- Test loss 0.08441373\n",
      "Epoch 390: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 391: -- Training loss 0.09436446 -- Validation loss:0.06066461 -- Test loss 0.08405627\n",
      "Epoch 391: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 392: -- Training loss 0.093971625 -- Validation loss:0.060323875 -- Test loss 0.08370335\n",
      "Epoch 392: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 393: -- Training loss 0.0935823 -- Validation loss:0.05998683 -- Test loss 0.083354816\n",
      "Epoch 393: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 394: -- Training loss 0.09319643 -- Validation loss:0.059653368 -- Test loss 0.08301064\n",
      "Epoch 394: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 395: -- Training loss 0.09281398 -- Validation loss:0.05932338 -- Test loss 0.08267089\n",
      "Epoch 395: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 396: -- Training loss 0.09243485 -- Validation loss:0.058996897 -- Test loss 0.082335345\n",
      "Epoch 396: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 397: -- Training loss 0.092059046 -- Validation loss:0.058673877 -- Test loss 0.08200391\n",
      "Epoch 397: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 398: -- Training loss 0.091686495 -- Validation loss:0.058354218 -- Test loss 0.08167662\n",
      "Epoch 398: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 399: -- Training loss 0.09131715 -- Validation loss:0.058037907 -- Test loss 0.08135334\n",
      "Epoch 399: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 400: -- Training loss 0.090950936 -- Validation loss:0.057724904 -- Test loss 0.08103408\n",
      "Epoch 400: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 401: -- Training loss 0.09058787 -- Validation loss:0.057415128 -- Test loss 0.08071875\n",
      "Epoch 401: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 402: -- Training loss 0.090227894 -- Validation loss:0.057108525 -- Test loss 0.08040729\n",
      "Epoch 402: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 403: -- Training loss 0.089870915 -- Validation loss:0.056805145 -- Test loss 0.08009961\n",
      "Epoch 403: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 404: -- Training loss 0.08951693 -- Validation loss:0.056504834 -- Test loss 0.079795636\n",
      "Epoch 404: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 405: -- Training loss 0.08916587 -- Validation loss:0.056207597 -- Test loss 0.07949537\n",
      "Epoch 405: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 406: -- Training loss 0.08881772 -- Validation loss:0.055913392 -- Test loss 0.079198696\n",
      "Epoch 406: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 407: -- Training loss 0.08847245 -- Validation loss:0.055622164 -- Test loss 0.07890562\n",
      "Epoch 407: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 408: -- Training loss 0.08812998 -- Validation loss:0.055333916 -- Test loss 0.078616016\n",
      "Epoch 408: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 409: -- Training loss 0.087790325 -- Validation loss:0.055048596 -- Test loss 0.078329846\n",
      "Epoch 409: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 410: -- Training loss 0.08745338 -- Validation loss:0.054766063 -- Test loss 0.07804714\n",
      "Epoch 410: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 411: -- Training loss 0.087119184 -- Validation loss:0.05448641 -- Test loss 0.07776776\n",
      "Epoch 411: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 412: -- Training loss 0.08678764 -- Validation loss:0.054209497 -- Test loss 0.077491745\n",
      "Epoch 412: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 413: -- Training loss 0.086458735 -- Validation loss:0.053935364 -- Test loss 0.07721888\n",
      "Epoch 413: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 414: -- Training loss 0.08613238 -- Validation loss:0.053663958 -- Test loss 0.07694921\n",
      "Epoch 414: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 415: -- Training loss 0.08580865 -- Validation loss:0.053395223 -- Test loss 0.076682694\n",
      "Epoch 415: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 416: -- Training loss 0.08548745 -- Validation loss:0.053129073 -- Test loss 0.076419406\n",
      "Epoch 416: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 417: -- Training loss 0.08516872 -- Validation loss:0.05286557 -- Test loss 0.07615906\n",
      "Epoch 417: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 418: -- Training loss 0.08485246 -- Validation loss:0.052604634 -- Test loss 0.0759017\n",
      "Epoch 418: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 419: -- Training loss 0.08453862 -- Validation loss:0.05234621 -- Test loss 0.07564731\n",
      "Epoch 419: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 420: -- Training loss 0.08422719 -- Validation loss:0.052090306 -- Test loss 0.075395904\n",
      "Epoch 420: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 421: -- Training loss 0.08391813 -- Validation loss:0.051836822 -- Test loss 0.07514737\n",
      "Epoch 421: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 422: -- Training loss 0.083611414 -- Validation loss:0.051585782 -- Test loss 0.07490167\n",
      "Epoch 422: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 423: -- Training loss 0.083307005 -- Validation loss:0.051337186 -- Test loss 0.074658655\n",
      "Epoch 423: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 424: -- Training loss 0.08300487 -- Validation loss:0.0510909 -- Test loss 0.07441849\n",
      "Epoch 424: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 425: -- Training loss 0.08270499 -- Validation loss:0.050846968 -- Test loss 0.07418105\n",
      "Epoch 425: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 426: -- Training loss 0.08240732 -- Validation loss:0.050605316 -- Test loss 0.0739463\n",
      "Epoch 426: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 427: -- Training loss 0.082111865 -- Validation loss:0.05036595 -- Test loss 0.073714204\n",
      "Epoch 427: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 428: -- Training loss 0.081818536 -- Validation loss:0.050128836 -- Test loss 0.073484555\n",
      "Epoch 428: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 429: -- Training loss 0.08152737 -- Validation loss:0.04989393 -- Test loss 0.07325759\n",
      "Epoch 429: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 430: -- Training loss 0.08123833 -- Validation loss:0.04966117 -- Test loss 0.073033184\n",
      "Epoch 430: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 431: -- Training loss 0.080951355 -- Validation loss:0.049430545 -- Test loss 0.072811216\n",
      "Epoch 431: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 432: -- Training loss 0.08066646 -- Validation loss:0.049202085 -- Test loss 0.07259176\n",
      "Epoch 432: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 433: -- Training loss 0.08038356 -- Validation loss:0.048975717 -- Test loss 0.07237459\n",
      "Epoch 433: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 434: -- Training loss 0.080102704 -- Validation loss:0.04875141 -- Test loss 0.072159976\n",
      "Epoch 434: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 435: -- Training loss 0.07982381 -- Validation loss:0.048529122 -- Test loss 0.07194763\n",
      "Epoch 435: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436: -- Training loss 0.07954689 -- Validation loss:0.048308868 -- Test loss 0.07173765\n",
      "Epoch 436: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 437: -- Training loss 0.079271905 -- Validation loss:0.04809059 -- Test loss 0.07152993\n",
      "Epoch 437: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 438: -- Training loss 0.078998834 -- Validation loss:0.047874287 -- Test loss 0.07132446\n",
      "Epoch 438: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 439: -- Training loss 0.07872764 -- Validation loss:0.047659915 -- Test loss 0.07112126\n",
      "Epoch 439: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 440: -- Training loss 0.078458354 -- Validation loss:0.047447428 -- Test loss 0.07092034\n",
      "Epoch 440: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 441: -- Training loss 0.07819091 -- Validation loss:0.047236815 -- Test loss 0.07072152\n",
      "Epoch 441: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 442: -- Training loss 0.07792529 -- Validation loss:0.04702811 -- Test loss 0.07052486\n",
      "Epoch 442: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 443: -- Training loss 0.07766139 -- Validation loss:0.046821225 -- Test loss 0.07033029\n",
      "Epoch 443: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 444: -- Training loss 0.07739936 -- Validation loss:0.04661614 -- Test loss 0.0701379\n",
      "Epoch 444: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 445: -- Training loss 0.07713906 -- Validation loss:0.046412826 -- Test loss 0.06994754\n",
      "Epoch 445: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 446: -- Training loss 0.0768805 -- Validation loss:0.046211332 -- Test loss 0.06975918\n",
      "Epoch 446: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 447: -- Training loss 0.07662368 -- Validation loss:0.046011534 -- Test loss 0.069572866\n",
      "Epoch 447: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 448: -- Training loss 0.07636855 -- Validation loss:0.04581344 -- Test loss 0.06938861\n",
      "Epoch 448: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 449: -- Training loss 0.0761151 -- Validation loss:0.045617063 -- Test loss 0.069206335\n",
      "Epoch 449: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 450: -- Training loss 0.07586332 -- Validation loss:0.04542241 -- Test loss 0.06902592\n",
      "Epoch 450: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 451: -- Training loss 0.07561317 -- Validation loss:0.045229394 -- Test loss 0.06884734\n",
      "Epoch 451: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 452: -- Training loss 0.07536465 -- Validation loss:0.045038003 -- Test loss 0.06867083\n",
      "Epoch 452: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 453: -- Training loss 0.07511775 -- Validation loss:0.0448482 -- Test loss 0.06849622\n",
      "Epoch 453: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 454: -- Training loss 0.07487243 -- Validation loss:0.044660006 -- Test loss 0.0683234\n",
      "Epoch 454: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 455: -- Training loss 0.07462866 -- Validation loss:0.044473413 -- Test loss 0.06815235\n",
      "Epoch 455: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 456: -- Training loss 0.074386485 -- Validation loss:0.044288382 -- Test loss 0.06798315\n",
      "Epoch 456: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 457: -- Training loss 0.07414583 -- Validation loss:0.044104844 -- Test loss 0.06781578\n",
      "Epoch 457: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 458: -- Training loss 0.073906675 -- Validation loss:0.043922838 -- Test loss 0.06765024\n",
      "Epoch 458: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 459: -- Training loss 0.07366903 -- Validation loss:0.04374233 -- Test loss 0.06748634\n",
      "Epoch 459: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 460: -- Training loss 0.073432885 -- Validation loss:0.04356332 -- Test loss 0.06732417\n",
      "Epoch 460: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 461: -- Training loss 0.07319819 -- Validation loss:0.043385748 -- Test loss 0.06716375\n",
      "Epoch 461: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 462: -- Training loss 0.07296498 -- Validation loss:0.043209642 -- Test loss 0.06700505\n",
      "Epoch 462: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 463: -- Training loss 0.07273314 -- Validation loss:0.043034926 -- Test loss 0.06684802\n",
      "Epoch 463: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 464: -- Training loss 0.072502814 -- Validation loss:0.04286168 -- Test loss 0.0666926\n",
      "Epoch 464: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 465: -- Training loss 0.07227384 -- Validation loss:0.042689774 -- Test loss 0.066538855\n",
      "Epoch 465: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 466: -- Training loss 0.07204627 -- Validation loss:0.04251926 -- Test loss 0.06638673\n",
      "Epoch 466: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 467: -- Training loss 0.071820065 -- Validation loss:0.042350087 -- Test loss 0.06623621\n",
      "Epoch 467: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 468: -- Training loss 0.07159523 -- Validation loss:0.04218227 -- Test loss 0.06608726\n",
      "Epoch 468: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 469: -- Training loss 0.07137176 -- Validation loss:0.04201581 -- Test loss 0.06593988\n",
      "Epoch 469: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 470: -- Training loss 0.071149595 -- Validation loss:0.041850626 -- Test loss 0.06579403\n",
      "Epoch 470: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 471: -- Training loss 0.07092875 -- Validation loss:0.041686747 -- Test loss 0.0656498\n",
      "Epoch 471: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 472: -- Training loss 0.07070923 -- Validation loss:0.041524164 -- Test loss 0.06550703\n",
      "Epoch 472: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 473: -- Training loss 0.07049101 -- Validation loss:0.041362826 -- Test loss 0.06536573\n",
      "Epoch 473: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 474: -- Training loss 0.070274055 -- Validation loss:0.041202746 -- Test loss 0.06522595\n",
      "Epoch 474: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 475: -- Training loss 0.070058376 -- Validation loss:0.041043866 -- Test loss 0.06508768\n",
      "Epoch 475: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 476: -- Training loss 0.069843955 -- Validation loss:0.040886216 -- Test loss 0.06495095\n",
      "Epoch 476: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 477: -- Training loss 0.06963073 -- Validation loss:0.040729817 -- Test loss 0.06481549\n",
      "Epoch 477: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 478: -- Training loss 0.06941875 -- Validation loss:0.040574603 -- Test loss 0.064681485\n",
      "Epoch 478: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 479: -- Training loss 0.069207974 -- Validation loss:0.04042055 -- Test loss 0.06454895\n",
      "Epoch 479: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 480: -- Training loss 0.068998426 -- Validation loss:0.040267635 -- Test loss 0.064417854\n",
      "Epoch 480: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 481: -- Training loss 0.06879004 -- Validation loss:0.04011589 -- Test loss 0.06428808\n",
      "Epoch 481: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 482: -- Training loss 0.068582855 -- Validation loss:0.03996532 -- Test loss 0.06415967\n",
      "Epoch 482: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 483: -- Training loss 0.06837682 -- Validation loss:0.039815858 -- Test loss 0.06403267\n",
      "Epoch 483: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 484: -- Training loss 0.06817195 -- Validation loss:0.03966746 -- Test loss 0.06390704\n",
      "Epoch 484: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 485: -- Training loss 0.067968205 -- Validation loss:0.039520208 -- Test loss 0.06378267\n",
      "Epoch 485: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 486: -- Training loss 0.06776561 -- Validation loss:0.039374042 -- Test loss 0.06365965\n",
      "Epoch 486: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 487: -- Training loss 0.067564115 -- Validation loss:0.03922893 -- Test loss 0.06353793\n",
      "Epoch 487: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 488: -- Training loss 0.06736374 -- Validation loss:0.039084893 -- Test loss 0.06341755\n",
      "Epoch 488: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 489: -- Training loss 0.06716445 -- Validation loss:0.038941927 -- Test loss 0.06329842\n",
      "Epoch 489: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 490: -- Training loss 0.066966236 -- Validation loss:0.038800005 -- Test loss 0.06318052\n",
      "Epoch 490: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 491: -- Training loss 0.06676911 -- Validation loss:0.038659062 -- Test loss 0.063063964\n",
      "Epoch 491: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 492: -- Training loss 0.06657308 -- Validation loss:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038519155 -- Test loss 0.06294861\n",
      "Epoch 492: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 493: -- Training loss 0.06637804 -- Validation loss:0.038380254 -- Test loss 0.06283452\n",
      "Epoch 493: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 494: -- Training loss 0.06618405 -- Validation loss:0.038242377 -- Test loss 0.0627216\n",
      "Epoch 494: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 495: -- Training loss 0.06599114 -- Validation loss:0.038105454 -- Test loss 0.062609956\n",
      "Epoch 495: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 496: -- Training loss 0.0657992 -- Validation loss:0.037969492 -- Test loss 0.062499486\n",
      "Epoch 496: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 497: -- Training loss 0.065608315 -- Validation loss:0.037834518 -- Test loss 0.06239022\n",
      "Epoch 497: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 498: -- Training loss 0.0654184 -- Validation loss:0.037700474 -- Test loss 0.062282182\n",
      "Epoch 498: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 499: -- Training loss 0.0652295 -- Validation loss:0.037567373 -- Test loss 0.062175218\n",
      "Epoch 499: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 500: -- Training loss 0.06504158 -- Validation loss:0.03743521 -- Test loss 0.062069483\n",
      "Epoch 500: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 501: -- Training loss 0.06485464 -- Validation loss:0.037303995 -- Test loss 0.06196488\n",
      "Epoch 501: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 502: -- Training loss 0.06466865 -- Validation loss:0.037173674 -- Test loss 0.061861385\n",
      "Epoch 502: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 503: -- Training loss 0.064483605 -- Validation loss:0.037044227 -- Test loss 0.06175908\n",
      "Epoch 503: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 504: -- Training loss 0.064299524 -- Validation loss:0.036915664 -- Test loss 0.061657876\n",
      "Epoch 504: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 505: -- Training loss 0.064116366 -- Validation loss:0.036788024 -- Test loss 0.061557785\n",
      "Epoch 505: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 506: -- Training loss 0.06393411 -- Validation loss:0.036661264 -- Test loss 0.061458744\n",
      "Epoch 506: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 507: -- Training loss 0.06375281 -- Validation loss:0.036535334 -- Test loss 0.061360817\n",
      "Epoch 507: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 508: -- Training loss 0.06357242 -- Validation loss:0.03641023 -- Test loss 0.061264053\n",
      "Epoch 508: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 509: -- Training loss 0.063392915 -- Validation loss:0.03628597 -- Test loss 0.061168347\n",
      "Epoch 509: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 510: -- Training loss 0.063214295 -- Validation loss:0.036162622 -- Test loss 0.061073586\n",
      "Epoch 510: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 511: -- Training loss 0.063036606 -- Validation loss:0.036040094 -- Test loss 0.06097995\n",
      "Epoch 511: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 512: -- Training loss 0.062859744 -- Validation loss:0.035918374 -- Test loss 0.06088737\n",
      "Epoch 512: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 513: -- Training loss 0.06268373 -- Validation loss:0.035797358 -- Test loss 0.060795866\n",
      "Epoch 513: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 514: -- Training loss 0.06250863 -- Validation loss:0.035677243 -- Test loss 0.060705326\n",
      "Epoch 514: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 515: -- Training loss 0.062334355 -- Validation loss:0.03555795 -- Test loss 0.060615767\n",
      "Epoch 515: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 516: -- Training loss 0.062160917 -- Validation loss:0.03543938 -- Test loss 0.060527343\n",
      "Epoch 516: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 517: -- Training loss 0.06198834 -- Validation loss:0.035321567 -- Test loss 0.0604399\n",
      "Epoch 517: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 518: -- Training loss 0.06181655 -- Validation loss:0.03520457 -- Test loss 0.060353413\n",
      "Epoch 518: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 519: -- Training loss 0.061645623 -- Validation loss:0.035088357 -- Test loss 0.060267888\n",
      "Epoch 519: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 520: -- Training loss 0.061475463 -- Validation loss:0.034972876 -- Test loss 0.060183316\n",
      "Epoch 520: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 521: -- Training loss 0.061306134 -- Validation loss:0.034858096 -- Test loss 0.060099885\n",
      "Epoch 521: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 522: -- Training loss 0.061137617 -- Validation loss:0.03474411 -- Test loss 0.060017303\n",
      "Epoch 522: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 523: -- Training loss 0.060969863 -- Validation loss:0.034630843 -- Test loss 0.059935607\n",
      "Epoch 523: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 524: -- Training loss 0.06080291 -- Validation loss:0.034518305 -- Test loss 0.059854988\n",
      "Epoch 524: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 525: -- Training loss 0.060636707 -- Validation loss:0.034406427 -- Test loss 0.059775267\n",
      "Epoch 525: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 526: -- Training loss 0.060471293 -- Validation loss:0.0342953 -- Test loss 0.059696488\n",
      "Epoch 526: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 527: -- Training loss 0.060306635 -- Validation loss:0.03418491 -- Test loss 0.05961852\n",
      "Epoch 527: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 528: -- Training loss 0.060142733 -- Validation loss:0.034075174 -- Test loss 0.059541646\n",
      "Epoch 528: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 529: -- Training loss 0.059979565 -- Validation loss:0.033966105 -- Test loss 0.059465643\n",
      "Epoch 529: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 530: -- Training loss 0.059817154 -- Validation loss:0.033857755 -- Test loss 0.059390496\n",
      "Epoch 530: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 531: -- Training loss 0.05965549 -- Validation loss:0.033750117 -- Test loss 0.059316214\n",
      "Epoch 531: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 532: -- Training loss 0.059494514 -- Validation loss:0.033643093 -- Test loss 0.059242856\n",
      "Epoch 532: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 533: -- Training loss 0.059334263 -- Validation loss:0.033536714 -- Test loss 0.059170555\n",
      "Epoch 533: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 534: -- Training loss 0.059174757 -- Validation loss:0.033430994 -- Test loss 0.05909894\n",
      "Epoch 534: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 535: -- Training loss 0.05901596 -- Validation loss:0.033325993 -- Test loss 0.05902817\n",
      "Epoch 535: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 536: -- Training loss 0.058857843 -- Validation loss:0.033221614 -- Test loss 0.058958277\n",
      "Epoch 536: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 537: -- Training loss 0.058700435 -- Validation loss:0.03311782 -- Test loss 0.058889437\n",
      "Epoch 537: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 538: -- Training loss 0.0585437 -- Validation loss:0.03301466 -- Test loss 0.058821257\n",
      "Epoch 538: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 539: -- Training loss 0.058387615 -- Validation loss:0.03291213 -- Test loss 0.058754034\n",
      "Epoch 539: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 540: -- Training loss 0.058232255 -- Validation loss:0.032810263 -- Test loss 0.05868757\n",
      "Epoch 540: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 541: -- Training loss 0.05807755 -- Validation loss:0.03270902 -- Test loss 0.05862193\n",
      "Epoch 541: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 542: -- Training loss 0.057923537 -- Validation loss:0.032608293 -- Test loss 0.05855724\n",
      "Epoch 542: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 543: -- Training loss 0.057770133 -- Validation loss:0.032508206 -- Test loss 0.058493286\n",
      "Epoch 543: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 544: -- Training loss 0.057617422 -- Validation loss:0.032408755 -- Test loss 0.058430057\n",
      "Epoch 544: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 545: -- Training loss 0.057465326 -- Validation loss:0.0323099 -- Test loss 0.05836773\n",
      "Epoch 545: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 546: -- Training loss 0.057313886 -- Validation loss:0.03221153 -- Test loss 0.058306333\n",
      "Epoch 546: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 547: -- Training loss 0.057163112 -- Validation loss:0.03211383 -- Test loss 0.058245596\n",
      "Epoch 547: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 548: -- Training loss 0.057012934 -- Validation loss:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032016713 -- Test loss 0.05818556\n",
      "Epoch 548: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 549: -- Training loss 0.056863375 -- Validation loss:0.031920087 -- Test loss 0.05812645\n",
      "Epoch 549: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 550: -- Training loss 0.056714483 -- Validation loss:0.031824026 -- Test loss 0.058068156\n",
      "Epoch 550: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 551: -- Training loss 0.05656613 -- Validation loss:0.03172859 -- Test loss 0.058010522\n",
      "Epoch 551: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 552: -- Training loss 0.056418445 -- Validation loss:0.031633694 -- Test loss 0.057953645\n",
      "Epoch 552: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 553: -- Training loss 0.05627134 -- Validation loss:0.031539302 -- Test loss 0.057897642\n",
      "Epoch 553: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 554: -- Training loss 0.05612484 -- Validation loss:0.03144547 -- Test loss 0.05784237\n",
      "Epoch 554: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 555: -- Training loss 0.055978946 -- Validation loss:0.03135219 -- Test loss 0.057787914\n",
      "Epoch 555: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 556: -- Training loss 0.05583361 -- Validation loss:0.03125943 -- Test loss 0.057734028\n",
      "Epoch 556: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 557: -- Training loss 0.055688877 -- Validation loss:0.031167211 -- Test loss 0.057680998\n",
      "Epoch 557: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 558: -- Training loss 0.055544708 -- Validation loss:0.031075513 -- Test loss 0.057628687\n",
      "Epoch 558: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 559: -- Training loss 0.055401158 -- Validation loss:0.030984314 -- Test loss 0.057577197\n",
      "Epoch 559: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 560: -- Training loss 0.0552581 -- Validation loss:0.030893603 -- Test loss 0.057526384\n",
      "Epoch 560: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 561: -- Training loss 0.05511566 -- Validation loss:0.030803481 -- Test loss 0.057476245\n",
      "Epoch 561: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 562: -- Training loss 0.054973755 -- Validation loss:0.030713819 -- Test loss 0.057426743\n",
      "Epoch 562: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 563: -- Training loss 0.05483241 -- Validation loss:0.030624637 -- Test loss 0.05737817\n",
      "Epoch 563: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 564: -- Training loss 0.054691616 -- Validation loss:0.030535936 -- Test loss 0.057330232\n",
      "Epoch 564: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 565: -- Training loss 0.05455136 -- Validation loss:0.030447796 -- Test loss 0.057282936\n",
      "Epoch 565: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 566: -- Training loss 0.05441169 -- Validation loss:0.030360125 -- Test loss 0.05723625\n",
      "Epoch 566: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 567: -- Training loss 0.0542725 -- Validation loss:0.03027287 -- Test loss 0.057190493\n",
      "Epoch 567: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 568: -- Training loss 0.054133847 -- Validation loss:0.030186133 -- Test loss 0.057145387\n",
      "Epoch 568: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 569: -- Training loss 0.053995777 -- Validation loss:0.030099867 -- Test loss 0.057100818\n",
      "Epoch 569: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 570: -- Training loss 0.05385817 -- Validation loss:0.030014126 -- Test loss 0.057056926\n",
      "Epoch 570: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 571: -- Training loss 0.053721096 -- Validation loss:0.02992875 -- Test loss 0.057013903\n",
      "Epoch 571: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 572: -- Training loss 0.053584557 -- Validation loss:0.02984389 -- Test loss 0.056971546\n",
      "Epoch 572: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 573: -- Training loss 0.053448472 -- Validation loss:0.029759482 -- Test loss 0.056929674\n",
      "Epoch 573: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 574: -- Training loss 0.053312927 -- Validation loss:0.029675543 -- Test loss 0.05688848\n",
      "Epoch 574: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 575: -- Training loss 0.053177923 -- Validation loss:0.029592045 -- Test loss 0.05684802\n",
      "Epoch 575: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 576: -- Training loss 0.053043358 -- Validation loss:0.029508935 -- Test loss 0.0568083\n",
      "Epoch 576: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 577: -- Training loss 0.052909307 -- Validation loss:0.029426338 -- Test loss 0.056769136\n",
      "Epoch 577: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 578: -- Training loss 0.052775778 -- Validation loss:0.029344171 -- Test loss 0.05673059\n",
      "Epoch 578: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 579: -- Training loss 0.05264269 -- Validation loss:0.02926241 -- Test loss 0.05669272\n",
      "Epoch 579: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 580: -- Training loss 0.052510098 -- Validation loss:0.029181056 -- Test loss 0.05665555\n",
      "Epoch 580: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 581: -- Training loss 0.052378 -- Validation loss:0.029100202 -- Test loss 0.05661894\n",
      "Epoch 581: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 582: -- Training loss 0.052246343 -- Validation loss:0.029019728 -- Test loss 0.056582917\n",
      "Epoch 582: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 583: -- Training loss 0.052115187 -- Validation loss:0.028939642 -- Test loss 0.056547638\n",
      "Epoch 583: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 584: -- Training loss 0.05198446 -- Validation loss:0.02886 -- Test loss 0.056512896\n",
      "Epoch 584: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 585: -- Training loss 0.051854234 -- Validation loss:0.028780779 -- Test loss 0.05647882\n",
      "Epoch 585: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 586: -- Training loss 0.05172447 -- Validation loss:0.028701985 -- Test loss 0.056445308\n",
      "Epoch 586: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 587: -- Training loss 0.05159513 -- Validation loss:0.02862352 -- Test loss 0.056412462\n",
      "Epoch 587: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 588: -- Training loss 0.05146625 -- Validation loss:0.028545566 -- Test loss 0.056380168\n",
      "Epoch 588: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 589: -- Training loss 0.05133784 -- Validation loss:0.028467925 -- Test loss 0.0563486\n",
      "Epoch 589: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 590: -- Training loss 0.05120986 -- Validation loss:0.028390668 -- Test loss 0.056317504\n",
      "Epoch 590: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 591: -- Training loss 0.05108232 -- Validation loss:0.028313877 -- Test loss 0.056287028\n",
      "Epoch 591: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 592: -- Training loss 0.050955225 -- Validation loss:0.028237468 -- Test loss 0.056257106\n",
      "Epoch 592: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 593: -- Training loss 0.05082858 -- Validation loss:0.028161349 -- Test loss 0.05622787\n",
      "Epoch 593: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 594: -- Training loss 0.050702322 -- Validation loss:0.028085679 -- Test loss 0.056199197\n",
      "Epoch 594: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 595: -- Training loss 0.050576553 -- Validation loss:0.028010434 -- Test loss 0.056170963\n",
      "Epoch 595: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 596: -- Training loss 0.050451156 -- Validation loss:0.027935466 -- Test loss 0.056143507\n",
      "Epoch 596: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 597: -- Training loss 0.050326202 -- Validation loss:0.027860878 -- Test loss 0.05611665\n",
      "Epoch 597: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 598: -- Training loss 0.050201684 -- Validation loss:0.027786732 -- Test loss 0.056090154\n",
      "Epoch 598: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 599: -- Training loss 0.05007755 -- Validation loss:0.027712958 -- Test loss 0.05606421\n",
      "Epoch 599: -- Training acc  0.9859154929577465 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 600: -- Training loss 0.049953848 -- Validation loss:0.027639449 -- Test loss 0.056039117\n",
      "Epoch 600: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 601: -- Training loss 0.049830556 -- Validation loss:0.027566342 -- Test loss 0.05601443\n",
      "Epoch 601: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 602: -- Training loss 0.049707666 -- Validation loss:0.027493661 -- Test loss 0.055990197\n",
      "Epoch 602: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 603: -- Training loss 0.049585182 -- Validation loss:0.027421279 -- Test loss 0.055966612\n",
      "Epoch 603: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 604: -- Training loss 0.049463093 -- Validation loss:0.027349206 -- Test loss 0.055943657\n",
      "Epoch 604: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 605: -- Training loss 0.0493414 -- Validation loss:0.027277498 -- Test loss 0.05592118\n",
      "Epoch 605: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 606: -- Training loss 0.049220104 -- Validation loss:0.027206207 -- Test loss 0.05589914\n",
      "Epoch 606: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 607: -- Training loss 0.049099196 -- Validation loss:0.027135238 -- Test loss 0.055877708\n",
      "Epoch 607: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 608: -- Training loss 0.048978712 -- Validation loss:0.027064517 -- Test loss 0.05585691\n",
      "Epoch 608: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 609: -- Training loss 0.04885858 -- Validation loss:0.026994223 -- Test loss 0.055836607\n",
      "Epoch 609: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 610: -- Training loss 0.04873884 -- Validation loss:0.026924238 -- Test loss 0.0558167\n",
      "Epoch 610: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 611: -- Training loss 0.048619486 -- Validation loss:0.02685462 -- Test loss 0.055797406\n",
      "Epoch 611: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 612: -- Training loss 0.048500516 -- Validation loss:0.026785241 -- Test loss 0.055778723\n",
      "Epoch 612: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 613: -- Training loss 0.048381887 -- Validation loss:0.02671622 -- Test loss 0.05576056\n",
      "Epoch 613: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 614: -- Training loss 0.04826365 -- Validation loss:0.026647585 -- Test loss 0.05574274\n",
      "Epoch 614: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 615: -- Training loss 0.048145812 -- Validation loss:0.026579268 -- Test loss 0.05572541\n",
      "Epoch 615: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 616: -- Training loss 0.048028275 -- Validation loss:0.026511133 -- Test loss 0.055708934\n",
      "Epoch 616: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 617: -- Training loss 0.047911152 -- Validation loss:0.026443385 -- Test loss 0.05569274\n",
      "Epoch 617: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 618: -- Training loss 0.047794383 -- Validation loss:0.026376067 -- Test loss 0.055676952\n",
      "Epoch 618: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 619: -- Training loss 0.047677975 -- Validation loss:0.02630902 -- Test loss 0.05566168\n",
      "Epoch 619: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 620: -- Training loss 0.047561906 -- Validation loss:0.026242113 -- Test loss 0.05564722\n",
      "Epoch 620: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 621: -- Training loss 0.047446232 -- Validation loss:0.026175624 -- Test loss 0.055633087\n",
      "Epoch 621: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 622: -- Training loss 0.047330886 -- Validation loss:0.026109554 -- Test loss 0.055619173\n",
      "Epoch 622: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 623: -- Training loss 0.047215894 -- Validation loss:0.02604363 -- Test loss 0.055606056\n",
      "Epoch 623: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 624: -- Training loss 0.04710126 -- Validation loss:0.025977978 -- Test loss 0.055593494\n",
      "Epoch 624: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 625: -- Training loss 0.04698694 -- Validation loss:0.025912689 -- Test loss 0.05558121\n",
      "Epoch 625: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 626: -- Training loss 0.04687299 -- Validation loss:0.025847783 -- Test loss 0.05556932\n",
      "Epoch 626: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 627: -- Training loss 0.046759374 -- Validation loss:0.02578306 -- Test loss 0.055558052\n",
      "Epoch 627: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 628: -- Training loss 0.046646107 -- Validation loss:0.025718568 -- Test loss 0.055547494\n",
      "Epoch 628: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 629: -- Training loss 0.046533193 -- Validation loss:0.025654448 -- Test loss 0.055537205\n",
      "Epoch 629: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 630: -- Training loss 0.04642057 -- Validation loss:0.02559072 -- Test loss 0.05552707\n",
      "Epoch 630: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 631: -- Training loss 0.046308327 -- Validation loss:0.025527095 -- Test loss 0.05551784\n",
      "Epoch 631: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 632: -- Training loss 0.046196375 -- Validation loss:0.02546374 -- Test loss 0.05550918\n",
      "Epoch 632: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 633: -- Training loss 0.046084765 -- Validation loss:0.02540083 -- Test loss 0.05550052\n",
      "Epoch 633: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 634: -- Training loss 0.04597348 -- Validation loss:0.025338164 -- Test loss 0.055492416\n",
      "Epoch 634: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 635: -- Training loss 0.045862533 -- Validation loss:0.025275579 -- Test loss 0.055485144\n",
      "Epoch 635: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 636: -- Training loss 0.045751896 -- Validation loss:0.025213407 -- Test loss 0.055478126\n",
      "Epoch 636: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 637: -- Training loss 0.04564158 -- Validation loss:0.02515158 -- Test loss 0.05547125\n",
      "Epoch 637: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 638: -- Training loss 0.045531586 -- Validation loss:0.025089948 -- Test loss 0.055465147\n",
      "Epoch 638: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 639: -- Training loss 0.0454219 -- Validation loss:0.025028436 -- Test loss 0.0554596\n",
      "Epoch 639: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 640: -- Training loss 0.045312524 -- Validation loss:0.024967404 -- Test loss 0.05545424\n",
      "Epoch 640: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 641: -- Training loss 0.045203485 -- Validation loss:0.02490664 -- Test loss 0.055449266\n",
      "Epoch 641: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 642: -- Training loss 0.045094732 -- Validation loss:0.024845958 -- Test loss 0.05544502\n",
      "Epoch 642: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 643: -- Training loss 0.0449863 -- Validation loss:0.024785554 -- Test loss 0.055441264\n",
      "Epoch 643: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 644: -- Training loss 0.04487817 -- Validation loss:0.02472555 -- Test loss 0.05543755\n",
      "Epoch 644: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 645: -- Training loss 0.04477034 -- Validation loss:0.024665743 -- Test loss 0.0554343\n",
      "Epoch 645: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 646: -- Training loss 0.044662822 -- Validation loss:0.024606107 -- Test loss 0.055431865\n",
      "Epoch 646: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 647: -- Training loss 0.044555616 -- Validation loss:0.024546787 -- Test loss 0.05542966\n",
      "Epoch 647: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 648: -- Training loss 0.044448677 -- Validation loss:0.024487702 -- Test loss 0.0554278\n",
      "Epoch 648: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 649: -- Training loss 0.04434205 -- Validation loss:0.024428902 -- Test loss 0.055426307\n",
      "Epoch 649: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 650: -- Training loss 0.04423574 -- Validation loss:0.024370246 -- Test loss 0.05542541\n",
      "Epoch 650: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 651: -- Training loss 0.04412971 -- Validation loss:0.024311913 -- Test loss 0.055424947\n",
      "Epoch 651: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 652: -- Training loss 0.044023972 -- Validation loss:0.024253808 -- Test loss 0.055424675\n",
      "Epoch 652: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 653: -- Training loss 0.04391853 -- Validation loss:0.02419593 -- Test loss 0.05542498\n",
      "Epoch 653: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 654: -- Training loss 0.043813355 -- Validation loss:0.024138272 -- Test loss 0.055425774\n",
      "Epoch 654: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 655: -- Training loss 0.043708492 -- Validation loss:0.024080863 -- Test loss 0.0554268\n",
      "Epoch 655: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 656: -- Training loss 0.043603916 -- Validation loss:0.024023704 -- Test loss 0.05542834\n",
      "Epoch 656: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 657: -- Training loss 0.04349963 -- Validation loss:0.023966743 -- Test loss 0.055430237\n",
      "Epoch 657: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 658: -- Training loss 0.04339559 -- Validation loss:0.023910051 -- Test loss 0.05543252\n",
      "Epoch 658: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 659: -- Training loss 0.043291885 -- Validation loss:0.023853526 -- Test loss 0.055435233\n",
      "Epoch 659: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 660: -- Training loss 0.04318842 -- Validation loss:0.023797238 -- Test loss 0.05543841\n",
      "Epoch 660: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 661: -- Training loss 0.043085236 -- Validation loss:0.023741268 -- Test loss 0.0554418\n",
      "Epoch 661: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 662: -- Training loss 0.042982347 -- Validation loss:0.02368546 -- Test loss 0.05544562\n",
      "Epoch 662: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 663: -- Training loss 0.04287973 -- Validation loss:0.023629777 -- Test loss 0.055450067\n",
      "Epoch 663: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 664: -- Training loss 0.04277739 -- Validation loss:0.023574414 -- Test loss 0.055454694\n",
      "Epoch 664: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 665: -- Training loss 0.04267531 -- Validation loss:0.02351927 -- Test loss 0.055459585\n",
      "Epoch 665: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 666: -- Training loss 0.042573515 -- Validation loss:0.023464294 -- Test loss 0.055465177\n",
      "Epoch 666: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 667: -- Training loss 0.04247197 -- Validation loss:0.02340957 -- Test loss 0.055470906\n",
      "Epoch 667: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 668: -- Training loss 0.042370718 -- Validation loss:0.023355087 -- Test loss 0.055477034\n",
      "Epoch 668: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 669: -- Training loss 0.042269737 -- Validation loss:0.023300732 -- Test loss 0.05548367\n",
      "Epoch 669: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 670: -- Training loss 0.042168997 -- Validation loss:0.023246609 -- Test loss 0.055490658\n",
      "Epoch 670: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 671: -- Training loss 0.042068534 -- Validation loss:0.023192741 -- Test loss 0.05549782\n",
      "Epoch 671: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 672: -- Training loss 0.04196832 -- Validation loss:0.02313905 -- Test loss 0.055505533\n",
      "Epoch 672: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 673: -- Training loss 0.041868407 -- Validation loss:0.023085518 -- Test loss 0.055513695\n",
      "Epoch 673: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 674: -- Training loss 0.041768737 -- Validation loss:0.02303228 -- Test loss 0.055522054\n",
      "Epoch 674: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 675: -- Training loss 0.041669317 -- Validation loss:0.022979192 -- Test loss 0.055530623\n",
      "Epoch 675: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 676: -- Training loss 0.04157016 -- Validation loss:0.022926232 -- Test loss 0.055540074\n",
      "Epoch 676: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 677: -- Training loss 0.041471265 -- Validation loss:0.02287358 -- Test loss 0.05554952\n",
      "Epoch 677: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 678: -- Training loss 0.04137261 -- Validation loss:0.022821173 -- Test loss 0.055559136\n",
      "Epoch 678: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 679: -- Training loss 0.041274235 -- Validation loss:0.022768803 -- Test loss 0.055569574\n",
      "Epoch 679: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 680: -- Training loss 0.04117612 -- Validation loss:0.02271664 -- Test loss 0.055580173\n",
      "Epoch 680: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 681: -- Training loss 0.041078232 -- Validation loss:0.022664847 -- Test loss 0.05559085\n",
      "Epoch 681: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 682: -- Training loss 0.04098056 -- Validation loss:0.022613129 -- Test loss 0.05560209\n",
      "Epoch 682: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 683: -- Training loss 0.040883217 -- Validation loss:0.022561485 -- Test loss 0.05561399\n",
      "Epoch 683: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 684: -- Training loss 0.04078608 -- Validation loss:0.022510193 -- Test loss 0.05562578\n",
      "Epoch 684: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 685: -- Training loss 0.040689178 -- Validation loss:0.022459073 -- Test loss 0.055638026\n",
      "Epoch 685: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 686: -- Training loss 0.040592577 -- Validation loss:0.022408033 -- Test loss 0.055650815\n",
      "Epoch 686: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 687: -- Training loss 0.040496204 -- Validation loss:0.022357248 -- Test loss 0.055663705\n",
      "Epoch 687: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 688: -- Training loss 0.04040003 -- Validation loss:0.022306738 -- Test loss 0.055676855\n",
      "Epoch 688: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 689: -- Training loss 0.04030413 -- Validation loss:0.022256209 -- Test loss 0.055690713\n",
      "Epoch 689: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 690: -- Training loss 0.04020848 -- Validation loss:0.022205943 -- Test loss 0.05570475\n",
      "Epoch 690: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 691: -- Training loss 0.040113058 -- Validation loss:0.022155954 -- Test loss 0.055718824\n",
      "Epoch 691: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 692: -- Training loss 0.0400179 -- Validation loss:0.022106037 -- Test loss 0.055733517\n",
      "Epoch 692: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 693: -- Training loss 0.03992296 -- Validation loss:0.022056269 -- Test loss 0.055748582\n",
      "Epoch 693: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 694: -- Training loss 0.039828237 -- Validation loss:0.022006733 -- Test loss 0.055763774\n",
      "Epoch 694: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 695: -- Training loss 0.0397338 -- Validation loss:0.02195745 -- Test loss 0.055779275\n",
      "Epoch 695: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 696: -- Training loss 0.03963959 -- Validation loss:0.02190817 -- Test loss 0.05579546\n",
      "Epoch 696: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 697: -- Training loss 0.0395456 -- Validation loss:0.02185913 -- Test loss 0.055811677\n",
      "Epoch 697: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 698: -- Training loss 0.039451852 -- Validation loss:0.021810407 -- Test loss 0.05582797\n",
      "Epoch 698: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 699: -- Training loss 0.03935833 -- Validation loss:0.021761604 -- Test loss 0.055845108\n",
      "Epoch 699: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 700: -- Training loss 0.03926506 -- Validation loss:0.021713024 -- Test loss 0.05586239\n",
      "Epoch 700: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 701: -- Training loss 0.03917202 -- Validation loss:0.021664796 -- Test loss 0.05587958\n",
      "Epoch 701: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 702: -- Training loss 0.0390792 -- Validation loss:0.021616524 -- Test loss 0.055897593\n",
      "Epoch 702: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 703: -- Training loss 0.03898662 -- Validation loss:0.021568462 -- Test loss 0.055915795\n",
      "Epoch 703: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 704: -- Training loss 0.038894296 -- Validation loss:0.021520624 -- Test loss 0.055934094\n",
      "Epoch 704: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 705: -- Training loss 0.038802136 -- Validation loss:0.021472963 -- Test loss 0.055952802\n",
      "Epoch 705: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 706: -- Training loss 0.038710237 -- Validation loss:0.021425337 -- Test loss 0.055972014\n",
      "Epoch 706: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 707: -- Training loss 0.038618572 -- Validation loss:0.021377953 -- Test loss 0.055991363\n",
      "Epoch 707: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 708: -- Training loss 0.038527098 -- Validation loss:0.021330774 -- Test loss 0.056010757\n",
      "Epoch 708: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709: -- Training loss 0.038435888 -- Validation loss:0.021283662 -- Test loss 0.05603084\n",
      "Epoch 709: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 710: -- Training loss 0.0383449 -- Validation loss:0.02123666 -- Test loss 0.056051183\n",
      "Epoch 710: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 711: -- Training loss 0.03825414 -- Validation loss:0.021189975 -- Test loss 0.05607154\n",
      "Epoch 711: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 712: -- Training loss 0.038163602 -- Validation loss:0.021143362 -- Test loss 0.056092292\n",
      "Epoch 712: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 713: -- Training loss 0.038073257 -- Validation loss:0.021096775 -- Test loss 0.056113765\n",
      "Epoch 713: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 714: -- Training loss 0.03798317 -- Validation loss:0.02105051 -- Test loss 0.05613495\n",
      "Epoch 714: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 715: -- Training loss 0.037893295 -- Validation loss:0.02100441 -- Test loss 0.056156546\n",
      "Epoch 715: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 716: -- Training loss 0.037803628 -- Validation loss:0.02095829 -- Test loss 0.056178693\n",
      "Epoch 716: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 717: -- Training loss 0.03771417 -- Validation loss:0.020912426 -- Test loss 0.05620093\n",
      "Epoch 717: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 718: -- Training loss 0.037624955 -- Validation loss:0.02086673 -- Test loss 0.056223404\n",
      "Epoch 718: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 719: -- Training loss 0.037535943 -- Validation loss:0.020821134 -- Test loss 0.056246195\n",
      "Epoch 719: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 720: -- Training loss 0.03744717 -- Validation loss:0.020775719 -- Test loss 0.056269363\n",
      "Epoch 720: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 721: -- Training loss 0.037358597 -- Validation loss:0.020730415 -- Test loss 0.056292668\n",
      "Epoch 721: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 722: -- Training loss 0.037270263 -- Validation loss:0.020685237 -- Test loss 0.05631634\n",
      "Epoch 722: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 723: -- Training loss 0.03718209 -- Validation loss:0.020640196 -- Test loss 0.056340326\n",
      "Epoch 723: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 724: -- Training loss 0.03709418 -- Validation loss:0.020595357 -- Test loss 0.056364417\n",
      "Epoch 724: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 725: -- Training loss 0.037006456 -- Validation loss:0.020550603 -- Test loss 0.056388874\n",
      "Epoch 725: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 726: -- Training loss 0.036918964 -- Validation loss:0.020505963 -- Test loss 0.056413844\n",
      "Epoch 726: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 727: -- Training loss 0.036831684 -- Validation loss:0.020461535 -- Test loss 0.056438584\n",
      "Epoch 727: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 728: -- Training loss 0.036744617 -- Validation loss:0.020417193 -- Test loss 0.0564639\n",
      "Epoch 728: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 729: -- Training loss 0.036657743 -- Validation loss:0.02037298 -- Test loss 0.056489583\n",
      "Epoch 729: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 730: -- Training loss 0.03657111 -- Validation loss:0.02032892 -- Test loss 0.056515306\n",
      "Epoch 730: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 731: -- Training loss 0.036484636 -- Validation loss:0.020285008 -- Test loss 0.05654126\n",
      "Epoch 731: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 732: -- Training loss 0.03639843 -- Validation loss:0.020241225 -- Test loss 0.056567594\n",
      "Epoch 732: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 733: -- Training loss 0.036312412 -- Validation loss:0.020197531 -- Test loss 0.056594305\n",
      "Epoch 733: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 734: -- Training loss 0.036226593 -- Validation loss:0.020153945 -- Test loss 0.056621123\n",
      "Epoch 734: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 735: -- Training loss 0.036141004 -- Validation loss:0.020110648 -- Test loss 0.05664791\n",
      "Epoch 735: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 736: -- Training loss 0.036055587 -- Validation loss:0.02006728 -- Test loss 0.056675583\n",
      "Epoch 736: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 737: -- Training loss 0.035970382 -- Validation loss:0.020024111 -- Test loss 0.056703158\n",
      "Epoch 737: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 738: -- Training loss 0.03588542 -- Validation loss:0.019981183 -- Test loss 0.056730762\n",
      "Epoch 738: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 739: -- Training loss 0.035800636 -- Validation loss:0.019938232 -- Test loss 0.056758884\n",
      "Epoch 739: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 740: -- Training loss 0.035716064 -- Validation loss:0.01989538 -- Test loss 0.05678742\n",
      "Epoch 740: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 741: -- Training loss 0.035631694 -- Validation loss:0.019852797 -- Test loss 0.056815818\n",
      "Epoch 741: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 742: -- Training loss 0.035547514 -- Validation loss:0.019810269 -- Test loss 0.05684461\n",
      "Epoch 742: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 743: -- Training loss 0.035463575 -- Validation loss:0.019767797 -- Test loss 0.056873865\n",
      "Epoch 743: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 744: -- Training loss 0.0353798 -- Validation loss:0.019725533 -- Test loss 0.056903075\n",
      "Epoch 744: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 745: -- Training loss 0.03529622 -- Validation loss:0.019683398 -- Test loss 0.0569325\n",
      "Epoch 745: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 746: -- Training loss 0.03521286 -- Validation loss:0.019641308 -- Test loss 0.05696239\n",
      "Epoch 746: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 747: -- Training loss 0.035129733 -- Validation loss:0.019599378 -- Test loss 0.056992408\n",
      "Epoch 747: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 748: -- Training loss 0.03504676 -- Validation loss:0.019557577 -- Test loss 0.05702256\n",
      "Epoch 748: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 749: -- Training loss 0.034964 -- Validation loss:0.01951583 -- Test loss 0.057053164\n",
      "Epoch 749: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 750: -- Training loss 0.034881428 -- Validation loss:0.019474292 -- Test loss 0.05708384\n",
      "Epoch 750: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 751: -- Training loss 0.034799088 -- Validation loss:0.019432873 -- Test loss 0.057114635\n",
      "Epoch 751: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 752: -- Training loss 0.03471693 -- Validation loss:0.019391445 -- Test loss 0.057145998\n",
      "Epoch 752: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 753: -- Training loss 0.03463495 -- Validation loss:0.019350221 -- Test loss 0.057177253\n",
      "Epoch 753: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 754: -- Training loss 0.034553185 -- Validation loss:0.019309128 -- Test loss 0.057208788\n",
      "Epoch 754: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 755: -- Training loss 0.034471612 -- Validation loss:0.019268038 -- Test loss 0.057240844\n",
      "Epoch 755: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 756: -- Training loss 0.03439026 -- Validation loss:0.019227153 -- Test loss 0.057272956\n",
      "Epoch 756: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 757: -- Training loss 0.034309078 -- Validation loss:0.019186458 -- Test loss 0.057304904\n",
      "Epoch 757: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 758: -- Training loss 0.03422809 -- Validation loss:0.019145662 -- Test loss 0.057337757\n",
      "Epoch 758: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 759: -- Training loss 0.034147322 -- Validation loss:0.019105067 -- Test loss 0.0573705\n",
      "Epoch 759: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 760: -- Training loss 0.03406673 -- Validation loss:0.019064708 -- Test loss 0.057403035\n",
      "Epoch 760: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 761: -- Training loss 0.033986334 -- Validation loss:0.019024262 -- Test loss 0.057436496\n",
      "Epoch 761: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 762: -- Training loss 0.033906136 -- Validation loss:0.01898395 -- Test loss 0.057470072\n",
      "Epoch 762: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 763: -- Training loss 0.033826113 -- Validation loss:0.01894401 -- Test loss 0.05750309\n",
      "Epoch 763: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 764: -- Training loss 0.0337463 -- Validation loss:0.018903773 -- Test loss 0.057537403\n",
      "Epoch 764: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 765: -- Training loss 0.033666674 -- Validation loss:0.018863862 -- Test loss 0.057571407\n",
      "Epoch 765: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 766: -- Training loss 0.033587243 -- Validation loss:0.01882417 -- Test loss 0.05760511\n",
      "Epoch 766: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 767: -- Training loss 0.03350799 -- Validation loss:0.01878429 -- Test loss 0.057640024\n",
      "Epoch 767: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 768: -- Training loss 0.033428926 -- Validation loss:0.018744638 -- Test loss 0.057674717\n",
      "Epoch 768: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 769: -- Training loss 0.03335007 -- Validation loss:0.01870525 -- Test loss 0.057709064\n",
      "Epoch 769: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770: -- Training loss 0.0332714 -- Validation loss:0.018665703 -- Test loss 0.057744507\n",
      "Epoch 770: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 771: -- Training loss 0.033192944 -- Validation loss:0.018626383 -- Test loss 0.057779822\n",
      "Epoch 771: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 772: -- Training loss 0.03311465 -- Validation loss:0.018587265 -- Test loss 0.057814866\n",
      "Epoch 772: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 773: -- Training loss 0.033036552 -- Validation loss:0.018548043 -- Test loss 0.05785075\n",
      "Epoch 773: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 774: -- Training loss 0.032958623 -- Validation loss:0.018508984 -- Test loss 0.057886623\n",
      "Epoch 774: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 775: -- Training loss 0.03288091 -- Validation loss:0.018470166 -- Test loss 0.05792232\n",
      "Epoch 775: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 776: -- Training loss 0.032803353 -- Validation loss:0.018431233 -- Test loss 0.057958893\n",
      "Epoch 776: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 777: -- Training loss 0.032726 -- Validation loss:0.018392522 -- Test loss 0.05799525\n",
      "Epoch 777: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 778: -- Training loss 0.03264885 -- Validation loss:0.018353878 -- Test loss 0.058031745\n",
      "Epoch 778: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 779: -- Training loss 0.03257186 -- Validation loss:0.0183153 -- Test loss 0.058068655\n",
      "Epoch 779: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 780: -- Training loss 0.032495078 -- Validation loss:0.018276839 -- Test loss 0.05810573\n",
      "Epoch 780: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 781: -- Training loss 0.032418452 -- Validation loss:0.018238554 -- Test loss 0.058142778\n",
      "Epoch 781: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 782: -- Training loss 0.032342043 -- Validation loss:0.018200247 -- Test loss 0.05818017\n",
      "Epoch 782: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 783: -- Training loss 0.0322658 -- Validation loss:0.018162003 -- Test loss 0.05821788\n",
      "Epoch 783: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 784: -- Training loss 0.03218975 -- Validation loss:0.018124007 -- Test loss 0.058255397\n",
      "Epoch 784: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 785: -- Training loss 0.032113902 -- Validation loss:0.018086 -- Test loss 0.058293365\n",
      "Epoch 785: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 786: -- Training loss 0.0320382 -- Validation loss:0.018048035 -- Test loss 0.05833174\n",
      "Epoch 786: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 787: -- Training loss 0.031962693 -- Validation loss:0.018010268 -- Test loss 0.058369808\n",
      "Epoch 787: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 788: -- Training loss 0.03188738 -- Validation loss:0.01797259 -- Test loss 0.058408193\n",
      "Epoch 788: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 789: -- Training loss 0.03181225 -- Validation loss:0.017934846 -- Test loss 0.05844724\n",
      "Epoch 789: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 790: -- Training loss 0.0317373 -- Validation loss:0.017897403 -- Test loss 0.05848577\n",
      "Epoch 790: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 791: -- Training loss 0.03166251 -- Validation loss:0.017859956 -- Test loss 0.05852475\n",
      "Epoch 791: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 792: -- Training loss 0.03158793 -- Validation loss:0.017822532 -- Test loss 0.058564104\n",
      "Epoch 792: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 793: -- Training loss 0.031513542 -- Validation loss:0.017785275 -- Test loss 0.0586033\n",
      "Epoch 793: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 794: -- Training loss 0.03143927 -- Validation loss:0.017748099 -- Test loss 0.05864279\n",
      "Epoch 794: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 795: -- Training loss 0.031365234 -- Validation loss:0.01771093 -- Test loss 0.058682695\n",
      "Epoch 795: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 796: -- Training loss 0.031291366 -- Validation loss:0.017673971 -- Test loss 0.058722496\n",
      "Epoch 796: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 797: -- Training loss 0.031217651 -- Validation loss:0.017637013 -- Test loss 0.05876253\n",
      "Epoch 797: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798: -- Training loss 0.031144146 -- Validation loss:0.01760014 -- Test loss 0.058802724\n",
      "Epoch 798: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 799: -- Training loss 0.031070823 -- Validation loss:0.017563375 -- Test loss 0.058843173\n",
      "Epoch 799: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 800: -- Training loss 0.030997673 -- Validation loss:0.017526766 -- Test loss 0.05888348\n",
      "Epoch 800: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 801: -- Training loss 0.030924669 -- Validation loss:0.017490063 -- Test loss 0.058924545\n",
      "Epoch 801: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 802: -- Training loss 0.030851899 -- Validation loss:0.017453557 -- Test loss 0.058965273\n",
      "Epoch 802: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 803: -- Training loss 0.030779257 -- Validation loss:0.017417165 -- Test loss 0.059006076\n",
      "Epoch 803: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 804: -- Training loss 0.030706812 -- Validation loss:0.017380722 -- Test loss 0.05904757\n",
      "Epoch 804: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 805: -- Training loss 0.030634541 -- Validation loss:0.017344471 -- Test loss 0.059088875\n",
      "Epoch 805: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 806: -- Training loss 0.030562468 -- Validation loss:0.017308382 -- Test loss 0.05913002\n",
      "Epoch 806: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 807: -- Training loss 0.030490546 -- Validation loss:0.017272076 -- Test loss 0.059172258\n",
      "Epoch 807: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 808: -- Training loss 0.030418789 -- Validation loss:0.017236164 -- Test loss 0.059213616\n",
      "Epoch 808: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 809: -- Training loss 0.030347219 -- Validation loss:0.017200174 -- Test loss 0.059255783\n",
      "Epoch 809: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 810: -- Training loss 0.030275842 -- Validation loss:0.017164262 -- Test loss 0.059297957\n",
      "Epoch 810: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 811: -- Training loss 0.030204605 -- Validation loss:0.017128494 -- Test loss 0.059340183\n",
      "Epoch 811: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 812: -- Training loss 0.030133566 -- Validation loss:0.017092811 -- Test loss 0.059382435\n",
      "Epoch 812: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 813: -- Training loss 0.030062692 -- Validation loss:0.01705711 -- Test loss 0.05942535\n",
      "Epoch 813: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 814: -- Training loss 0.029991958 -- Validation loss:0.01702152 -- Test loss 0.05946803\n",
      "Epoch 814: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 815: -- Training loss 0.029921457 -- Validation loss:0.016986096 -- Test loss 0.059510678\n",
      "Epoch 815: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 816: -- Training loss 0.029851107 -- Validation loss:0.016950598 -- Test loss 0.059554063\n",
      "Epoch 816: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 817: -- Training loss 0.029780911 -- Validation loss:0.016915293 -- Test loss 0.059597027\n",
      "Epoch 817: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 818: -- Training loss 0.029710937 -- Validation loss:0.016880084 -- Test loss 0.059640236\n",
      "Epoch 818: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 819: -- Training loss 0.029641094 -- Validation loss:0.016844755 -- Test loss 0.059684146\n",
      "Epoch 819: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 820: -- Training loss 0.029571423 -- Validation loss:0.016809748 -- Test loss 0.059727434\n",
      "Epoch 820: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 821: -- Training loss 0.029501915 -- Validation loss:0.016774694 -- Test loss 0.05977111\n",
      "Epoch 821: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 822: -- Training loss 0.029432585 -- Validation loss:0.016739672 -- Test loss 0.059815276\n",
      "Epoch 822: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 823: -- Training loss 0.02936344 -- Validation loss:0.016704822 -- Test loss 0.05985916\n",
      "Epoch 823: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 824: -- Training loss 0.029294431 -- Validation loss:0.016669985 -- Test loss 0.05990336\n",
      "Epoch 824: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 825: -- Training loss 0.029225612 -- Validation loss:0.016635183 -- Test loss 0.059947763\n",
      "Epoch 825: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 826: -- Training loss 0.029156983 -- Validation loss:0.01660053 -- Test loss 0.059992094\n",
      "Epoch 826: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 827: -- Training loss 0.029088505 -- Validation loss:0.016565926 -- Test loss 0.060036723\n",
      "Epoch 827: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 828: -- Training loss 0.029020188 -- Validation loss:0.016531395 -- Test loss 0.060081393\n",
      "Epoch 828: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 829: -- Training loss 0.028952042 -- Validation loss:0.016496873 -- Test loss 0.06012629\n",
      "Epoch 829: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 830: -- Training loss 0.028884076 -- Validation loss:0.016462514 -- Test loss 0.06017114\n",
      "Epoch 830: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 831: -- Training loss 0.028816264 -- Validation loss:0.016428191 -- Test loss 0.060216293\n",
      "Epoch 831: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 832: -- Training loss 0.0287486 -- Validation loss:0.016393872 -- Test loss 0.060261834\n",
      "Epoch 832: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 833: -- Training loss 0.028681116 -- Validation loss:0.016359808 -- Test loss 0.06030682\n",
      "Epoch 833: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 834: -- Training loss 0.02861381 -- Validation loss:0.01632557 -- Test loss 0.06035273\n",
      "Epoch 834: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 835: -- Training loss 0.028546682 -- Validation loss:0.016291568 -- Test loss 0.060398135\n",
      "Epoch 835: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 836: -- Training loss 0.028479686 -- Validation loss:0.016257612 -- Test loss 0.060443845\n",
      "Epoch 836: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 837: -- Training loss 0.028412879 -- Validation loss:0.016223565 -- Test loss 0.06049023\n",
      "Epoch 837: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 838: -- Training loss 0.02834624 -- Validation loss:0.01618989 -- Test loss 0.06053556\n",
      "Epoch 838: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 839: -- Training loss 0.028279735 -- Validation loss:0.016156042 -- Test loss 0.060581923\n",
      "Epoch 839: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 840: -- Training loss 0.028213434 -- Validation loss:0.016122239 -- Test loss 0.06062851\n",
      "Epoch 840: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 841: -- Training loss 0.028147267 -- Validation loss:0.0160888 -- Test loss 0.06067426\n",
      "Epoch 841: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 842: -- Training loss 0.028081259 -- Validation loss:0.016055044 -- Test loss 0.060721282\n",
      "Epoch 842: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 843: -- Training loss 0.028015435 -- Validation loss:0.016021552 -- Test loss 0.060767837\n",
      "Epoch 843: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 844: -- Training loss 0.027949769 -- Validation loss:0.015988166 -- Test loss 0.060814228\n",
      "Epoch 844: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 845: -- Training loss 0.027884271 -- Validation loss:0.015954684 -- Test loss 0.060861517\n",
      "Epoch 845: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 846: -- Training loss 0.027818909 -- Validation loss:0.015921399 -- Test loss 0.060908347\n",
      "Epoch 846: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 847: -- Training loss 0.027753726 -- Validation loss:0.01588823 -- Test loss 0.060955305\n",
      "Epoch 847: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 848: -- Training loss 0.027688712 -- Validation loss:0.015854962 -- Test loss 0.061002813\n",
      "Epoch 848: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 849: -- Training loss 0.027623845 -- Validation loss:0.015821856 -- Test loss 0.06105008\n",
      "Epoch 849: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 850: -- Training loss 0.027559152 -- Validation loss:0.015788829 -- Test loss 0.06109723\n",
      "Epoch 850: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 851: -- Training loss 0.027494583 -- Validation loss:0.015755752 -- Test loss 0.061145253\n",
      "Epoch 851: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 852: -- Training loss 0.027430208 -- Validation loss:0.015722854 -- Test loss 0.061192766\n",
      "Epoch 852: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 853: -- Training loss 0.027365984 -- Validation loss:0.015690051 -- Test loss 0.061240282\n",
      "Epoch 853: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 854: -- Training loss 0.027301908 -- Validation loss:0.015657159 -- Test loss 0.061288584\n",
      "Epoch 854: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 855: -- Training loss 0.027238024 -- Validation loss:0.015624468 -- Test loss 0.061336227\n",
      "Epoch 855: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 856: -- Training loss 0.02717427 -- Validation loss:0.015591771 -- Test loss 0.061384343\n",
      "Epoch 856: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 857: -- Training loss 0.027110692 -- Validation loss:0.01555913 -- Test loss 0.061432656\n",
      "Epoch 857: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 858: -- Training loss 0.027047262 -- Validation loss:0.015526567 -- Test loss 0.06148093\n",
      "Epoch 858: -- Training acc  1.0 -- Validation acc: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 -- Test acc  0.96\n",
      "Epoch 859: -- Training loss 0.026983988 -- Validation loss:0.015494108 -- Test loss 0.06152928\n",
      "Epoch 859: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 860: -- Training loss 0.02692087 -- Validation loss:0.015461613 -- Test loss 0.06157805\n",
      "Epoch 860: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 861: -- Training loss 0.026857927 -- Validation loss:0.015429326 -- Test loss 0.061626248\n",
      "Epoch 861: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 862: -- Training loss 0.026795106 -- Validation loss:0.015396867 -- Test loss 0.06167557\n",
      "Epoch 862: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 863: -- Training loss 0.02673246 -- Validation loss:0.015364754 -- Test loss 0.06172383\n",
      "Epoch 863: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 864: -- Training loss 0.026669953 -- Validation loss:0.015332439 -- Test loss 0.061773058\n",
      "Epoch 864: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 865: -- Training loss 0.026607655 -- Validation loss:0.0153003475 -- Test loss 0.061822176\n",
      "Epoch 865: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 866: -- Training loss 0.02654543 -- Validation loss:0.015268378 -- Test loss 0.061870933\n",
      "Epoch 866: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 867: -- Training loss 0.026483428 -- Validation loss:0.015236232 -- Test loss 0.061920673\n",
      "Epoch 867: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 868: -- Training loss 0.026421519 -- Validation loss:0.015204329 -- Test loss 0.061969653\n",
      "Epoch 868: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 869: -- Training loss 0.026359834 -- Validation loss:0.015172456 -- Test loss 0.062019054\n",
      "Epoch 869: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 870: -- Training loss 0.026298255 -- Validation loss:0.015140531 -- Test loss 0.062069044\n",
      "Epoch 870: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 871: -- Training loss 0.026236832 -- Validation loss:0.015108914 -- Test loss 0.062118087\n",
      "Epoch 871: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 872: -- Training loss 0.026175564 -- Validation loss:0.015077069 -- Test loss 0.06216814\n",
      "Epoch 872: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 873: -- Training loss 0.026114462 -- Validation loss:0.015045437 -- Test loss 0.062217884\n",
      "Epoch 873: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 874: -- Training loss 0.026053527 -- Validation loss:0.01501385 -- Test loss 0.062267747\n",
      "Epoch 874: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 875: -- Training loss 0.025992727 -- Validation loss:0.014982318 -- Test loss 0.062317796\n",
      "Epoch 875: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 876: -- Training loss 0.025932064 -- Validation loss:0.0149508035 -- Test loss 0.06236792\n",
      "Epoch 876: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 877: -- Training loss 0.025871567 -- Validation loss:0.014919394 -- Test loss 0.062417913\n",
      "Epoch 877: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 878: -- Training loss 0.02581119 -- Validation loss:0.014888003 -- Test loss 0.06246838\n",
      "Epoch 878: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 879: -- Training loss 0.025751 -- Validation loss:0.014856697 -- Test loss 0.06251867\n",
      "Epoch 879: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 880: -- Training loss 0.02569094 -- Validation loss:0.014825426 -- Test loss 0.062569134\n",
      "Epoch 880: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 881: -- Training loss 0.025631048 -- Validation loss:0.014794261 -- Test loss 0.062619664\n",
      "Epoch 881: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 882: -- Training loss 0.025571298 -- Validation loss:0.014763068 -- Test loss 0.0626703\n",
      "Epoch 882: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 883: -- Training loss 0.025511691 -- Validation loss:0.014732015 -- Test loss 0.06272084\n",
      "Epoch 883: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 884: -- Training loss 0.02545221 -- Validation loss:0.014700979 -- Test loss 0.06277173\n",
      "Epoch 884: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 885: -- Training loss 0.025392933 -- Validation loss:0.014670006 -- Test loss 0.06282263\n",
      "Epoch 885: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 886: -- Training loss 0.02533377 -- Validation loss:0.014639066 -- Test loss 0.06287358\n",
      "Epoch 886: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 887: -- Training loss 0.02527474 -- Validation loss:0.0146081885 -- Test loss 0.06292471\n",
      "Epoch 887: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 888: -- Training loss 0.025215881 -- Validation loss:0.0145774335 -- Test loss 0.06297566\n",
      "Epoch 888: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 889: -- Training loss 0.025157163 -- Validation loss:0.014546645 -- Test loss 0.06302702\n",
      "Epoch 889: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 890: -- Training loss 0.025098592 -- Validation loss:0.014515895 -- Test loss 0.06307843\n",
      "Epoch 890: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 891: -- Training loss 0.025040165 -- Validation loss:0.014485378 -- Test loss 0.06312922\n",
      "Epoch 891: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 892: -- Training loss 0.024981903 -- Validation loss:0.014454686 -- Test loss 0.063181214\n",
      "Epoch 892: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 893: -- Training loss 0.024923755 -- Validation loss:0.014424226 -- Test loss 0.06323253\n",
      "Epoch 893: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 894: -- Training loss 0.024865752 -- Validation loss:0.014393699 -- Test loss 0.063284114\n",
      "Epoch 894: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 895: -- Training loss 0.024807913 -- Validation loss:0.014363293 -- Test loss 0.063335866\n",
      "Epoch 895: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 896: -- Training loss 0.024750212 -- Validation loss:0.014332924 -- Test loss 0.0633876\n",
      "Epoch 896: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 897: -- Training loss 0.024692673 -- Validation loss:0.014302614 -- Test loss 0.06343938\n",
      "Epoch 897: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 898: -- Training loss 0.024635216 -- Validation loss:0.014272348 -- Test loss 0.06349131\n",
      "Epoch 898: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 899: -- Training loss 0.02457796 -- Validation loss:0.014242142 -- Test loss 0.063543335\n",
      "Epoch 899: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 900: -- Training loss 0.024520824 -- Validation loss:0.014212009 -- Test loss 0.063595265\n",
      "Epoch 900: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 901: -- Training loss 0.02446387 -- Validation loss:0.014181829 -- Test loss 0.063647725\n",
      "Epoch 901: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 902: -- Training loss 0.024407014 -- Validation loss:0.014151891 -- Test loss 0.06369946\n",
      "Epoch 902: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 903: -- Training loss 0.024350312 -- Validation loss:0.014121857 -- Test loss 0.063751966\n",
      "Epoch 903: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 904: -- Training loss 0.024293762 -- Validation loss:0.014091884 -- Test loss 0.06380441\n",
      "Epoch 904: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 905: -- Training loss 0.024237309 -- Validation loss:0.014062119 -- Test loss 0.063856386\n",
      "Epoch 905: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 906: -- Training loss 0.024181034 -- Validation loss:0.014032148 -- Test loss 0.06390951\n",
      "Epoch 906: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 907: -- Training loss 0.024124905 -- Validation loss:0.014002431 -- Test loss 0.06396149\n",
      "Epoch 907: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 908: -- Training loss 0.024068903 -- Validation loss:0.013972717 -- Test loss 0.064014114\n",
      "Epoch 908: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 909: -- Training loss 0.02401305 -- Validation loss:0.013942949 -- Test loss 0.0640673\n",
      "Epoch 909: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 910: -- Training loss 0.023957334 -- Validation loss:0.01391346 -- Test loss 0.064119235\n",
      "Epoch 910: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 911: -- Training loss 0.02390176 -- Validation loss:0.013883767 -- Test loss 0.064172685\n",
      "Epoch 911: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 912: -- Training loss 0.023846319 -- Validation loss:0.013854287 -- Test loss 0.06422546\n",
      "Epoch 912: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 913: -- Training loss 0.023790997 -- Validation loss:0.01382489 -- Test loss 0.064277984\n",
      "Epoch 913: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 914: -- Training loss 0.023735845 -- Validation loss:0.013795334 -- Test loss 0.064331755\n",
      "Epoch 914: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 915: -- Training loss 0.023680815 -- Validation loss:0.013766162 -- Test loss 0.06438394\n",
      "Epoch 915: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 916: -- Training loss 0.02362592 -- Validation loss:0.013736666 -- Test loss 0.06443794\n",
      "Epoch 916: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 917: -- Training loss 0.023571176 -- Validation loss:0.013707538 -- Test loss 0.06449048\n",
      "Epoch 917: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 918: -- Training loss 0.023516549 -- Validation loss:0.0136782825 -- Test loss 0.06454405\n",
      "Epoch 918: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 919: -- Training loss 0.02346208 -- Validation loss:0.013649146 -- Test loss 0.06459739\n",
      "Epoch 919: -- Training acc  1.0 -- Validation acc: 1.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Test acc  0.96\n",
      "Epoch 920: -- Training loss 0.023407733 -- Validation loss:0.013620052 -- Test loss 0.064650506\n",
      "Epoch 920: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 921: -- Training loss 0.023353502 -- Validation loss:0.013590966 -- Test loss 0.064704165\n",
      "Epoch 921: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 922: -- Training loss 0.023299448 -- Validation loss:0.013561964 -- Test loss 0.064757526\n",
      "Epoch 922: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 923: -- Training loss 0.023245502 -- Validation loss:0.01353306 -- Test loss 0.06481101\n",
      "Epoch 923: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 924: -- Training loss 0.02319169 -- Validation loss:0.013504143 -- Test loss 0.064864814\n",
      "Epoch 924: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 925: -- Training loss 0.023138005 -- Validation loss:0.013475299 -- Test loss 0.064918324\n",
      "Epoch 925: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 926: -- Training loss 0.023084464 -- Validation loss:0.013446485 -- Test loss 0.064972386\n",
      "Epoch 926: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 927: -- Training loss 0.023031082 -- Validation loss:0.0134178 -- Test loss 0.065025695\n",
      "Epoch 927: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 928: -- Training loss 0.022977797 -- Validation loss:0.0133890435 -- Test loss 0.06507975\n",
      "Epoch 928: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 929: -- Training loss 0.022924645 -- Validation loss:0.013360403 -- Test loss 0.0651338\n",
      "Epoch 929: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 930: -- Training loss 0.022871632 -- Validation loss:0.013331871 -- Test loss 0.06518724\n",
      "Epoch 930: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 931: -- Training loss 0.022818763 -- Validation loss:0.013303231 -- Test loss 0.06524169\n",
      "Epoch 931: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 932: -- Training loss 0.022766035 -- Validation loss:0.013274786 -- Test loss 0.06529562\n",
      "Epoch 932: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 933: -- Training loss 0.02271341 -- Validation loss:0.013246396 -- Test loss 0.06534957\n",
      "Epoch 933: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 934: -- Training loss 0.022660913 -- Validation loss:0.013217882 -- Test loss 0.06540427\n",
      "Epoch 934: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 935: -- Training loss 0.02260857 -- Validation loss:0.013189697 -- Test loss 0.06545773\n",
      "Epoch 935: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 936: -- Training loss 0.022556359 -- Validation loss:0.013161283 -- Test loss 0.06551262\n",
      "Epoch 936: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 937: -- Training loss 0.022504274 -- Validation loss:0.0131331375 -- Test loss 0.06556654\n",
      "Epoch 937: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 938: -- Training loss 0.022452293 -- Validation loss:0.01310492 -- Test loss 0.06562097\n",
      "Epoch 938: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 939: -- Training loss 0.022400467 -- Validation loss:0.0130766975 -- Test loss 0.06567566\n",
      "Epoch 939: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 940: -- Training loss 0.022348776 -- Validation loss:0.013048765 -- Test loss 0.06572937\n",
      "Epoch 940: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 941: -- Training loss 0.022297174 -- Validation loss:0.013020503 -- Test loss 0.06578496\n",
      "Epoch 941: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 942: -- Training loss 0.02224573 -- Validation loss:0.01299272 -- Test loss 0.06583852\n",
      "Epoch 942: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 943: -- Training loss 0.02219442 -- Validation loss:0.0129646985 -- Test loss 0.0658935\n",
      "Epoch 943: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 944: -- Training loss 0.022143206 -- Validation loss:0.012936733 -- Test loss 0.06594838\n",
      "Epoch 944: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 945: -- Training loss 0.022092154 -- Validation loss:0.0129090585 -- Test loss 0.06600226\n",
      "Epoch 945: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 946: -- Training loss 0.022041226 -- Validation loss:0.012881064 -- Test loss 0.06605803\n",
      "Epoch 946: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 947: -- Training loss 0.02199038 -- Validation loss:0.012853469 -- Test loss 0.06611225\n",
      "Epoch 947: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 948: -- Training loss 0.021939714 -- Validation loss:0.012825795 -- Test loss 0.06616697\n",
      "Epoch 948: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 949: -- Training loss 0.021889174 -- Validation loss:0.012797969 -- Test loss 0.066222504\n",
      "Epoch 949: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 950: -- Training loss 0.021838695 -- Validation loss:0.01277063 -- Test loss 0.06627629\n",
      "Epoch 950: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 951: -- Training loss 0.021788415 -- Validation loss:0.012742844 -- Test loss 0.066332586\n",
      "Epoch 951: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 952: -- Training loss 0.02173822 -- Validation loss:0.012715523 -- Test loss 0.0663866\n",
      "Epoch 952: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 953: -- Training loss 0.021688169 -- Validation loss:0.012687995 -- Test loss 0.06644194\n",
      "Epoch 953: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 954: -- Training loss 0.02163821 -- Validation loss:0.012660541 -- Test loss 0.066497356\n",
      "Epoch 954: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 955: -- Training loss 0.021588411 -- Validation loss:0.012633395 -- Test loss 0.06655142\n",
      "Epoch 955: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 956: -- Training loss 0.021538703 -- Validation loss:0.0126058 -- Test loss 0.06660799\n",
      "Epoch 956: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 957: -- Training loss 0.021489147 -- Validation loss:0.012578796 -- Test loss 0.06666187\n",
      "Epoch 957: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 958: -- Training loss 0.02143971 -- Validation loss:0.012551453 -- Test loss 0.066717826\n",
      "Epoch 958: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 959: -- Training loss 0.021390386 -- Validation loss:0.012524284 -- Test loss 0.06677324\n",
      "Epoch 959: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 960: -- Training loss 0.021341186 -- Validation loss:0.012497361 -- Test loss 0.066827536\n",
      "Epoch 960: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 961: -- Training loss 0.021292126 -- Validation loss:0.012470069 -- Test loss 0.06688417\n",
      "Epoch 961: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 962: -- Training loss 0.021243157 -- Validation loss:0.012443216 -- Test loss 0.06693865\n",
      "Epoch 962: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 963: -- Training loss 0.021194315 -- Validation loss:0.012416247 -- Test loss 0.06699421\n",
      "Epoch 963: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 964: -- Training loss 0.021145608 -- Validation loss:0.012389198 -- Test loss 0.06705037\n",
      "Epoch 964: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 965: -- Training loss 0.021097014 -- Validation loss:0.012362544 -- Test loss 0.06710476\n",
      "Epoch 965: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 966: -- Training loss 0.021048537 -- Validation loss:0.01233558 -- Test loss 0.06716126\n",
      "Epoch 966: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 967: -- Training loss 0.021000199 -- Validation loss:0.012308836 -- Test loss 0.06721649\n",
      "Epoch 967: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 968: -- Training loss 0.020951936 -- Validation loss:0.012282233 -- Test loss 0.06727158\n",
      "Epoch 968: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 969: -- Training loss 0.020903839 -- Validation loss:0.012255379 -- Test loss 0.06732823\n",
      "Epoch 969: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 970: -- Training loss 0.0208558 -- Validation loss:0.012228961 -- Test loss 0.06738282\n",
      "Epoch 970: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 971: -- Training loss 0.020807939 -- Validation loss:0.012202251 -- Test loss 0.067439176\n",
      "Epoch 971: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 972: -- Training loss 0.020760186 -- Validation loss:0.01217577 -- Test loss 0.06749469\n",
      "Epoch 972: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 973: -- Training loss 0.020712543 -- Validation loss:0.012149311 -- Test loss 0.06755032\n",
      "Epoch 973: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 974: -- Training loss 0.020665 -- Validation loss:0.012122867 -- Test loss 0.06760635\n",
      "Epoch 974: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 975: -- Training loss 0.020617591 -- Validation loss:0.012096533 -- Test loss 0.06766183\n",
      "Epoch 975: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 976: -- Training loss 0.020570287 -- Validation loss:0.012070116 -- Test loss 0.06771808\n",
      "Epoch 976: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 977: -- Training loss 0.020523135 -- Validation loss:0.012043909 -- Test loss 0.06777347\n",
      "Epoch 977: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 978: -- Training loss 0.020476053 -- Validation loss:0.012017578 -- Test loss 0.06782992\n",
      "Epoch 978: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 979: -- Training loss 0.020429121 -- Validation loss:0.011991542 -- Test loss 0.06788514\n",
      "Epoch 979: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 980: -- Training loss 0.020382304 -- Validation loss:0.011965289 -- Test loss 0.06794171\n",
      "Epoch 980: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "Epoch 981: -- Training loss 0.020335572 -- Validation loss:0.011939268 -- Test loss 0.067997344\n",
      "Epoch 981: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 982: -- Training loss 0.020288989 -- Validation loss:0.011913179 -- Test loss 0.06805351\n",
      "Epoch 982: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 983: -- Training loss 0.020242471 -- Validation loss:0.01188717 -- Test loss 0.068109594\n",
      "Epoch 983: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 984: -- Training loss 0.020196134 -- Validation loss:0.0118612675 -- Test loss 0.06816548\n",
      "Epoch 984: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 985: -- Training loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020149862 -- Validation loss:0.011835269 -- Test loss 0.06822199\n",
      "Epoch 985: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 986: -- Training loss 0.020103713 -- Validation loss:0.011809553 -- Test loss 0.06827759\n",
      "Epoch 986: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 987: -- Training loss 0.020057695 -- Validation loss:0.011783659 -- Test loss 0.06833433\n",
      "Epoch 987: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 988: -- Training loss 0.020011779 -- Validation loss:0.011757958 -- Test loss 0.06839008\n",
      "Epoch 988: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 989: -- Training loss 0.019965976 -- Validation loss:0.01173228 -- Test loss 0.06844615\n",
      "Epoch 989: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 990: -- Training loss 0.019920276 -- Validation loss:0.011706469 -- Test loss 0.06850317\n",
      "Epoch 990: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 991: -- Training loss 0.019874685 -- Validation loss:0.01168105 -- Test loss 0.0685581\n",
      "Epoch 991: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 992: -- Training loss 0.01982923 -- Validation loss:0.011655301 -- Test loss 0.06861564\n",
      "Epoch 992: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 993: -- Training loss 0.019783903 -- Validation loss:0.01162995 -- Test loss 0.068670996\n",
      "Epoch 993: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 994: -- Training loss 0.019738635 -- Validation loss:0.011604368 -- Test loss 0.068727836\n",
      "Epoch 994: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 995: -- Training loss 0.01969351 -- Validation loss:0.011578987 -- Test loss 0.06878395\n",
      "Epoch 995: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 996: -- Training loss 0.01964848 -- Validation loss:0.011553613 -- Test loss 0.06884017\n",
      "Epoch 996: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 997: -- Training loss 0.019603567 -- Validation loss:0.011528242 -- Test loss 0.06889678\n",
      "Epoch 997: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 998: -- Training loss 0.019558746 -- Validation loss:0.011503051 -- Test loss 0.06895282\n",
      "Epoch 998: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 999: -- Training loss 0.019514045 -- Validation loss:0.01147775 -- Test loss 0.06900975\n",
      "Epoch 999: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 1000: -- Training loss 0.019469477 -- Validation loss:0.01145265 -- Test loss 0.069065474\n",
      "Epoch 1000: -- Training acc  1.0 -- Validation acc: 1.0 -- Test acc  0.96\n",
      "Epoch 0: -- Training loss 1.1628685 -- Validation loss:1.2084945 -- Test loss 1.1867625\n",
      "Epoch 1: -- Training loss 1.1515971 -- Validation loss:1.19357 -- Test loss 1.1736835\n",
      "Epoch 1: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 2: -- Training loss 1.1414355 -- Validation loss:1.179846 -- Test loss 1.1617433\n",
      "Epoch 2: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 3: -- Training loss 1.132305 -- Validation loss:1.1672212 -- Test loss 1.1508548\n",
      "Epoch 3: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 4: -- Training loss 1.1241536 -- Validation loss:1.1556449 -- Test loss 1.1409695\n",
      "Epoch 4: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 5: -- Training loss 1.1169454 -- Validation loss:1.145083 -- Test loss 1.1320561\n",
      "Epoch 5: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 6: -- Training loss 1.1106416 -- Validation loss:1.1354997 -- Test loss 1.1240811\n",
      "Epoch 6: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 7: -- Training loss 1.1051964 -- Validation loss:1.1268559 -- Test loss 1.117004\n",
      "Epoch 7: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 8: -- Training loss 1.1005572 -- Validation loss:1.1191058 -- Test loss 1.1107779\n",
      "Epoch 8: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 9: -- Training loss 1.0966642 -- Validation loss:1.1121995 -- Test loss 1.1053492\n",
      "Epoch 9: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 10: -- Training loss 1.0934508 -- Validation loss:1.1060823 -- Test loss 1.1006579\n",
      "Epoch 10: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 11: -- Training loss 1.0908452 -- Validation loss:1.1006945 -- Test loss 1.0966393\n",
      "Epoch 11: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 12: -- Training loss 1.0887712 -- Validation loss:1.0959749 -- Test loss 1.0932237\n",
      "Epoch 12: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 13: -- Training loss 1.0871495 -- Validation loss:1.0918595 -- Test loss 1.0903392\n",
      "Epoch 13: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 14: -- Training loss 1.0858991 -- Validation loss:1.0882832 -- Test loss 1.0879117\n",
      "Epoch 14: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 15: -- Training loss 1.0849398 -- Validation loss:1.0851809 -- Test loss 1.0858675\n",
      "Epoch 15: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 16: -- Training loss 1.0841931 -- Validation loss:1.0824891 -- Test loss 1.0841343\n",
      "Epoch 16: -- Training acc  0.3380281690140845 -- Validation acc: 0.2916666666666667 -- Test acc  0.48\n",
      "Epoch 17: -- Training loss 1.0835841 -- Validation loss:1.0801458 -- Test loss 1.0826428\n",
      "Epoch 17: -- Training acc  0.39436619718309857 -- Validation acc: 0.4166666666666667 -- Test acc  0.44\n",
      "Epoch 18: -- Training loss 1.0830456 -- Validation loss:1.0780932 -- Test loss 1.081329\n",
      "Epoch 18: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 19: -- Training loss 1.0825181 -- Validation loss:1.0762776 -- Test loss 1.080135\n",
      "Epoch 19: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 20: -- Training loss 1.0819519 -- Validation loss:1.0746514 -- Test loss 1.079012\n",
      "Epoch 20: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 21: -- Training loss 1.0813081 -- Validation loss:1.0731728 -- Test loss 1.07792\n",
      "Epoch 21: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 22: -- Training loss 1.0805587 -- Validation loss:1.0718085 -- Test loss 1.0768273\n",
      "Epoch 22: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 23: -- Training loss 1.0796863 -- Validation loss:1.070531 -- Test loss 1.0757118\n",
      "Epoch 23: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 24: -- Training loss 1.0786818 -- Validation loss:1.0693201 -- Test loss 1.0745596\n",
      "Epoch 24: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 25: -- Training loss 1.0775458 -- Validation loss:1.0681608 -- Test loss 1.0733628\n",
      "Epoch 25: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 26: -- Training loss 1.0762832 -- Validation loss:1.067043 -- Test loss 1.0721197\n",
      "Epoch 26: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 27: -- Training loss 1.0749047 -- Validation loss:1.0659608 -- Test loss 1.070832\n",
      "Epoch 27: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 28: -- Training loss 1.0734227 -- Validation loss:1.0649095 -- Test loss 1.0695055\n",
      "Epoch 28: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 29: -- Training loss 1.0718528 -- Validation loss:1.0638868 -- Test loss 1.0681454\n",
      "Epoch 29: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 30: -- Training loss 1.0702097 -- Validation loss:1.0628899 -- Test loss 1.0667583\n",
      "Epoch 30: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 31: -- Training loss 1.0685076 -- Validation loss:1.061916 -- Test loss 1.0653495\n",
      "Epoch 31: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 32: -- Training loss 1.0667588 -- Validation loss:1.0609605 -- Test loss 1.0639228\n",
      "Epoch 32: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 33: -- Training loss 1.0649725 -- Validation loss:1.0600172 -- Test loss 1.0624795\n",
      "Epoch 33: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 34: -- Training loss 1.0631564 -- Validation loss:1.0590771 -- Test loss 1.0610187\n",
      "Epoch 34: -- Training acc  0.36619718309859156 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 35: -- Training loss 1.061314 -- Validation loss:1.0581294 -- Test loss 1.0595361\n",
      "Epoch 35: -- Training acc  0.4647887323943662 -- Validation acc: 0.5416666666666666 -- Test acc  0.48\n",
      "Epoch 36: -- Training loss 1.0594455 -- Validation loss:1.0571603 -- Test loss 1.0580249\n",
      "Epoch 36: -- Training acc  0.5774647887323944 -- Validation acc: 0.625 -- Test acc  0.52\n",
      "Epoch 37: -- Training loss 1.0575485 -- Validation loss:1.056154 -- Test loss 1.0564755\n",
      "Epoch 37: -- Training acc  0.5211267605633803 -- Validation acc: 0.5416666666666666 -- Test acc  0.64\n",
      "Epoch 38: -- Training loss 1.0556175 -- Validation loss:1.055093 -- Test loss 1.0548762\n",
      "Epoch 38: -- Training acc  0.4225352112676056 -- Validation acc: 0.3333333333333333 -- Test acc  0.48\n",
      "Epoch 39: -- Training loss 1.0536448 -- Validation loss:1.0539583 -- Test loss 1.053213\n",
      "Epoch 39: -- Training acc  0.39436619718309857 -- Validation acc: 0.3333333333333333 -- Test acc  0.4\n",
      "Epoch 40: -- Training loss 1.0516207 -- Validation loss:1.0527298 -- Test loss 1.0514716\n",
      "Epoch 40: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38028169014084506 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 41: -- Training loss 1.0495346 -- Validation loss:1.0513885 -- Test loss 1.049637\n",
      "Epoch 41: -- Training acc  0.38028169014084506 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 42: -- Training loss 1.0473756 -- Validation loss:1.0499157 -- Test loss 1.0476943\n",
      "Epoch 42: -- Training acc  0.38028169014084506 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 43: -- Training loss 1.0451325 -- Validation loss:1.0482947 -- Test loss 1.0456295\n",
      "Epoch 43: -- Training acc  0.38028169014084506 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 44: -- Training loss 1.042795 -- Validation loss:1.0465108 -- Test loss 1.043431\n",
      "Epoch 44: -- Training acc  0.4225352112676056 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 45: -- Training loss 1.0403543 -- Validation loss:1.0445522 -- Test loss 1.0410886\n",
      "Epoch 45: -- Training acc  0.4225352112676056 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 46: -- Training loss 1.0378023 -- Validation loss:1.0424104 -- Test loss 1.0385948\n",
      "Epoch 46: -- Training acc  0.4647887323943662 -- Validation acc: 0.5 -- Test acc  0.44\n",
      "Epoch 47: -- Training loss 1.0351334 -- Validation loss:1.0400797 -- Test loss 1.0359435\n",
      "Epoch 47: -- Training acc  0.5774647887323944 -- Validation acc: 0.5416666666666666 -- Test acc  0.56\n",
      "Epoch 48: -- Training loss 1.0323426 -- Validation loss:1.0375582 -- Test loss 1.033132\n",
      "Epoch 48: -- Training acc  0.6056338028169014 -- Validation acc: 0.5416666666666666 -- Test acc  0.56\n",
      "Epoch 49: -- Training loss 1.0294267 -- Validation loss:1.0348457 -- Test loss 1.0301589\n",
      "Epoch 49: -- Training acc  0.6338028169014085 -- Validation acc: 0.5416666666666666 -- Test acc  0.64\n",
      "Epoch 50: -- Training loss 1.0263838 -- Validation loss:1.0319456 -- Test loss 1.027025\n",
      "Epoch 50: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 51: -- Training loss 1.0232126 -- Validation loss:1.0288624 -- Test loss 1.0237328\n",
      "Epoch 51: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 52: -- Training loss 1.0199126 -- Validation loss:1.0256025 -- Test loss 1.020285\n",
      "Epoch 52: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 53: -- Training loss 1.0164837 -- Validation loss:1.0221738 -- Test loss 1.0166856\n",
      "Epoch 53: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 54: -- Training loss 1.0129259 -- Validation loss:1.0185834 -- Test loss 1.0129385\n",
      "Epoch 54: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 55: -- Training loss 1.0092386 -- Validation loss:1.0148404 -- Test loss 1.0090477\n",
      "Epoch 55: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 56: -- Training loss 1.0054219 -- Validation loss:1.0109516 -- Test loss 1.0050173\n",
      "Epoch 56: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 57: -- Training loss 1.0014747 -- Validation loss:1.0069252 -- Test loss 1.00085\n",
      "Epoch 57: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 58: -- Training loss 0.99739593 -- Validation loss:1.0027672 -- Test loss 0.9965489\n",
      "Epoch 58: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 59: -- Training loss 0.99318427 -- Validation loss:0.9984843 -- Test loss 0.99211586\n",
      "Epoch 59: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 60: -- Training loss 0.9888385 -- Validation loss:0.9940813 -- Test loss 0.9875529\n",
      "Epoch 60: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 61: -- Training loss 0.98435694 -- Validation loss:0.9895625 -- Test loss 0.98286116\n",
      "Epoch 61: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 62: -- Training loss 0.9797385 -- Validation loss:0.9849324 -- Test loss 0.9780419\n",
      "Epoch 62: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 63: -- Training loss 0.9749819 -- Validation loss:0.9801937 -- Test loss 0.97309566\n",
      "Epoch 63: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 64: -- Training loss 0.97008646 -- Validation loss:0.9753491 -- Test loss 0.9680233\n",
      "Epoch 64: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 65: -- Training loss 0.9650518 -- Validation loss:0.9704005 -- Test loss 0.9628253\n",
      "Epoch 65: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 66: -- Training loss 0.95987797 -- Validation loss:0.9653501 -- Test loss 0.9575024\n",
      "Epoch 66: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 67: -- Training loss 0.95456576 -- Validation loss:0.96019894 -- Test loss 0.9520558\n",
      "Epoch 67: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 68: -- Training loss 0.94911647 -- Validation loss:0.9549486 -- Test loss 0.94648635\n",
      "Epoch 68: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 69: -- Training loss 0.94353205 -- Validation loss:0.9495998 -- Test loss 0.94079554\n",
      "Epoch 69: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 70: -- Training loss 0.93781453 -- Validation loss:0.94415385 -- Test loss 0.9349848\n",
      "Epoch 70: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 71: -- Training loss 0.9319672 -- Validation loss:0.9386115 -- Test loss 0.92905617\n",
      "Epoch 71: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 72: -- Training loss 0.92599356 -- Validation loss:0.9329739 -- Test loss 0.92301196\n",
      "Epoch 72: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 73: -- Training loss 0.9198975 -- Validation loss:0.9272421 -- Test loss 0.9168546\n",
      "Epoch 73: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 74: -- Training loss 0.9136836 -- Validation loss:0.9214175 -- Test loss 0.9105871\n",
      "Epoch 74: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 75: -- Training loss 0.9073564 -- Validation loss:0.9155012 -- Test loss 0.9042128\n",
      "Epoch 75: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 76: -- Training loss 0.9009212 -- Validation loss:0.90949535 -- Test loss 0.89773536\n",
      "Epoch 76: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 77: -- Training loss 0.89438385 -- Validation loss:0.9034018 -- Test loss 0.8911589\n",
      "Epoch 77: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 78: -- Training loss 0.8877501 -- Validation loss:0.89722306 -- Test loss 0.8844883\n",
      "Epoch 78: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 79: -- Training loss 0.8810263 -- Validation loss:0.8909619 -- Test loss 0.8777283\n",
      "Epoch 79: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 80: -- Training loss 0.874219 -- Validation loss:0.88462204 -- Test loss 0.8708842\n",
      "Epoch 80: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 81: -- Training loss 0.8673353 -- Validation loss:0.8782069 -- Test loss 0.86396265\n",
      "Epoch 81: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 82: -- Training loss 0.86038226 -- Validation loss:0.87172157 -- Test loss 0.85696983\n",
      "Epoch 82: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 83: -- Training loss 0.8533675 -- Validation loss:0.8651707 -- Test loss 0.8499131\n",
      "Epoch 83: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 84: -- Training loss 0.8462988 -- Validation loss:0.85856 -- Test loss 0.8427998\n",
      "Epoch 84: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 85: -- Training loss 0.8391843 -- Validation loss:0.8518956 -- Test loss 0.835638\n",
      "Epoch 85: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 86: -- Training loss 0.8320321 -- Validation loss:0.8451841 -- Test loss 0.82843614\n",
      "Epoch 86: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 87: -- Training loss 0.82485044 -- Validation loss:0.83843285 -- Test loss 0.82120275\n",
      "Epoch 87: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 88: -- Training loss 0.8176481 -- Validation loss:0.83164907 -- Test loss 0.8139471\n",
      "Epoch 88: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 89: -- Training loss 0.81043357 -- Validation loss:0.82484126 -- Test loss 0.8066783\n",
      "Epoch 89: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 90: -- Training loss 0.8032156 -- Validation loss:0.8180174 -- Test loss 0.79940534\n",
      "Epoch 90: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 91: -- Training loss 0.7960027 -- Validation loss:0.8111861 -- Test loss 0.7921379\n",
      "Epoch 91: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 92: -- Training loss 0.7888034 -- Validation loss:0.8043559 -- Test loss 0.78488517\n",
      "Epoch 92: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 93: -- Training loss 0.7816263 -- Validation loss:0.7975359 -- Test loss 0.7776564\n",
      "Epoch 93: -- Training acc  0.6619718309859155 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 94: -- Training loss 0.77447957 -- Validation loss:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7907346 -- Test loss 0.7704604\n",
      "Epoch 94: -- Training acc  0.6619718309859155 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 95: -- Training loss 0.76737136 -- Validation loss:0.7839608 -- Test loss 0.763306\n",
      "Epoch 95: -- Training acc  0.6619718309859155 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 96: -- Training loss 0.76030976 -- Validation loss:0.7772234 -- Test loss 0.756202\n",
      "Epoch 96: -- Training acc  0.6619718309859155 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 97: -- Training loss 0.7533021 -- Validation loss:0.7705307 -- Test loss 0.7491558\n",
      "Epoch 97: -- Training acc  0.6619718309859155 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 98: -- Training loss 0.7463559 -- Validation loss:0.76389056 -- Test loss 0.74217576\n",
      "Epoch 98: -- Training acc  0.6619718309859155 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 99: -- Training loss 0.7394782 -- Validation loss:0.75731105 -- Test loss 0.7352688\n",
      "Epoch 99: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 100: -- Training loss 0.73267543 -- Validation loss:0.7507994 -- Test loss 0.728442\n",
      "Epoch 100: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 101: -- Training loss 0.725954 -- Validation loss:0.74436253 -- Test loss 0.72170156\n",
      "Epoch 101: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 102: -- Training loss 0.7193197 -- Validation loss:0.73800683 -- Test loss 0.71505356\n",
      "Epoch 102: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 103: -- Training loss 0.7127779 -- Validation loss:0.7317383 -- Test loss 0.708503\n",
      "Epoch 103: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 104: -- Training loss 0.7063335 -- Validation loss:0.72556233 -- Test loss 0.70205545\n",
      "Epoch 104: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 105: -- Training loss 0.6999914 -- Validation loss:0.71948344 -- Test loss 0.6957149\n",
      "Epoch 105: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 106: -- Training loss 0.69375527 -- Validation loss:0.7135059 -- Test loss 0.6894855\n",
      "Epoch 106: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 107: -- Training loss 0.6876289 -- Validation loss:0.70763355 -- Test loss 0.68337053\n",
      "Epoch 107: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 108: -- Training loss 0.6816156 -- Validation loss:0.7018691 -- Test loss 0.6773732\n",
      "Epoch 108: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 109: -- Training loss 0.67571795 -- Validation loss:0.6962152 -- Test loss 0.671496\n",
      "Epoch 109: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 110: -- Training loss 0.6699383 -- Validation loss:0.69067407 -- Test loss 0.66574097\n",
      "Epoch 110: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 111: -- Training loss 0.66427857 -- Validation loss:0.68524724 -- Test loss 0.6601101\n",
      "Epoch 111: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 112: -- Training loss 0.6587401 -- Validation loss:0.6799355 -- Test loss 0.65460426\n",
      "Epoch 112: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 113: -- Training loss 0.65332395 -- Validation loss:0.67473984 -- Test loss 0.64922464\n",
      "Epoch 113: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 114: -- Training loss 0.6480308 -- Validation loss:0.6696605 -- Test loss 0.64397156\n",
      "Epoch 114: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 115: -- Training loss 0.6428612 -- Validation loss:0.6646974 -- Test loss 0.63884515\n",
      "Epoch 115: -- Training acc  0.676056338028169 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 116: -- Training loss 0.6378147 -- Validation loss:0.6598502 -- Test loss 0.63384527\n",
      "Epoch 116: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.64\n",
      "Epoch 117: -- Training loss 0.63289106 -- Validation loss:0.6551183 -- Test loss 0.6289711\n",
      "Epoch 117: -- Training acc  0.676056338028169 -- Validation acc: 0.6666666666666666 -- Test acc  0.64\n",
      "Epoch 118: -- Training loss 0.6280896 -- Validation loss:0.65050083 -- Test loss 0.62422204\n",
      "Epoch 118: -- Training acc  0.6901408450704225 -- Validation acc: 0.6666666666666666 -- Test acc  0.64\n",
      "Epoch 119: -- Training loss 0.62340945 -- Validation loss:0.645997 -- Test loss 0.61959684\n",
      "Epoch 119: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 120: -- Training loss 0.61884904 -- Validation loss:0.64160514 -- Test loss 0.615094\n",
      "Epoch 120: -- Training acc  0.704225352112676 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 121: -- Training loss 0.61440706 -- Validation loss:0.6373243 -- Test loss 0.61071205\n",
      "Epoch 121: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 122: -- Training loss 0.61008173 -- Validation loss:0.63315254 -- Test loss 0.606449\n",
      "Epoch 122: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 123: -- Training loss 0.6058712 -- Validation loss:0.62908846 -- Test loss 0.6023028\n",
      "Epoch 123: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 124: -- Training loss 0.60177314 -- Validation loss:0.6251301 -- Test loss 0.5982713\n",
      "Epoch 124: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 125: -- Training loss 0.59778553 -- Validation loss:0.6212758 -- Test loss 0.59435195\n",
      "Epoch 125: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 126: -- Training loss 0.59390575 -- Validation loss:0.6175234 -- Test loss 0.59054255\n",
      "Epoch 126: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 127: -- Training loss 0.59013134 -- Validation loss:0.6138708 -- Test loss 0.58684015\n",
      "Epoch 127: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 128: -- Training loss 0.58645964 -- Validation loss:0.6103161 -- Test loss 0.5832424\n",
      "Epoch 128: -- Training acc  0.7183098591549296 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 129: -- Training loss 0.58288795 -- Validation loss:0.6068569 -- Test loss 0.57974637\n",
      "Epoch 129: -- Training acc  0.7323943661971831 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 130: -- Training loss 0.57941335 -- Validation loss:0.6034911 -- Test loss 0.57634926\n",
      "Epoch 130: -- Training acc  0.7605633802816901 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 131: -- Training loss 0.57603306 -- Validation loss:0.6002163 -- Test loss 0.57304823\n",
      "Epoch 131: -- Training acc  0.7605633802816901 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 132: -- Training loss 0.57274413 -- Validation loss:0.59703016 -- Test loss 0.5698403\n",
      "Epoch 132: -- Training acc  0.7605633802816901 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 133: -- Training loss 0.5695437 -- Validation loss:0.5939302 -- Test loss 0.5667226\n",
      "Epoch 133: -- Training acc  0.7605633802816901 -- Validation acc: 0.6666666666666666 -- Test acc  0.68\n",
      "Epoch 134: -- Training loss 0.5664286 -- Validation loss:0.590914 -- Test loss 0.56369215\n",
      "Epoch 134: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 135: -- Training loss 0.563396 -- Validation loss:0.5879792 -- Test loss 0.560746\n",
      "Epoch 135: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 136: -- Training loss 0.56044286 -- Validation loss:0.58512306 -- Test loss 0.5578812\n",
      "Epoch 136: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 137: -- Training loss 0.5575662 -- Validation loss:0.582343 -- Test loss 0.5550949\n",
      "Epoch 137: -- Training acc  0.7605633802816901 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 138: -- Training loss 0.554763 -- Validation loss:0.57963645 -- Test loss 0.552384\n",
      "Epoch 138: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 139: -- Training loss 0.55203056 -- Validation loss:0.5770009 -- Test loss 0.54974556\n",
      "Epoch 139: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 140: -- Training loss 0.54936564 -- Validation loss:0.5744335 -- Test loss 0.5471767\n",
      "Epoch 140: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.68\n",
      "Epoch 141: -- Training loss 0.5467655 -- Validation loss:0.57193184 -- Test loss 0.54467446\n",
      "Epoch 141: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 142: -- Training loss 0.5442273 -- Validation loss:0.5694931 -- Test loss 0.54223603\n",
      "Epoch 142: -- Training acc  0.7746478873239436 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 143: -- Training loss 0.54174805 -- Validation loss:0.56711465 -- Test loss 0.53985864\n",
      "Epoch 143: -- Training acc  0.7746478873239436 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 144: -- Training loss 0.5393253 -- Validation loss:0.564794 -- Test loss 0.5375394\n",
      "Epoch 144: -- Training acc  0.7746478873239436 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 145: -- Training loss 0.53695595 -- Validation loss:0.5625285 -- Test loss 0.5352756\n",
      "Epoch 145: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 146: -- Training loss 0.5346374 -- Validation loss:0.5603155 -- Test loss 0.53306425\n",
      "Epoch 146: -- Training acc  0.8028169014084507 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 147: -- Training loss 0.5323671 -- Validation loss:0.55815244 -- Test loss 0.53090304\n",
      "Epoch 147: -- Training acc  0.8028169014084507 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 148: -- Training loss 0.5301424 -- Validation loss:0.55603695 -- Test loss 0.52878904\n",
      "Epoch 148: -- Training acc  0.8028169014084507 -- Validation acc: 0.7916666666666666 -- Test acc  0.72"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 149: -- Training loss 0.5279609 -- Validation loss:0.55396646 -- Test loss 0.5267199\n",
      "Epoch 149: -- Training acc  0.8028169014084507 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 150: -- Training loss 0.52581984 -- Validation loss:0.55193865 -- Test loss 0.52469295\n",
      "Epoch 150: -- Training acc  0.8028169014084507 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 151: -- Training loss 0.52371687 -- Validation loss:0.549951 -- Test loss 0.5227057\n",
      "Epoch 151: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 152: -- Training loss 0.52164966 -- Validation loss:0.54800135 -- Test loss 0.52075565\n",
      "Epoch 152: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 153: -- Training loss 0.51961565 -- Validation loss:0.54608756 -- Test loss 0.5188406\n",
      "Epoch 153: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 154: -- Training loss 0.51761276 -- Validation loss:0.54420716 -- Test loss 0.516958\n",
      "Epoch 154: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 155: -- Training loss 0.51563865 -- Validation loss:0.5423583 -- Test loss 0.5151059\n",
      "Epoch 155: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 156: -- Training loss 0.51369095 -- Validation loss:0.5405387 -- Test loss 0.51328176\n",
      "Epoch 156: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 157: -- Training loss 0.5117678 -- Validation loss:0.53874665 -- Test loss 0.5114837\n",
      "Epoch 157: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 158: -- Training loss 0.5098668 -- Validation loss:0.53698003 -- Test loss 0.50970954\n",
      "Epoch 158: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 159: -- Training loss 0.507986 -- Validation loss:0.535237 -- Test loss 0.50795704\n",
      "Epoch 159: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 160: -- Training loss 0.5061233 -- Validation loss:0.5335159 -- Test loss 0.5062246\n",
      "Epoch 160: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 161: -- Training loss 0.5042768 -- Validation loss:0.53181475 -- Test loss 0.50450987\n",
      "Epoch 161: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 162: -- Training loss 0.5024445 -- Validation loss:0.5301319 -- Test loss 0.50281125\n",
      "Epoch 162: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 163: -- Training loss 0.5006245 -- Validation loss:0.5284658 -- Test loss 0.50112677\n",
      "Epoch 163: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 164: -- Training loss 0.49881485 -- Validation loss:0.5268147 -- Test loss 0.49945477\n",
      "Epoch 164: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 165: -- Training loss 0.49701405 -- Validation loss:0.525177 -- Test loss 0.49779338\n",
      "Epoch 165: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 166: -- Training loss 0.49522004 -- Validation loss:0.5235513 -- Test loss 0.49614093\n",
      "Epoch 166: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 167: -- Training loss 0.4934312 -- Validation loss:0.521936 -- Test loss 0.49449566\n",
      "Epoch 167: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 168: -- Training loss 0.4916458 -- Validation loss:0.5203298 -- Test loss 0.4928562\n",
      "Epoch 168: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 169: -- Training loss 0.48986226 -- Validation loss:0.51873094 -- Test loss 0.49122077\n",
      "Epoch 169: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 170: -- Training loss 0.48807907 -- Validation loss:0.51713824 -- Test loss 0.48958796\n",
      "Epoch 170: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.84\n",
      "Epoch 171: -- Training loss 0.4862946 -- Validation loss:0.51555026 -- Test loss 0.4879562\n",
      "Epoch "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171: -- Training acc  0.8732394366197183 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 172: -- Training loss 0.48450738 -- Validation loss:0.51396567 -- Test loss 0.486324\n",
      "Epoch 172: -- Training acc  0.8873239436619719 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 173: -- Training loss 0.48271587 -- Validation loss:0.51238304 -- Test loss 0.48469016\n",
      "Epoch 173: -- Training acc  0.9014084507042254 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 174: -- Training loss 0.48091877 -- Validation loss:0.51080126 -- Test loss 0.48305318\n",
      "Epoch 174: -- Training acc  0.9014084507042254 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 175: -- Training loss 0.47911486 -- Validation loss:0.50921893 -- Test loss 0.4814118\n",
      "Epoch 175: -- Training acc  0.9014084507042254 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 176: -- Training loss 0.47730267 -- Validation loss:0.50763494 -- Test loss 0.47976494\n",
      "Epoch 176: -- Training acc  0.9014084507042254 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 177: -- Training loss 0.47548112 -- Validation loss:0.5060479 -- Test loss 0.4781111\n",
      "Epoch 177: -- Training acc  0.9154929577464789 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 178: -- Training loss 0.47364888 -- Validation loss:0.50445694 -- Test loss 0.4764493\n",
      "Epoch 178: -- Training acc  0.9154929577464789 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 179: -- Training loss 0.47180504 -- Validation loss:0.50286067 -- Test loss 0.47477856\n",
      "Epoch 179: -- Training acc  0.9154929577464789 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 180: -- Training loss 0.46994823 -- Validation loss:0.50125825 -- Test loss 0.47309777\n",
      "Epoch 180: -- Training acc  0.9154929577464789 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 181: -- Training loss 0.46807775 -- Validation loss:0.49964854 -- Test loss 0.471406\n",
      "Epoch 181: -- Training acc  0.9154929577464789 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 182: -- Training loss 0.46619254 -- Validation loss:0.49803054 -- Test loss 0.46970236\n",
      "Epoch 182: -- Training acc  0.9154929577464789 -- Validation acc: 0.8333333333333334 -- Test acc  0.84\n",
      "Epoch 183: -- Training loss 0.4642918 -- Validation loss:0.49640346 -- Test loss 0.4679861\n",
      "Epoch 183: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.84\n",
      "Epoch 184: -- Training loss 0.4623747 -- Validation loss:0.49476644 -- Test loss 0.46625653\n",
      "Epoch 184: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.84\n",
      "Epoch 185: -- Training loss 0.46044025 -- Validation loss:0.49311838 -- Test loss 0.46451274\n",
      "Epoch 185: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.84\n",
      "Epoch 186: -- Training loss 0.45848814 -- Validation loss:0.49145886 -- Test loss 0.46275434\n",
      "Epoch 186: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.84\n",
      "Epoch 187: -- Training loss 0.4565176 -- Validation loss:0.48978707 -- Test loss 0.46098053\n",
      "Epoch 187: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.84\n",
      "Epoch 188: -- Training loss 0.45452812 -- Validation loss:0.48810244 -- Test loss 0.4591913\n",
      "Epoch 188: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.84\n",
      "Epoch 189: -- Training loss 0.45251912 -- Validation loss:0.4864044 -- Test loss 0.45738587\n",
      "Epoch 189: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 190: -- Training loss 0.45049036 -- Validation loss:0.48469236 -- Test loss 0.4555638\n",
      "Epoch 190: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 191: -- Training loss 0.4484414 -- Validation loss:0.48296607 -- Test loss 0.45372543\n",
      "Epoch 191: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 192: -- Training loss 0.446372 -- Validation loss:0.48122516 -- Test loss 0.45186982\n",
      "Epoch 192: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 193: -- Training loss 0.44428197 -- Validation loss:0.47946933 -- Test loss 0.4499972\n",
      "Epoch 193: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 194: -- Training loss 0.4421711 -- Validation loss:0.47769845 -- Test loss 0.44810745\n",
      "Epoch 194: -- Training acc  0.9295774647887324 -- Validation acc: 0.875 -- Test acc  0.88\n",
      "Epoch 195: -- Training loss 0.44003946 -- Validation loss:0.47591245 -- Test loss 0.44620055\n",
      "Epoch 195: -- Training acc  0.9295774647887324 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 196: -- Training loss 0.43788695 -- Validation loss:0.47411117 -- Test loss 0.4442765\n",
      "Epoch 196: -- Training acc  0.9295774647887324 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 197: -- Training loss 0.43571368 -- Validation loss:0.47229493 -- Test loss 0.44233552\n",
      "Epoch 197: -- Training acc  0.9295774647887324 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 198: -- Training loss 0.43351972 -- Validation loss:0.47046363 -- Test loss 0.44037753\n",
      "Epoch 198: -- Training acc  0.9295774647887324 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 199: -- Training loss 0.43130532 -- Validation loss:0.4686177 -- Test loss 0.43840277\n",
      "Epoch 199: -- Training acc  0.9436619718309859 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 200: -- Training loss 0.42907065 -- Validation loss:0.4667572 -- Test loss 0.4364115\n",
      "Epoch 200: -- Training acc  0.9436619718309859 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 201: -- Training loss 0.4268161 -- Validation loss:0.46488276 -- Test loss 0.43440408\n",
      "Epoch 201: -- Training acc  0.9436619718309859 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 202: -- Training loss 0.4245419 -- Validation loss:0.46299472 -- Test loss 0.4323807\n",
      "Epoch 202: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 203: -- Training loss 0.42224845 -- Validation loss:0.46109363 -- Test loss 0.43034208\n",
      "Epoch 203: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 204: -- Training loss 0.4199364 -- Validation loss:0.4591801 -- Test loss 0.42828816\n",
      "Epoch 204: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 205: -- Training loss 0.41760594 -- Validation loss:0.45725453 -- Test loss 0.42621964\n",
      "Epoch 205: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 206: -- Training loss 0.41525775 -- Validation loss:0.45531797 -- Test loss 0.42413723\n",
      "Epoch 206: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 207: -- Training loss 0.41289234 -- Validation loss:0.45337096 -- Test loss 0.4220412\n",
      "Epoch 207: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 208: -- Training loss 0.41051033 -- Validation loss:0.45141435 -- Test loss 0.41993222\n",
      "Epoch 208: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 209: -- Training loss 0.4081122 -- Validation loss:0.44944882 -- Test loss 0.41781083\n",
      "Epoch 209: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 210: -- Training loss 0.40569875 -- Validation loss:0.4474753 -- Test loss 0.41567764\n",
      "Epoch 210: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 211: -- Training loss 0.40327054 -- Validation loss:0.4454945 -- Test loss 0.4135334\n",
      "Epoch 211: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 212: -- Training loss 0.4008283 -- Validation loss:0.4435074 -- Test loss 0.4113787\n",
      "Epoch 212: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 213: -- Training loss 0.3983726 -- Validation loss:0.44151458 -- Test loss 0.40921417\n",
      "Epoch 213: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 214: -- Training loss 0.3959043 -- Validation loss:0.4395169 -- Test loss 0.40704042\n",
      "Epoch 214: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 215: -- Training loss 0.393424 -- Validation loss:0.4375153 -- Test loss 0.40485808\n",
      "Epoch 215: -- Training acc  0.9577464788732394 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 216: -- Training loss 0.3909325 -- Validation loss:0.4355103 -- Test loss 0.40266782\n",
      "Epoch 216: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 217: -- Training loss 0.38843036 -- Validation loss:0.43350255 -- Test loss 0.40047023\n",
      "Epoch 217: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 218: -- Training loss 0.3859185 -- Validation loss:0.43149272 -- Test loss 0.39826593\n",
      "Epoch 218: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 219: -- Training loss 0.3833975 -- Validation loss:0.42948136 -- Test loss 0.3960554\n",
      "Epoch 219: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 220: -- Training loss 0.38086814 -- Validation loss:0.42746902 -- Test loss 0.39383924\n",
      "Epoch 220: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 221: -- Training loss 0.37833107 -- Validation loss:0.4254562 -- Test loss 0.3916178\n",
      "Epoch 221: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 222: -- Training loss 0.37578705 -- Validation loss:0.42344308 -- Test loss 0.38939178\n",
      "Epoch 222: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 223: -- Training loss 0.37323686 -- Validation loss:0.4214301 -- Test loss 0.3871615\n",
      "Epoch 223: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 224: -- Training loss 0.37068108 -- Validation loss:0.4194174 -- Test loss 0.3849274\n",
      "Epoch 224: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Test acc  0.92\n",
      "Epoch 225: -- Training loss 0.36812034 -- Validation loss:0.4174054 -- Test loss 0.38268998\n",
      "Epoch 225: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 226: -- Training loss 0.36555555 -- Validation loss:0.41539404 -- Test loss 0.38044956\n",
      "Epoch 226: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 227: -- Training loss 0.3629872 -- Validation loss:0.4133834 -- Test loss 0.37820652\n",
      "Epoch 227: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 228: -- Training loss 0.360416 -- Validation loss:0.41137365 -- Test loss 0.37596133\n",
      "Epoch 228: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 229: -- Training loss 0.3578425 -- Validation loss:0.4093647 -- Test loss 0.3737142\n",
      "Epoch 229: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 230: -- Training loss 0.35526747 -- Validation loss:0.40735653 -- Test loss 0.3714654\n",
      "Epoch 230: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 231: -- Training loss 0.3526914 -- Validation loss:0.4053489 -- Test loss 0.36921552\n",
      "Epoch 231: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 232: -- Training loss 0.35011506 -- Validation loss:0.403342 -- Test loss 0.36696458\n",
      "Epoch 232: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 233: -- Training loss 0.3475389 -- Validation loss:0.40133545 -- Test loss 0.3647129\n",
      "Epoch 233: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 234: -- Training loss 0.3449635 -- Validation loss:0.39932907 -- Test loss 0.3624608\n",
      "Epoch 234: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 235: -- Training loss 0.3423895 -- Validation loss:0.39732286 -- Test loss 0.36020836\n",
      "Epoch 235: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 236: -- Training loss 0.33981743 -- Validation loss:0.3953165 -- Test loss 0.35795593\n",
      "Epoch 236: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 237: -- Training loss 0.3372478 -- Validation loss:0.39330998 -- Test loss 0.35570377\n",
      "Epoch 237: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 238: -- Training loss 0.3346812 -- Validation loss:0.39130303 -- Test loss 0.353452\n",
      "Epoch 238: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 239: -- Training loss 0.33211806 -- Validation loss:0.38929567 -- Test loss 0.35120082\n",
      "Epoch 239: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 240: -- Training loss 0.32955903 -- Validation loss:0.38728765 -- Test loss 0.34895054\n",
      "Epoch 240: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 241: -- Training loss 0.32700443 -- Validation loss:0.38527903 -- Test loss 0.34670135\n",
      "Epoch 241: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 242: -- Training loss 0.32445487 -- Validation loss:0.3832698 -- Test loss 0.3444535\n",
      "Epoch 242: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 243: -- Training loss 0.32191077 -- Validation loss:0.3812599 -- Test loss 0.34220725\n",
      "Epoch 243: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 244: -- Training loss 0.31937262 -- Validation loss:0.37924948 -- Test loss 0.33996305\n",
      "Epoch 244: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 245: -- Training loss 0.31684098 -- Validation loss:0.37723863 -- Test loss 0.3377211\n",
      "Epoch 245: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 246: -- Training loss 0.3143162 -- Validation loss:0.3752277 -- Test loss 0.3354818\n",
      "Epoch 246: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 247: -- Training loss 0.31179887 -- Validation loss:0.37321675 -- Test loss 0.33324546\n",
      "Epoch 247: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 248: -- Training loss 0.30928925 -- Validation loss:0.37120596 -- Test loss 0.33101258\n",
      "Epoch 248: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 249: -- Training loss 0.3067879 -- Validation loss:0.3691958 -- Test loss 0.3287836\n",
      "Epoch 249: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 250: -- Training loss 0.3042954 -- Validation loss:0.36718652 -- Test loss 0.32655895\n",
      "Epoch 250: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 251: -- Training loss 0.30181196 -- Validation loss:0.3651785 -- Test loss 0.32433906\n",
      "Epoch 251: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 252: -- Training loss 0.29933813 -- Validation loss:0.36317202 -- Test loss 0.32212433\n",
      "Epoch 252: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 253: -- Training loss 0.29687428 -- Validation loss:0.36116764 -- Test loss 0.3199154\n",
      "Epoch 253: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 254: -- Training loss 0.29442105 -- Validation loss:0.35916552 -- Test loss 0.31771275\n",
      "Epoch 254: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 255: -- Training loss 0.29197863 -- Validation loss:0.35716638 -- Test loss 0.31551686\n",
      "Epoch 255: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 256: -- Training loss 0.28954753 -- Validation loss:0.3551704 -- Test loss 0.3133283\n",
      "Epoch 256: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 257: -- Training loss 0.28712818 -- Validation loss:0.35317823 -- Test loss 0.3111474\n",
      "Epoch 257: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 258: -- Training loss 0.284721 -- Validation loss:0.35119018 -- Test loss 0.30897498\n",
      "Epoch 258: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 259: -- Training loss 0.28232637 -- Validation loss:0.3492067 -- Test loss 0.3068115\n",
      "Epoch 259: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 260: -- Training loss 0.2799447 -- Validation loss:0.34722838 -- Test loss 0.30465755\n",
      "Epoch 260: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 261: -- Training loss 0.27757633 -- Validation loss:0.3452554 -- Test loss 0.30251357\n",
      "Epoch 261: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 262: -- Training loss 0.27522168 -- Validation loss:0.34328842 -- Test loss 0.30038023\n",
      "Epoch 262: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 263: -- Training loss 0.2728811 -- Validation loss:0.34132782 -- Test loss 0.298258\n",
      "Epoch 263: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 264: -- Training loss 0.27055493 -- Validation loss:0.33937395 -- Test loss 0.2961475\n",
      "Epoch 264: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 265: -- Training loss 0.2682436 -- Validation loss:0.3374273 -- Test loss 0.29404917\n",
      "Epoch 265: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 266: -- Training loss 0.2659473 -- Validation loss:0.33548823 -- Test loss 0.2919635\n",
      "Epoch 266: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 267: -- Training loss 0.26366654 -- Validation loss:0.333557 -- Test loss 0.289891\n",
      "Epoch 267: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 268: -- Training loss 0.2614014 -- Validation loss:0.33163425 -- Test loss 0.28783214\n",
      "Epoch 268: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 269: -- Training loss 0.25915238 -- Validation loss:0.32972002 -- Test loss 0.28578737\n",
      "Epoch 269: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 270: -- Training loss 0.25691962 -- Validation loss:0.32781485 -- Test loss 0.2837571\n",
      "Epoch 270: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 271: -- Training loss 0.25470358 -- Validation loss:0.3259191 -- Test loss 0.2817417\n",
      "Epoch 271: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 272: -- Training loss 0.2525042 -- Validation loss:0.32403296 -- Test loss 0.27974164\n",
      "Epoch 272: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 273: -- Training loss 0.25032204 -- Validation loss:0.32215682 -- Test loss 0.27775726\n",
      "Epoch 273: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 274: -- Training loss 0.24815717 -- Validation loss:0.32029098 -- Test loss 0.27578887\n",
      "Epoch 274: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 275: -- Training loss 0.24600983 -- Validation loss:0.3184357 -- Test loss 0.2738369\n",
      "Epoch 275: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 276: -- Training loss 0.24388018 -- Validation loss:0.3165913 -- Test loss 0.27190155\n",
      "Epoch 276: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 277: -- Training loss 0.24176852 -- Validation loss:0.3147581 -- Test loss 0.2699832\n",
      "Epoch 277: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 278: -- Training loss 0.23967488 -- Validation loss:0.31293616 -- Test loss 0.26808205\n",
      "Epoch 278: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 279: -- Training loss 0.23759946"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Validation loss:0.3111258 -- Test loss 0.2661984\n",
      "Epoch 279: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 280: -- Training loss 0.23554254 -- Validation loss:0.30932736 -- Test loss 0.2643323\n",
      "Epoch 280: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 281: -- Training loss 0.23350409 -- Validation loss:0.30754086 -- Test loss 0.26248416\n",
      "Epoch 281: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 282: -- Training loss 0.23148432 -- Validation loss:0.3057666 -- Test loss 0.26065397\n",
      "Epoch 282: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 283: -- Training loss 0.22948329 -- Validation loss:0.30400476 -- Test loss 0.25884202\n",
      "Epoch 283: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 284: -- Training loss 0.22750111 -- Validation loss:0.30225533 -- Test loss 0.25704843\n",
      "Epoch 284: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 285: -- Training loss 0.22553788 -- Validation loss:0.30051875 -- Test loss 0.25527322\n",
      "Epoch 285: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 286: -- Training loss 0.22359364 -- Validation loss:0.29879484 -- Test loss 0.25351653\n",
      "Epoch 286: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 287: -- Training loss 0.22166845 -- Validation loss:0.2970839 -- Test loss 0.2517784\n",
      "Epoch 287: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 288: -- Training loss 0.21976241 -- Validation loss:0.29538605 -- Test loss 0.25005898\n",
      "Epoch 288: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 289: -- Training loss 0.21787553 -- Validation loss:0.2937013 -- Test loss 0.24835826\n",
      "Epoch 289: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 290: -- Training loss 0.21600777 -- Validation loss:0.29202977 -- Test loss 0.24667625\n",
      "Epoch 290: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 291: -- Training loss 0.21415924 -- Validation loss:0.2903716 -- Test loss 0.24501315\n",
      "Epoch 291: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 292: -- Training loss 0.2123299 -- Validation loss:0.28872672 -- Test loss 0.24336874\n",
      "Epoch 292: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 293: -- Training loss 0.21051975 -- Validation loss:0.28709528 -- Test loss 0.24174315\n",
      "Epoch 293: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 294: -- Training loss 0.20872878 -- Validation loss:0.2854773 -- Test loss 0.24013628\n",
      "Epoch 294: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 295: -- Training loss 0.20695695 -- Validation loss:0.28387284 -- Test loss 0.23854814\n",
      "Epoch 295: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 296: -- Training loss 0.20520426 -- Validation loss:0.2822818 -- Test loss 0.23697855\n",
      "Epoch 296: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 297: -- Training loss 0.2034706 -- Validation loss:0.2807043 -- Test loss 0.23542774\n",
      "Epoch 297: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 298: -- Training loss 0.20175602 -- Validation loss:0.27914032 -- Test loss 0.23389535\n",
      "Epoch 298: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 299: -- Training loss 0.2000604 -- Validation loss:0.27758995 -- Test loss 0.23238148\n",
      "Epoch 299: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 300: -- Training loss 0.19838366 -- Validation loss:0.2760531 -- Test loss 0.23088594\n",
      "Epoch 300: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 301: -- Training loss 0.19672577 -- Validation loss:0.27452978 -- Test loss 0.2294088\n",
      "Epoch 301: -- Training acc  0.971830985915493 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 302: -- Training loss 0.19508658 -- Validation loss:0.27302012 -- Test loss 0.2279499\n",
      "Epoch 302: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 303: -- Training loss 0.19346607 -- Validation loss:0.27152386 -- Test loss 0.22650911\n",
      "Epoch 303: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 304: -- Training loss 0.19186413 -- Validation loss:0.2700412 -- Test loss 0.22508633\n",
      "Epoch 304: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 305: -- Training loss 0.19028065 -- Validation loss:0.26857197 -- Test loss 0.22368154\n",
      "Epoch 305: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 306: -- Training loss 0.18871553 -- Validation loss:0.26711634 -- Test loss 0.22229448\n",
      "Epoch 306: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 307: -- Training loss 0.18716866 -- Validation loss:0.26567402 -- Test loss 0.22092515\n",
      "Epoch 307: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 308: -- Training loss 0.18563989 -- Validation loss:0.26424515 -- Test loss 0.21957329\n",
      "Epoch 308: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 309: -- Training loss 0.1841291 -- Validation loss:0.26282963 -- Test loss 0.21823889\n",
      "Epoch 309: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 310: -- Training loss 0.18263623 -- Validation loss:0.26142752 -- Test loss 0.2169218\n",
      "Epoch 310: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 311: -- Training loss 0.18116112 -- Validation loss:0.2600387 -- Test loss 0.21562189\n",
      "Epoch 311: -- Training acc  0.971830985915493 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 312: -- Training loss 0.17970353 -- Validation loss:0.25866315 -- Test loss 0.21433908\n",
      "Epoch 312: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 313: -- Training loss 0.17826346 -- Validation loss:0.25730088 -- Test loss 0.21307307\n",
      "Epoch 313: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 314: -- Training loss 0.17684071 -- Validation loss:0.25595176 -- Test loss 0.21182393\n",
      "Epoch 314: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 315: -- Training loss 0.17543508 -- Validation loss:0.25461578 -- Test loss 0.21059127\n",
      "Epoch 315: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 316: -- Training loss 0.17404653 -- Validation loss:0.2532929 -- Test loss 0.20937511\n",
      "Epoch 316: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 317: -- Training loss 0.17267479 -- Validation loss:0.251983 -- Test loss 0.20817527\n",
      "Epoch 317: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 318: -- Training loss 0.17131975 -- Validation loss:0.25068605 -- Test loss 0.20699158\n",
      "Epoch 318: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 319: -- Training loss 0.16998132 -- Validation loss:0.24940203 -- Test loss 0.20582394\n",
      "Epoch 319: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 320: -- Training loss 0.16865923 -- Validation loss:0.2481309 -- Test loss 0.20467208\n",
      "Epoch 320: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 321: -- Training loss 0.16735338 -- Validation loss:0.24687244 -- Test loss 0.20353597\n",
      "Epoch 321: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 322: -- Training loss 0.16606356 -- Validation loss:0.24562685 -- Test loss 0.2024154\n",
      "Epoch 322: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 323: -- Training loss 0.16478962 -- Validation loss:0.24439381 -- Test loss 0.20131016\n",
      "Epoch 323: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 324: -- Training loss 0.16353144 -- Validation loss:0.2431734 -- Test loss 0.20022023\n",
      "Epoch 324: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 325: -- Training loss 0.16228876 -- Validation loss:0.24196547 -- Test loss 0.19914526\n",
      "Epoch 325: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 326: -- Training loss 0.16106148 -- Validation loss:0.24076998 -- Test loss 0.19808522\n",
      "Epoch 326: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 327: -- Training loss 0.15984938 -- Validation loss:0.23958685 -- Test loss 0.19703993\n",
      "Epoch 327: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 328: -- Training loss 0.1586523 -- Validation loss:0.23841609 -- Test loss 0.19600922\n",
      "Epoch 328: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 329: -- Training loss 0.15747008 -- Validation loss:0.23725747 -- Test loss 0.19499293\n",
      "Epoch 329: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 330: -- Training loss 0.15630254 -- Validation loss:0.23611104 -- Test loss 0.19399084\n",
      "Epoch 330: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 331: -- Training loss 0.1551495 -- Validation loss:0.23497666 -- Test loss 0.1930029\n",
      "Epoch 331: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 332: -- Training loss 0.15401079 -- Validation loss:0.23385422 -- Test loss 0.19202887\n",
      "Epoch 332: -- Training acc  0.9859154929577465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 333: -- Training loss 0.1528862 -- Validation loss:0.2327437 -- Test loss 0.19106865\n",
      "Epoch 333: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 334: -- Training loss 0.15177561 -- Validation loss:0.231645 -- Test loss 0.19012198\n",
      "Epoch 334: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 335: -- Training loss 0.15067883 -- Validation loss:0.230558 -- Test loss 0.18918869\n",
      "Epoch 335: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 336: -- Training loss 0.14959568 -- Validation loss:0.2294827 -- Test loss 0.18826878\n",
      "Epoch 336: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 337: -- Training loss 0.14852598 -- Validation loss:0.22841902 -- Test loss 0.18736191\n",
      "Epoch 337: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 338: -- Training loss 0.14746955 -- Validation loss:0.22736682 -- Test loss 0.18646808\n",
      "Epoch 338: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 339: -- Training loss 0.14642622 -- Validation loss:0.226326 -- Test loss 0.18558699\n",
      "Epoch 339: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 340: -- Training loss 0.1453958 -- Validation loss:0.2252965 -- Test loss 0.18471853\n",
      "Epoch 340: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 341: -- Training loss 0.14437817 -- Validation loss:0.22427817 -- Test loss 0.1838625\n",
      "Epoch 341: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 342: -- Training loss 0.14337313 -- Validation loss:0.22327115 -- Test loss 0.18301888\n",
      "Epoch 342: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 343: -- Training loss 0.14238052 -- Validation loss:0.22227515 -- Test loss 0.18218741\n",
      "Epoch 343: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 344: -- Training loss 0.14140013 -- Validation loss:0.22129016 -- Test loss 0.18136795\n",
      "Epoch 344: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 345: -- Training loss 0.14043185 -- Validation loss:0.2203161 -- Test loss 0.1805603\n",
      "Epoch 345: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 346: -- Training loss 0.13947546 -- Validation loss:0.21935284 -- Test loss 0.17976446\n",
      "Epoch 346: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 347: -- Training loss 0.13853084 -- Validation loss:0.21840031 -- Test loss 0.17898008\n",
      "Epoch 347: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 348: -- Training loss 0.13759781 -- Validation loss:0.21745847 -- Test loss 0.1782071\n",
      "Epoch 348: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 349: -- Training loss 0.1366762 -- Validation loss:0.21652721 -- Test loss 0.17744546\n",
      "Epoch 349: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 350: -- Training loss 0.1357659 -- Validation loss:0.21560639 -- Test loss 0.17669474\n",
      "Epoch 350: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 351: -- Training loss 0.13486665 -- Validation loss:0.21469603 -- Test loss 0.17595507\n",
      "Epoch 351: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 352: -- Training loss 0.13397837 -- Validation loss:0.21379596 -- Test loss 0.1752262\n",
      "Epoch 352: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 353: -- Training loss 0.1331009 -- Validation loss:0.21290614 -- Test loss 0.17450805\n",
      "Epoch 353: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 354: -- Training loss 0.13223408 -- Validation loss:0.21202652 -- Test loss 0.17380035\n",
      "Epoch 354: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 355: -- Training loss 0.13137771 -- Validation loss:0.21115702 -- Test loss 0.17310308\n",
      "Epoch 355: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 356: -- Training loss 0.13053171 -- Validation loss:0.21029757 -- Test loss 0.17241606\n",
      "Epoch 356: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 357: -- Training loss 0.12969589 -- Validation loss:0.20944788 -- Test loss 0.17173916\n",
      "Epoch 357: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 358: -- Training loss 0.12887007 -- Validation loss:0.2086082 -- Test loss 0.17107213\n",
      "Epoch 358: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 359: -- Training loss 0.1280542 -- Validation loss:0.20777814 -- Test loss 0.17041506\n",
      "Epoch 359: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 360: -- Training loss 0.12724802 -- Validation loss:0.20695789 -- Test loss 0.16976766\n",
      "Epoch 360: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 361: -- Training loss 0.12645149 -- Validation loss:0.20614721 -- Test loss 0.16912973\n",
      "Epoch 361: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 362: -- Training loss 0.12566443 -- Validation loss:0.20534605 -- Test loss 0.16850142\n",
      "Epoch 362: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 363: -- Training loss 0.12488666 -- Validation loss:0.2045544 -- Test loss 0.16788231\n",
      "Epoch 363: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 364: -- Training loss 0.124118105 -- Validation loss:0.20377211 -- Test loss 0.1672725\n",
      "Epoch 364: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 365: -- Training loss 0.12335863 -- Validation loss:0.20299911 -- Test loss 0.1666717\n",
      "Epoch 365: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 366: -- Training loss 0.12260805 -- Validation loss:0.20223546 -- Test loss 0.16607982\n",
      "Epoch 366: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 367: -- Training loss 0.12186626 -- Validation loss:0.20148094 -- Test loss 0.16549689\n",
      "Epoch 367: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 368: -- Training loss 0.121133134 -- Validation loss:0.20073551 -- Test loss 0.16492262\n",
      "Epoch 368: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 369: -- Training loss 0.12040854 -- Validation loss:0.19999905 -- Test loss 0.1643569\n",
      "Epoch 369: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 370: -- Training loss 0.11969235 -- Validation loss:0.19927162 -- Test loss 0.1637997\n",
      "Epoch 370: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 371: -- Training loss 0.11898444 -- Validation loss:0.19855303 -- Test loss 0.16325083\n",
      "Epoch 371: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 372: -- Training loss 0.11828468 -- Validation loss:0.19784318 -- Test loss 0.16271025\n",
      "Epoch 372: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 373: -- Training loss 0.11759296 -- Validation loss:0.1971422 -- Test loss 0.16217783\n",
      "Epoch 373: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 374: -- Training loss 0.116909176 -- Validation loss:0.19644986 -- Test loss 0.16165343\n",
      "Epoch 374: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 375: -- Training loss 0.11623317 -- Validation loss:0.19576605 -- Test loss 0.16113701\n",
      "Epoch 375: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 376: -- Training loss 0.115564846 -- Validation loss:0.19509096 -- Test loss 0.1606284\n",
      "Epoch 376: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 377: -- Training loss 0.114904106 -- Validation loss:0.1944242 -- Test loss 0.1601275\n",
      "Epoch 377: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 378: -- Training loss 0.11425082 -- Validation loss:0.19376588 -- Test loss 0.15963417\n",
      "Epoch 378: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 379: -- Training loss 0.113604896 -- Validation loss:0.19311588 -- Test loss 0.15914845\n",
      "Epoch 379: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 380: -- Training loss 0.1129662 -- Validation loss:0.19247419 -- Test loss 0.15867011\n",
      "Epoch 380: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 381: -- Training loss 0.11233464 -- Validation loss:0.19184078 -- Test loss 0.15819916\n",
      "Epoch 381: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 382: -- Training loss 0.111710094 -- Validation loss:0.19121553 -- Test loss 0.15773554\n",
      "Epoch 382: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 383: -- Training loss 0.11109246 -- Validation loss:0.19059835 -- Test loss 0.157279\n",
      "Epoch 383: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 384: -- Training loss 0.11048165 -- Validation loss:0.18998916 -- Test loss 0.15682958\n",
      "Epoch 384: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 385: -- Training loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1098776 -- Validation loss:0.18938804 -- Test loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15638699\n",
      "Epoch 385: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 386: -- Training loss 0.10928012 -- Validation loss:0.18879473 -- Test loss 0.15595137\n",
      "Epoch 386: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 387: -- Training loss 0.10868919 -- Validation loss:0.18820931 -- Test loss 0.15552253\n",
      "Epoch 387: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 388: -- Training loss 0.10810468 -- Validation loss:0.18763174 -- Test loss 0.15510038\n",
      "Epoch 388: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 389: -- Training loss 0.107526496 -- Validation loss:0.18706185 -- Test loss 0.15468489\n",
      "Epoch 389: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 390: -- Training loss 0.10695455 -- Validation loss:0.18649955 -- Test loss 0.15427588\n",
      "Epoch 390: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 391: -- Training loss 0.10638875 -- Validation loss:0.18594493 -- Test loss 0.15387332\n",
      "Epoch 391: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 392: -- Training loss 0.10582903 -- Validation loss:0.18539792 -- Test loss 0.15347719\n",
      "Epoch 392: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 393: -- Training loss 0.10527526 -- Validation loss:0.18485832 -- Test loss 0.15308733\n",
      "Epoch 393: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 394: -- Training loss 0.10472735 -- Validation loss:0.1843263 -- Test loss 0.15270372\n",
      "Epoch 394: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 395: -- Training loss 0.10418526 -- Validation loss:0.18380158 -- Test loss 0.1523263\n",
      "Epoch 395: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 396: -- Training loss 0.10364888 -- Validation loss:0.18328418 -- Test loss 0.15195493\n",
      "Epoch 396: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 397: -- Training loss 0.1031181 -- Validation loss:0.18277413 -- Test loss 0.15158959\n",
      "Epoch 397: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 398: -- Training loss 0.102592885 -- Validation loss:0.18227129 -- Test loss 0.15123019\n",
      "Epoch 398: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 399: -- Training loss 0.102073155 -- Validation loss:0.18177557 -- Test loss 0.15087667\n",
      "Epoch 399: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 400: -- Training loss 0.10155879 -- Validation loss:0.18128699 -- Test loss 0.1505289\n",
      "Epoch 400: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 401: -- Training loss 0.10104976 -- Validation loss:0.18080549 -- Test loss 0.15018682\n",
      "Epoch 401: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 402: -- Training loss 0.10054594 -- Validation loss:0.18033087 -- Test loss 0.14985038\n",
      "Epoch 402: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 403: -- Training loss 0.10004726 -- Validation loss:0.1798632 -- Test loss 0.1495195\n",
      "Epoch 403: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 404: -- Training loss 0.09955365 -- Validation loss:0.17940253 -- Test loss 0.14919412\n",
      "Epoch 404: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 405: -- Training loss 0.09906509 -- Validation loss:0.17894866 -- Test loss 0.14887428\n",
      "Epoch 405: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 406: -- Training loss 0.098581456 -- Validation loss:0.17850159 -- Test loss 0.14855978\n",
      "Epoch 406: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 407: -- Training loss 0.09810269 -- Validation loss:0.1780612 -- Test loss 0.14825067\n",
      "Epoch 407: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 408: -- Training loss 0.097628705 -- Validation loss:0.17762762 -- Test loss 0.14794682\n",
      "Epoch 408: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 409: -- Training loss 0.09715946 -- Validation loss:0.17720054 -- Test loss 0.14764822\n",
      "Epoch 409: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 410: -- Training loss 0.09669487 -- Validation loss:0.17678016 -- Test loss 0.14735475\n",
      "Epoch 410: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 411: -- Training loss 0.09623489 -- Validation loss:0.17636625 -- Test loss 0.14706637\n",
      "Epoch 411: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 412: -- Training loss 0.095779434 -- Validation loss:0.17595881 -- Test loss 0.146783\n",
      "Epoch 412: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 413: -- Training loss 0.095328435 -- Validation loss:0.17555779 -- Test loss 0.1465046\n",
      "Epoch 413: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 414: -- Training loss 0.09488183 -- Validation loss:0.17516315 -- Test loss 0.1462311\n",
      "Epoch 414: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 415: -- Training loss 0.09443959 -- Validation loss:0.17477481 -- Test loss 0.14596245\n",
      "Epoch 415: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 416: -- Training loss 0.09400159 -- Validation loss:0.17439269 -- Test loss 0.14569858\n",
      "Epoch 416: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 417: -- Training loss 0.09356786 -- Validation loss:0.17401688 -- Test loss 0.14543952\n",
      "Epoch 417: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 418: -- Training loss 0.09313825 -- Validation loss:0.17364718 -- Test loss 0.1451852\n",
      "Epoch 418: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 419: -- Training loss 0.09271276 -- Validation loss:0.17328364 -- Test loss 0.14493556\n",
      "Epoch 419: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 420: -- Training loss 0.09229132 -- Validation loss:0.17292614 -- Test loss 0.14469042\n",
      "Epoch 420: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 421: -- Training loss 0.09187387 -- Validation loss:0.17257471 -- Test loss 0.14444992\n",
      "Epoch 421: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 422: -- Training loss 0.091460325 -- Validation loss:0.17222928 -- Test loss 0.14421394\n",
      "Epoch 422: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 423: -- Training loss 0.09105071 -- Validation loss:0.17188965 -- Test loss 0.14398234\n",
      "Epoch 423: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 424: -- Training loss 0.0906449 -- Validation loss:0.171556 -- Test loss 0.14375515\n",
      "Epoch 424: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 425: -- Training loss 0.090242825 -- Validation loss:0.17122816 -- Test loss 0.14353232\n",
      "Epoch 425: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 426: -- Training loss 0.08984453 -- Validation loss:0.17090595 -- Test loss 0.14331381\n",
      "Epoch 426: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 427: -- Training loss 0.08944986 -- Validation loss:0.17058957 -- Test loss 0.14309956\n",
      "Epoch 427: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 428: -- Training loss 0.08905884 -- Validation loss:0.1702789 -- Test loss 0.14288953\n",
      "Epoch 428: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 429: -- Training loss 0.08867135 -- Validation loss:0.16997384 -- Test loss 0.14268363\n",
      "Epoch 429: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 430: -- Training loss 0.08828742 -- Validation loss:0.16967432 -- Test loss 0.14248188\n",
      "Epoch 430: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.92\n",
      "Epoch 431: -- Training loss 0.08790694 -- Validation loss:0.16938037 -- Test loss 0.14228426\n",
      "Epoch 431: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 432: -- Training loss 0.087529905 -- Validation loss:0.16909184 -- Test loss 0.14209065\n",
      "Epoch 432: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 433: -- Training loss 0.08715623 -- Validation loss:0.16880874 -- Test loss 0.14190096\n",
      "Epoch 433: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 434: -- Training loss 0.08678588 -- Validation loss:0.168531 -- Test loss 0.14171527\n",
      "Epoch 434: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 435: -- Training loss 0.086418845 -- Validation loss:0.16825871 -- Test loss 0.14153352\n",
      "Epoch 435: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 436: -- Training loss 0.08605504 -- Validation loss:0.16799168 -- Test loss 0.14135565\n",
      "Epoch 436: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 437: -- Training loss 0.08569443 -- Validation loss:0.16772985 -- Test loss 0.14118162\n",
      "Epoch 437: -- Training acc  0.9859154929577465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 438: -- Training loss 0.085337 -- Validation loss:0.1674733 -- Test loss 0.14101142\n",
      "Epoch 438: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 439: -- Training loss 0.08498269 -- Validation loss:0.16722184 -- Test loss 0.14084488\n",
      "Epoch 439: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 440: -- Training loss 0.08463143 -- Validation loss:0.1669754 -- Test loss 0.14068197\n",
      "Epoch 440: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 441: -- Training loss 0.08428323 -- Validation loss:0.16673405 -- Test loss 0.14052281\n",
      "Epoch 441: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 442: -- Training loss 0.08393797 -- Validation loss:0.16649778 -- Test loss 0.14036734\n",
      "Epoch 442: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 443: -- Training loss 0.083595715 -- Validation loss:0.1662664 -- Test loss 0.14021535\n",
      "Epoch 443: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 444: -- Training loss 0.08325635 -- Validation loss:0.16603999 -- Test loss 0.14006698\n",
      "Epoch 444: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 445: -- Training loss 0.082919836 -- Validation loss:0.16581845 -- Test loss 0.13992216\n",
      "Epoch 445: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 446: -- Training loss 0.082586214 -- Validation loss:0.16560163 -- Test loss 0.1397808\n",
      "Epoch 446: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 447: -- Training loss 0.08225536 -- Validation loss:0.16538984 -- Test loss 0.13964298\n",
      "Epoch 447: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 448: -- Training loss 0.081927285 -- Validation loss:0.16518258 -- Test loss 0.13950847\n",
      "Epoch 448: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 449: -- Training loss 0.081601925 -- Validation loss:0.16498007 -- Test loss 0.13937739\n",
      "Epoch 449: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 450: -- Training loss 0.081279255 -- Validation loss:0.1647822 -- Test loss 0.13924961\n",
      "Epoch 450: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 451: -- Training loss 0.08095923 -- Validation loss:0.16458887 -- Test loss 0.13912511\n",
      "Epoch 451: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 452: -- Training loss 0.08064185 -- Validation loss:0.1644001 -- Test loss 0.13900384\n",
      "Epoch 452: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 453: -- Training loss 0.08032706 -- Validation loss:0.16421585 -- Test loss 0.13888581\n",
      "Epoch 453: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 454: -- Training loss 0.08001481 -- Validation loss:0.16403608 -- Test loss 0.13877112\n",
      "Epoch 454: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 455: -- Training loss 0.07970509 -- Validation loss:0.16386078 -- Test loss 0.13865946\n",
      "Epoch 455: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 456: -- Training loss 0.07939785 -- Validation loss:0.1636898 -- Test loss 0.13855103\n",
      "Epoch 456: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 457: -- Training loss 0.07909308 -- Validation loss:0.16352312 -- Test loss 0.13844566\n",
      "Epoch 457: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 458: -- Training loss 0.07879072 -- Validation loss:0.1633608 -- Test loss 0.13834344\n",
      "Epoch 458: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 459: -- Training loss 0.07849077 -- Validation loss:0.16320272 -- Test loss 0.13824414\n",
      "Epoch 459: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 460: -- Training loss 0.0781932 -- Validation loss:0.16304879 -- Test loss 0.13814792\n",
      "Epoch 460: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 461: -- Training loss 0.07789792 -- Validation loss:0.16289903 -- Test loss 0.1380546\n",
      "Epoch 461: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 462: -- Training loss 0.077604964 -- Validation loss:0.16275334 -- Test loss 0.13796426\n",
      "Epoch 462: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 463: -- Training loss 0.07731431 -- Validation loss:0.1626118 -- Test loss 0.13787682\n",
      "Epoch 463: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 464: -- Training loss 0.07702585 -- Validation loss:0.16247426 -- Test loss 0.1377923\n",
      "Epoch 464: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 465: -- Training loss 0.07673965 -- Validation loss:0.16234072 -- Test loss 0.13771072\n",
      "Epoch 465: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 466: -- Training loss 0.07645563 -- Validation loss:0.16221116 -- Test loss 0.13763183\n",
      "Epoch 466: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 467: -- Training loss 0.07617376 -- Validation loss:0.16208543 -- Test loss 0.13755572\n",
      "Epoch 467: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 468: -- Training loss 0.07589404 -- Validation loss:0.16196363 -- Test loss 0.13748245\n",
      "Epoch 468: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 469: -- Training loss 0.07561643 -- Validation loss:0.16184567 -- Test loss 0.13741186\n",
      "Epoch 469: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 470: -- Training loss 0.0753409 -- Validation loss:0.16173148 -- Test loss 0.13734403\n",
      "Epoch 470: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 471: -- Training loss 0.075067416 -- Validation loss:0.16162102 -- Test loss 0.13727885\n",
      "Epoch 471: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 472: -- Training loss 0.07479596 -- Validation loss:0.1615143 -- Test loss 0.13721639\n",
      "Epoch 472: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 473: -- Training loss 0.074526526 -- Validation loss:0.16141106 -- Test loss 0.13715631\n",
      "Epoch 473: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 474: -- Training loss 0.07425909 -- Validation loss:0.16131164 -- Test loss 0.13709897\n",
      "Epoch 474: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 475: -- Training loss 0.07399358 -- Validation loss:0.16121574 -- Test loss 0.13704433\n",
      "Epoch 475: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 476: -- Training loss 0.073730014 -- Validation loss:0.16112335 -- Test loss 0.1369921\n",
      "Epoch 476: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 477: -- Training loss 0.07346836 -- Validation loss:0.16103451 -- Test loss 0.13694239\n",
      "Epoch 477: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 478: -- Training loss 0.07320857 -- Validation loss:0.16094916 -- Test loss 0.13689518\n",
      "Epoch 478: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 479: -- Training loss 0.07295067 -- Validation loss:0.16086715 -- Test loss 0.13685045\n",
      "Epoch 479: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 480: -- Training loss 0.07269459 -- Validation loss:0.16078858 -- Test loss 0.13680807\n",
      "Epoch 480: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 481: -- Training loss 0.07244038 -- Validation loss:0.16071336 -- Test loss 0.13676809\n",
      "Epoch 481: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 482: -- Training loss 0.07218788 -- Validation loss:0.16064139 -- Test loss 0.13673052\n",
      "Epoch 482: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 483: -- Training loss 0.0719372 -- Validation loss:0.16057271 -- Test loss 0.13669524\n",
      "Epoch 483: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 484: -- Training loss 0.07168829 -- Validation loss:0.16050728 -- Test loss 0.13666236\n",
      "Epoch 484: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 485: -- Training loss 0.071441084 -- Validation loss:0.16044514 -- Test loss 0.13663182\n",
      "Epoch 485: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 486: -- Training loss 0.07119561 -- Validation loss:0.1603861 -- Test loss 0.13660358\n",
      "Epoch 486: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 487: -- Training loss 0.070951834 -- Validation loss:0.16033018 -- Test loss 0.13657755\n",
      "Epoch 487: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 488: -- Training loss 0.07070969 -- Validation loss:0.16027729 -- Test loss 0.13655365\n",
      "Epoch 488: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 489: -- Training loss 0.07046924 -- Validation loss:0.16022752 -- Test loss 0.13653201\n",
      "Epoch 489: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 490: -- Training loss 0.07023039 -- Validation loss:0.16018075 -- Test loss 0.13651249\n",
      "Epoch 490: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 491: -- Training loss 0.06999315 -- Validation loss:0.16013692 -- Test loss 0.13649522\n",
      "Epoch 491: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 492: -- Training loss 0.06975754 -- Validation loss:0.16009608 -- Test loss 0.13648005\n",
      "Epoch 492: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 493: -- Training loss 0.069523476 -- Validation loss:0.16005827 -- Test loss 0.13646704\n",
      "Epoch 493: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 494: -- Training loss 0.06929095 -- Validation loss:0.16002315 -- Test loss 0.13645607\n",
      "Epoch 494: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 495: -- Training loss 0.06905998 -- Validation loss:0.15999098 -- Test loss 0.13644713\n",
      "Epoch 495: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 496: -- Training loss 0.068830565 -- Validation loss:0.15996163 -- Test loss 0.13644029\n",
      "Epoch 496: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 497: -- Training loss 0.06860261 -- Validation loss:0.15993498 -- Test loss 0.13643539\n",
      "Epoch 497: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 498: -- Training loss 0.06837614 -- Validation loss:0.15991102 -- Test loss 0.13643241\n",
      "Epoch 498: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 499: -- Training loss 0.06815116 -- Validation loss:0.15988977 -- Test loss 0.13643147\n",
      "Epoch 499: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 500: -- Training loss 0.06792761 -- Validation loss:0.15987132 -- Test loss 0.13643247\n",
      "Epoch 500: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 501: -- Training loss 0.0677055 -- Validation loss:0.15985541 -- Test loss 0.13643546\n",
      "Epoch 501: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 502: -- Training loss 0.067484796 -- Validation loss:0.15984218 -- Test loss 0.13644034\n",
      "Epoch 502: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 503: -- Training loss 0.067265525 -- Validation loss:0.15983154 -- Test loss 0.13644707\n",
      "Epoch 503: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 504: -- Training loss 0.06704763 -- Validation loss:0.15982343 -- Test loss 0.13645571\n",
      "Epoch 504: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 505: -- Training loss 0.066831075 -- Validation loss:0.15981787 -- Test loss 0.1364662\n",
      "Epoch 505: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 506: -- Training loss 0.06661589 -- Validation loss:0.15981467 -- Test loss 0.13647829\n",
      "Epoch 506: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 507: -- Training loss 0.066402055 -- Validation loss:0.15981393 -- Test loss 0.13649234\n",
      "Epoch 507: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 508: -- Training loss 0.06618953 -- Validation loss:0.15981562 -- Test loss 0.13650806\n",
      "Epoch 508: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 509: -- Training loss 0.0659783 -- Validation loss:0.1598197 -- Test loss 0.13652562\n",
      "Epoch 509: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 510: -- Training loss 0.06576841 -- Validation loss:0.15982623 -- Test loss 0.13654493\n",
      "Epoch 510: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 511: -- Training loss 0.06555976 -- Validation loss:0.15983503 -- Test loss 0.13656592\n",
      "Epoch 511: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 512: -- Training loss 0.06535237 -- Validation loss:0.15984617 -- Test loss 0.13658865\n",
      "Epoch 512: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 513: -- Training loss 0.06514624 -- Validation loss:0.15985946 -- Test loss 0.13661303\n",
      "Epoch 513: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 514: -- Training loss 0.064941354 -- Validation loss:0.15987511 -- Test loss 0.13663901\n",
      "Epoch 514: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 515: -- Training loss 0.0647377 -- Validation loss:0.1598929 -- Test loss 0.13666669\n",
      "Epoch 515: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 516: -- Training loss 0.06453524 -- Validation loss:0.15991293 -- Test loss 0.13669592\n",
      "Epoch 516: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 517: -- Training loss 0.06433395 -- Validation loss:0.15993504 -- Test loss 0.1367267\n",
      "Epoch 517: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 518: -- Training loss 0.06413389 -- Validation loss:0.15995929 -- Test loss 0.13675907\n",
      "Epoch 518: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 519: -- Training loss 0.06393499 -- Validation loss:0.15998565 -- Test loss 0.13679308\n",
      "Epoch 519: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 520: -- Training loss 0.06373723 -- Validation loss:0.16001408 -- Test loss 0.13682857\n",
      "Epoch 520: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 521: -- Training loss 0.06354063 -- Validation loss:0.1600446 -- Test loss 0.13686569\n",
      "Epoch 521: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 522: -- Training loss 0.06334517 -- Validation loss:0.16007711 -- Test loss 0.13690425\n",
      "Epoch 522: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 523: -- Training loss 0.06315079 -- Validation loss:0.16011168 -- Test loss 0.13694434\n",
      "Epoch 523: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 524: -- Training loss 0.06295755 -- Validation loss:0.16014807 -- Test loss 0.13698576\n",
      "Epoch 524: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 525: -- Training loss 0.062765405 -- Validation loss:0.1601865 -- Test loss 0.13702875\n",
      "Epoch 525: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 526: -- Training loss 0.062574334 -- Validation loss:0.16022672 -- Test loss 0.13707303\n",
      "Epoch 526: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Epoch 527: -- Training loss 0.062384345 -- Validation loss:0.16026895 -- Test loss 0.13711883\n",
      "Epoch 527: -- Training acc  0.9859154929577465 -- Validation acc: 0.9583333333333334 -- Test acc  0.96\n",
      "Early stopped: Validation loss hasn't improved in  20 epochs.\n",
      "Epoch 0: -- Training loss 1.2692125 -- Validation loss:1.1728863 -- Test loss 1.242956\n",
      "Epoch 1: -- Training loss 1.2488456 -- Validation loss:1.1579541 -- Test loss 1.224142\n",
      "Epoch 1: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 2: -- Training loss 1.2298336 -- Validation loss:1.1443032 -- Test loss 1.2066673\n",
      "Epoch 2: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 3: -- Training loss 1.2121773 -- Validation loss:1.1319242 -- Test loss 1.1905296\n",
      "Epoch 3: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 4: -- Training loss 1.1958671 -- Validation loss:1.1207957 -- Test loss 1.1757154\n",
      "Epoch 4: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 5: -- Training loss 1.1808815 -- Validation loss:1.1108857 -- Test loss 1.1621994\n",
      "Epoch 5: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 6: -- Training loss 1.167189 -- Validation loss:1.1021508 -- Test loss 1.1499454\n",
      "Epoch 6: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 7: -- Training loss 1.1547476 -- Validation loss:1.0945374 -- Test loss 1.138907\n",
      "Epoch 7: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 8: -- Training loss 1.1435059 -- Validation loss:1.0879859 -- Test loss 1.1290307\n",
      "Epoch 8: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 9: -- Training loss 1.133406 -- Validation loss:1.0824307 -- Test loss 1.1202563\n",
      "Epoch 9: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 10: -- Training loss 1.124384 -- Validation loss:1.0778013 -- Test loss 1.112518\n",
      "Epoch 10: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 11: -- Training loss 1.1163708 -- Validation loss:1.0740228 -- Test loss 1.1057448\n",
      "Epoch 11: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 12: -- Training loss 1.109293 -- Validation loss:1.0710169 -- Test loss 1.0998626\n",
      "Epoch 12: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 13: -- Training loss 1.1030757 -- Validation loss:1.0687027 -- Test loss 1.0947938\n",
      "Epoch 13: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 14: -- Training loss 1.0976416 -- Validation loss:1.067 -- Test loss 1.0904609\n",
      "Epoch 14: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: -- Training loss 1.0929146 -- Validation loss:1.0658286 -- Test loss 1.0867858\n",
      "Epoch 15: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 16: -- Training loss 1.0888182 -- Validation loss:1.0651103 -- Test loss 1.0836916\n",
      "Epoch 16: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 17: -- Training loss 1.0852795 -- Validation loss:1.0647703 -- Test loss 1.0811048\n",
      "Epoch 17: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 18: -- Training loss 1.0822278 -- Validation loss:1.0647377 -- Test loss 1.0789537\n",
      "Epoch 18: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 19: -- Training loss 1.0795959 -- Validation loss:1.0649456 -- Test loss 1.0771716\n",
      "Epoch 19: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 20: -- Training loss 1.077322 -- Validation loss:1.0653323 -- Test loss 1.0756958\n",
      "Epoch 20: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 21: -- Training loss 1.0753474 -- Validation loss:1.0658413 -- Test loss 1.0744679\n",
      "Epoch 21: -- Training acc  0.3380281690140845 -- Validation acc: 0.4166666666666667 -- Test acc  0.36\n",
      "Epoch 22: -- Training loss 1.073619 -- Validation loss:1.0664212 -- Test loss 1.0734347\n",
      "Epoch 22: -- Training acc  0.3380281690140845 -- Validation acc: 0.4583333333333333 -- Test acc  0.36\n",
      "Epoch 23: -- Training loss 1.0720876 -- Validation loss:1.0670254 -- Test loss 1.0725473\n",
      "Epoch 23: -- Training acc  0.6056338028169014 -- Validation acc: 0.5833333333333334 -- Test acc  0.6\n",
      "Epoch 24: -- Training loss 1.0707091 -- Validation loss:1.0676131 -- Test loss 1.0717622\n",
      "Epoch 24: -- Training acc  0.43661971830985913 -- Validation acc: 0.2916666666666667 -- Test acc  0.36\n",
      "Epoch 25: -- Training loss 1.0694435 -- Validation loss:1.0681477 -- Test loss 1.07104\n",
      "Epoch 25: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 26: -- Training loss 1.0682557 -- Validation loss:1.0685982 -- Test loss 1.0703465\n",
      "Epoch 26: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 27: -- Training loss 1.0671141 -- Validation loss:1.0689372 -- Test loss 1.0696503\n",
      "Epoch 27: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 28: -- Training loss 1.0659919 -- Validation loss:1.0691425 -- Test loss 1.0689263\n",
      "Epoch 28: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 29: -- Training loss 1.0648652 -- Validation loss:1.0691954 -- Test loss 1.0681516\n",
      "Epoch 29: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 30: -- Training loss 1.0637136 -- Validation loss:1.0690808 -- Test loss 1.0673071\n",
      "Epoch 30: -- Training acc  0.352112676056338 -- Validation acc: 0.2916666666666667 -- Test acc  0.32\n",
      "Epoch 31: -- Training loss 1.06252 -- Validation loss:1.0687879 -- Test loss 1.0663775\n",
      "Epoch 31: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 32: -- Training loss 1.0612704 -- Validation loss:1.0683074 -- Test loss 1.0653497\n",
      "Epoch 32: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.32\n",
      "Epoch 33: -- Training loss 1.0599526 -- Validation loss:1.0676342 -- Test loss 1.0642142\n",
      "Epoch 33: -- Training acc  0.36619718309859156 -- Validation acc: 0.3333333333333333 -- Test acc  0.36\n",
      "Epoch 34: -- Training loss 1.0585575 -- Validation loss:1.066765 -- Test loss 1.062963\n",
      "Epoch 34: -- Training acc  0.36619718309859156 -- Validation acc: 0.375 -- Test acc  0.36\n",
      "Epoch 35: -- Training loss 1.0570774 -- Validation loss:1.0656986 -- Test loss 1.0615901\n",
      "Epoch 35: -- Training acc  0.39436619718309857 -- Validation acc: 0.375 -- Test acc  0.36\n",
      "Epoch 36: -- Training loss 1.0555062 -- Validation loss:1.0644355 -- Test loss 1.060092\n",
      "Epoch 36: -- Training acc  0.4084507042253521 -- Validation acc: 0.4166666666666667 -- Test acc  0.4\n",
      "Epoch 37: -- Training loss 1.0538399 -- Validation loss:1.0629783 -- Test loss 1.0584661\n",
      "Epoch 37: -- Training acc  0.43661971830985913 -- Validation acc: 0.4583333333333333 -- Test acc  0.4\n",
      "Epoch 38: -- Training loss 1.0520746 -- Validation loss:1.06133 -- Test loss 1.0567111\n",
      "Epoch 38: -- Training acc  0.4647887323943662 -- Validation acc: 0.4583333333333333 -- Test acc  0.4\n",
      "Epoch 39: -- Training loss 1.0502082 -- Validation loss:1.0594954 -- Test loss 1.0548266\n",
      "Epoch 39: -- Training acc  0.5211267605633803 -- Validation acc: 0.5 -- Test acc  0.48\n",
      "Epoch 40: -- Training loss 1.0482392 -- Validation loss:1.0574799 -- Test loss 1.052814\n",
      "Epoch 40: -- Training acc  0.5774647887323944 -- Validation acc: 0.5416666666666666 -- Test acc  0.56\n",
      "Epoch 41: -- Training loss 1.0461667 -- Validation loss:1.0552889 -- Test loss 1.0506736\n",
      "Epoch 41: -- Training acc  0.6056338028169014 -- Validation acc: 0.5833333333333334 -- Test acc  0.56\n",
      "Epoch 42: -- Training loss 1.04399 -- Validation loss:1.052929 -- Test loss 1.0484072\n",
      "Epoch 42: -- Training acc  0.6056338028169014 -- Validation acc: 0.5833333333333334 -- Test acc  0.6\n",
      "Epoch 43: -- Training loss 1.0417085 -- Validation loss:1.0504066 -- Test loss 1.0460167\n",
      "Epoch 43: -- Training acc  0.6197183098591549 -- Validation acc: 0.5833333333333334 -- Test acc  0.6\n",
      "Epoch 44: -- Training loss 1.0393217 -- Validation loss:1.0477282 -- Test loss 1.0435038\n",
      "Epoch 44: -- Training acc  0.647887323943662 -- Validation acc: 0.5833333333333334 -- Test acc  0.6\n",
      "Epoch 45: -- Training loss 1.03683 -- Validation loss:1.0449 -- Test loss 1.0408705\n",
      "Epoch 45: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 46: -- Training loss 1.0342323 -- Validation loss:1.0419285 -- Test loss 1.0381182\n",
      "Epoch 46: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 47: -- Training loss 1.0315279 -- Validation loss:1.0388192 -- Test loss 1.0352488\n",
      "Epoch 47: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 48: -- Training loss 1.0287163 -- Validation loss:1.0355778 -- Test loss 1.0322632\n",
      "Epoch 48: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 49: -- Training loss 1.0257965 -- Validation loss:1.0322098 -- Test loss 1.0291622\n",
      "Epoch 49: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 50: -- Training loss 1.0227665 -- Validation loss:1.0287191 -- Test loss 1.0259465\n",
      "Epoch 50: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 51: -- Training loss 1.019625 -- Validation loss:1.0251104 -- Test loss 1.0226161\n",
      "Epoch 51: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 52: -- Training loss 1.0163692 -- Validation loss:1.0213865 -- Test loss 1.0191706\n",
      "Epoch 52: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 53: -- Training loss 1.0129976 -- Validation loss:1.0175511 -- Test loss 1.0156096\n",
      "Epoch 53: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 54: -- Training loss 1.009507 -- Validation loss:1.0136062 -- Test loss 1.0119315\n",
      "Epoch 54: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 55: -- Training loss 1.0058948 -- Validation loss:1.0095536 -- Test loss 1.0081354\n",
      "Epoch 55: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 56: -- Training loss 1.0021578 -- Validation loss:1.0053953 -- Test loss 1.0042194\n",
      "Epoch 56: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 57: -- Training loss 0.9982933 -- Validation loss:1.0011321 -- Test loss 1.0001819\n",
      "Epoch 57: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 58: -- Training loss 0.9942976 -- Validation loss:0.9967646 -- Test loss 0.9960207\n",
      "Epoch 58: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 59: -- Training loss 0.99016815 -- Validation loss:0.99229336 -- Test loss 0.9917335\n",
      "Epoch 59: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 60: -- Training loss 0.98590183 -- Validation loss:0.9877183 -- Test loss 0.9873184\n",
      "Epoch 60: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 61: -- Training loss 0.9814956 -- Validation loss:0.9830394 -- Test loss 0.982773\n",
      "Epoch 61: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 62: -- Training loss 0.97694707 -- Validation loss:0.9782563 -- Test loss 0.97809553\n",
      "Epoch 62: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 63: -- Training loss 0.9722539 -- Validation loss:0.9733692 -- Test loss 0.9732841\n",
      "Epoch 63: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 64: -- Training loss 0.9674141 -- Validation loss:0.9683772 -- Test loss 0.96833694\n",
      "Epoch 64: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 65: -- Training loss 0.96242607 -- Validation loss:0.9632805 -- Test loss 0.9632528\n",
      "Epoch 65: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 66: -- Training loss 0.9572889 -- Validation loss:0.9580791 -- Test loss 0.95803094\n",
      "Epoch 66: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 67: -- Training loss 0.9520023 -- Validation loss:0.9527731 -- Test loss 0.9526706\n",
      "Epoch 67: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 68: -- Training loss 0.94656575 -- Validation loss:0.9473625 -- Test loss 0.9471719\n",
      "Epoch 68: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n",
      "Epoch 69: -- Training loss 0.9409804 -- Validation loss:0.9418485 -- Test loss 0.9415351\n",
      "Epoch 69: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 70: -- Training loss 0.93524706 -- Validation loss:0.93623203 -- Test loss 0.9357618\n",
      "Epoch 70: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 71: -- Training loss 0.9293676 -- Validation loss:0.9305144 -- Test loss 0.92985314\n",
      "Epoch 71: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72: -- Training loss 0.92334455 -- Validation loss:0.9246976 -- Test loss 0.92381155\n",
      "Epoch 72: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 73: -- Training loss 0.9171812 -- Validation loss:0.9187837 -- Test loss 0.91764015\n",
      "Epoch 73: -- Training acc  0.6619718309859155 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 74: -- Training loss 0.9108813 -- Validation loss:0.9127758 -- Test loss 0.9113426\n",
      "Epoch 74: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 75: -- Training loss 0.90444905 -- Validation loss:0.90667725 -- Test loss 0.90492296\n",
      "Epoch 75: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 76: -- Training loss 0.8978897 -- Validation loss:0.9004913 -- Test loss 0.898386\n",
      "Epoch 76: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 77: -- Training loss 0.8912089 -- Validation loss:0.8942227 -- Test loss 0.8917376\n",
      "Epoch 77: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 78: -- Training loss 0.88441277 -- Validation loss:0.887876 -- Test loss 0.88498366\n",
      "Epoch 78: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 79: -- Training loss 0.8775083 -- Validation loss:0.88145596 -- Test loss 0.87813103\n",
      "Epoch 79: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 80: -- Training loss 0.8705025 -- Validation loss:0.87496835 -- Test loss 0.8711867\n",
      "Epoch 80: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 81: -- Training loss 0.8634031 -- Validation loss:0.8684192 -- Test loss 0.8641587\n",
      "Epoch 81: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 82: -- Training loss 0.8562184 -- Validation loss:0.86181426 -- Test loss 0.85705477\n",
      "Epoch 82: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 83: -- Training loss 0.8489569 -- Validation loss:0.85516024 -- Test loss 0.84988326\n",
      "Epoch 83: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 84: -- Training loss 0.8416272 -- Validation loss:0.848464 -- Test loss 0.8426533\n",
      "Epoch 84: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 85: -- Training loss 0.8342386 -- Validation loss:0.84173226 -- Test loss 0.83537364\n",
      "Epoch 85: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 86: -- Training loss 0.8268001 -- Validation loss:0.83497167 -- Test loss 0.82805336\n",
      "Epoch 86: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 87: -- Training loss 0.8193215 -- Validation loss:0.82818955 -- Test loss 0.8207016\n",
      "Epoch 87: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 88: -- Training loss 0.81181204 -- Validation loss:0.82139283 -- Test loss 0.8133276\n",
      "Epoch 88: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 89: -- Training loss 0.8042814 -- Validation loss:0.81458855 -- Test loss 0.80594045\n",
      "Epoch 89: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 90: -- Training loss 0.79673886 -- Validation loss:0.80778354 -- Test loss 0.7985494\n",
      "Epoch 90: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 91: -- Training loss 0.7891941 -- Validation loss:0.8009844 -- Test loss 0.79116327\n",
      "Epoch 91: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 92: -- Training loss 0.78165627 -- Validation loss:0.794198 -- Test loss 0.7837903\n",
      "Epoch 92: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 93: -- Training loss 0.7741347 -- Validation loss:0.7874302 -- Test loss 0.7764392\n",
      "Epoch 93: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 94: -- Training loss 0.7666381 -- Validation loss:0.7806875 -- Test loss 0.76911813\n",
      "Epoch 94: -- Training acc  0.676056338028169 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 95: -- Training loss 0.7591752 -- Validation loss:0.77397543 -- Test loss 0.7618345\n",
      "Epoch 95: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 96: -- Training loss 0.75175434 -- Validation loss:0.7672999 -- Test loss 0.7545962\n",
      "Epoch 96: -- Training acc  0.6901408450704225 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 97: -- Training loss 0.7443834 -- Validation loss:0.7606659 -- Test loss 0.74740964\n",
      "Epoch 97: -- Training acc  0.704225352112676 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 98: -- Training loss 0.7370701 -- Validation loss:0.7540782 -- Test loss 0.740282\n",
      "Epoch 98: -- Training acc  0.704225352112676 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 99: -- Training loss 0.72982144 -- Validation loss:0.7475422 -- Test loss 0.73321897\n",
      "Epoch 99: -- Training acc  0.704225352112676 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 100: -- Training loss 0.7226442 -- Validation loss:0.7410617 -- Test loss 0.72622687\n",
      "Epoch 100: -- Training acc  0.704225352112676 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 101: -- Training loss 0.7155448 -- Validation loss:0.734641 -- Test loss 0.71931076\n",
      "Epoch 101: -- Training acc  0.704225352112676 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 102: -- Training loss 0.708529 -- Validation loss:0.72828436 -- Test loss 0.71247613\n",
      "Epoch 102: -- Training acc  0.7183098591549296 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 103: -- Training loss 0.70160204 -- Validation loss:0.7219951 -- Test loss 0.7057272\n",
      "Epoch 103: -- Training acc  0.7183098591549296 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 104: -- Training loss 0.694769 -- Validation loss:0.7157772 -- Test loss 0.69906855\n",
      "Epoch 104: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 105: -- Training loss 0.68803424 -- Validation loss:0.7096338 -- Test loss 0.69250417\n",
      "Epoch 105: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 106: -- Training loss 0.6814018 -- Validation loss:0.70356804 -- Test loss 0.68603766\n",
      "Epoch 106: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 107: -- Training loss 0.674875 -- Validation loss:0.69758326 -- Test loss 0.6796724\n",
      "Epoch 107: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 108: -- Training loss 0.668457 -- Validation loss:0.6916819 -- Test loss 0.6734114\n",
      "Epoch 108: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 109: -- Training loss 0.66215056 -- Validation loss:0.68586713 -- Test loss 0.6672571\n",
      "Epoch 109: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 110: -- Training loss 0.65595764 -- Validation loss:0.6801414 -- Test loss 0.6612123\n",
      "Epoch 110: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 111: -- Training loss 0.64988023 -- Validation loss:0.67450696 -- Test loss 0.6552786\n",
      "Epoch 111: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 112: -- Training loss 0.64391947 -- Validation loss:0.66896635 -- Test loss 0.64945793\n",
      "Epoch 112: -- Training acc  0.7323943661971831 -- Validation acc: 0.5833333333333334 -- Test acc  0.64\n",
      "Epoch 113: -- Training loss 0.6380765 -- Validation loss:0.6635214 -- Test loss 0.643752\n",
      "Epoch 113: -- Training acc  0.7323943661971831 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 114: -- Training loss 0.632352 -- Validation loss:0.6581742 -- Test loss 0.6381615\n",
      "Epoch 114: -- Training acc  0.7323943661971831 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 115: -- Training loss 0.62674624 -- Validation loss:0.65292627 -- Test loss 0.63268757\n",
      "Epoch 115: -- Training acc  0.7605633802816901 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 116: -- Training loss 0.621259 -- Validation loss:0.64777917 -- Test loss 0.62733054\n",
      "Epoch 116: -- Training acc  0.7605633802816901 -- Validation acc: 0.625 -- Test acc  0.64\n",
      "Epoch 117: -- Training loss 0.6158901 -- Validation loss:0.642734 -- Test loss 0.62209064\n",
      "Epoch 117: -- Training acc  0.7605633802816901 -- Validation acc: 0.625 -- Test acc  0.68\n",
      "Epoch 118: -- Training loss 0.6106388 -- Validation loss:0.6377918 -- Test loss 0.6169678\n",
      "Epoch 118: -- Training acc  0.7746478873239436 -- Validation acc: 0.625 -- Test acc  0.68\n",
      "Epoch 119: -- Training loss 0.60550404 -- Validation loss:0.63295317 -- Test loss 0.6119618\n",
      "Epoch 119: -- Training acc  0.7746478873239436 -- Validation acc: 0.625 -- Test acc  0.68\n",
      "Epoch 120: -- Training loss 0.60048485 -- Validation loss:0.62821853 -- Test loss 0.6070717\n",
      "Epoch 120: -- Training acc  0.7746478873239436 -- Validation acc: 0.625 -- Test acc  0.68\n",
      "Epoch 121: -- Training loss 0.59557956 -- Validation loss:0.6235882 -- Test loss 0.60229665\n",
      "Epoch 121: -- Training acc  0.7887323943661971 -- Validation acc: 0.625 -- Test acc  0.72\n",
      "Epoch 122: -- Training loss 0.59078664 -- Validation loss:0.6190619 -- Test loss 0.5976356\n",
      "Epoch 122: -- Training acc  0.7887323943661971 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 123: -- Training loss 0.58610415 -- Validation loss:0.6146393 -- Test loss 0.593087\n",
      "Epoch 123: -- Training acc  0.8028169014084507 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 124: -- Training loss 0.58153015 -- Validation loss:0.6103197 -- Test loss 0.5886493\n",
      "Epoch 124: -- Training acc  0.8028169014084507 -- Validation acc: 0.6666666666666666 -- Test acc  0.72\n",
      "Epoch 125: -- Training loss 0.5770623 -- Validation loss:0.6061023 -- Test loss 0.58432037\n",
      "Epoch 125: -- Training acc  0.8169014084507042 -- Validation acc: 0.7083333333333334 -- Test acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "Epoch 126: -- Training loss 0.5726985 -- Validation loss:0.6019859 -- Test loss 0.58009845\n",
      "Epoch 126: -- Training acc  0.8169014084507042 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 127: -- Training loss 0.56843597 -- Validation loss:0.5979691 -- Test loss 0.5759812\n",
      "Epoch 127: -- Training acc  0.8309859154929577 -- Validation acc: 0.7083333333333334 -- Test acc  0.72\n",
      "Epoch 128: -- Training loss 0.5642723 -- Validation loss:0.59405035 -- Test loss 0.5719664\n",
      "Epoch 128: -- Training acc  0.8309859154929577 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 129: -- Training loss 0.5602049 -- Validation loss:0.5902278 -- Test loss 0.5680513\n",
      "Epoch 129: -- Training acc  0.8309859154929577 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 130: -- Training loss 0.55623096 -- Validation loss:0.5864997 -- Test loss 0.5642336\n",
      "Epoch 130: -- Training acc  0.8309859154929577 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 131: -- Training loss 0.5523477 -- Validation loss:0.5828638 -- Test loss 0.56051064\n",
      "Epoch 131: -- Training acc  0.8309859154929577 -- Validation acc: 0.75 -- Test acc  0.72\n",
      "Epoch 132: -- Training loss 0.54855245 -- Validation loss:0.57931787 -- Test loss 0.5568794\n",
      "Epoch 132: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 133: -- Training loss 0.54484206 -- Validation loss:0.5758597 -- Test loss 0.55333734\n",
      "Epoch 133: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 134: -- Training loss 0.541214 -- Validation loss:0.5724868 -- Test loss 0.5498817\n",
      "Epoch 134: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 135: -- Training loss 0.5376651 -- Validation loss:0.5691966 -- Test loss 0.54650956\n",
      "Epoch 135: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 136: -- Training loss 0.53419274 -- Validation loss:0.5659866 -- Test loss 0.54321826\n",
      "Epoch 136: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 137: -- Training loss 0.5307941 -- Validation loss:0.5628541 -- Test loss 0.5400047\n",
      "Epoch 137: -- Training acc  0.8309859154929577 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 138: -- Training loss 0.5274662 -- Validation loss:0.5597966 -- Test loss 0.53686637\n",
      "Epoch 138: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 139: -- Training loss 0.5242064 -- Validation loss:0.5568112 -- Test loss 0.53380036\n",
      "Epoch 139: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.72\n",
      "Epoch 140: -- Training loss 0.52101207 -- Validation loss:0.5538956 -- Test loss 0.5308041\n",
      "Epoch 140: -- Training acc  0.8450704225352113 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 141: -- Training loss 0.5178803 -- Validation loss:0.55104685 -- Test loss 0.5278749\n",
      "Epoch 141: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 142: -- Training loss 0.51480854 -- Validation loss:0.54826236 -- Test loss 0.52500975\n",
      "Epoch 142: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 143: -- Training loss 0.5117944 -- Validation loss:0.54553956 -- Test loss 0.52220654\n",
      "Epoch 143: -- Training acc  0.8591549295774648 -- Validation acc: 0.7916666666666666 -- Test acc  0.76\n",
      "Epoch 144: -- Training loss 0.5088352 -- Validation loss:0.54287577 -- Test loss 0.5194625\n",
      "Epoch 144: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 145: -- Training loss 0.5059287 -- Validation loss:0.54026854 -- Test loss 0.5167751\n",
      "Epoch 145: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 146: -- Training loss 0.5030723 -- Validation loss:0.53771514 -- Test loss 0.51414186\n",
      "Epoch 146: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 147: -- Training loss 0.5002638 -- Validation loss:0.5352135 -- Test loss 0.5115608\n",
      "Epoch 147: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 148: -- Training loss 0.49750105 -- Validation loss:0.5327607 -- Test loss 0.50902915\n",
      "Epoch 148: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 149: -- Training loss 0.49478164 -- Validation loss:0.53035474 -- Test loss 0.50654477\n",
      "Epoch 149: -- Training acc  0.8732394366197183 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 150: -- Training loss 0.49210384 -- Validation loss:0.52799326 -- Test loss 0.5041057\n",
      "Epoch 150: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 151: -- Training loss 0.48946536 -- Validation loss:0.525674 -- Test loss 0.5017096\n",
      "Epoch 151: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 152: -- Training loss 0.4868644 -- Validation loss:0.5233949 -- Test loss 0.49935463\n",
      "Epoch 152: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 153: -- Training loss 0.48429903 -- Validation loss:0.5211538 -- Test loss 0.49703866\n",
      "Epoch 153: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 154: -- Training loss 0.48176742 -- Validation loss:0.51894885 -- Test loss 0.49475986\n",
      "Epoch 154: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 155: -- Training loss 0.47926798 -- Validation loss:0.5167781 -- Test loss 0.49251637\n",
      "Epoch 155: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 156: -- Training loss 0.47679886 -- Validation loss:0.51463985 -- Test loss 0.4903066\n",
      "Epoch 156: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 157: -- Training loss 0.47435862 -- Validation loss:0.51253223 -- Test loss 0.4881289\n",
      "Epoch 157: -- Training acc  0.9014084507042254 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 158: -- Training loss 0.4719457 -- Validation loss:0.51045394 -- Test loss 0.48598135\n",
      "Epoch 158: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 159: -- Training loss 0.46955872 -- Validation loss:0.5084032 -- Test loss 0.4838628\n",
      "Epoch 159: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 160: -- Training loss 0.46719614 -- Validation loss:0.5063785 -- Test loss 0.48177174\n",
      "Epoch 160: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 161: -- Training loss 0.4648568 -- Validation loss:0.50437886 -- Test loss 0.47970665\n",
      "Epoch 161: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 162: -- Training loss 0.46253946 -- Validation loss:0.50240296 -- Test loss 0.47766647\n",
      "Epoch 162: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 163: -- Training loss 0.4602428 -- Validation loss:0.5004495 -- Test loss 0.47564974\n",
      "Epoch 163: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 164: -- Training loss 0.45796585 -- Validation loss:0.49851727 -- Test loss 0.4736557\n",
      "Epoch 164: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 165: -- Training loss 0.45570743 -- Validation loss:0.4966056 -- Test loss 0.471683\n",
      "Epoch 165: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 166: -- Training loss 0.45346656 -- Validation loss:0.49471334 -- Test loss 0.46973065\n",
      "Epoch 166: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 167: -- Training loss 0.45124242 -- Validation loss:0.49283972 -- Test loss 0.46779773\n",
      "Epoch 167: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 168: -- Training loss 0.4490339 -- Validation loss:0.49098387 -- Test loss 0.46588323\n",
      "Epoch 168: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 169: -- Training loss 0.44684032 -- Validation loss:0.48914504 -- Test loss 0.4639864\n",
      "Epoch 169: -- Training acc  0.9154929577464789 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 170: -- Training loss 0.4446608 -- Validation loss:0.4873226 -- Test loss 0.46210644\n",
      "Epoch 170: -- Training acc  0.9295774647887324 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 171: -- Training loss 0.4424947 -- Validation loss:0.48551574 -- Test loss 0.46024245\n",
      "Epoch 171: -- Training acc  0.9295774647887324 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 172: -- Training loss 0.44034126 -- Validation loss:0.483724 -- Test loss 0.45839402\n",
      "Epoch 172: -- Training acc  0.9295774647887324 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 173: -- Training loss 0.43819982 -- Validation loss:0.48194674 -- Test loss 0.45656016\n",
      "Epoch 173: -- Training acc  0.9436619718309859 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 174: -- Training loss 0.4360698 -- Validation loss:0.48018333 -- Test loss 0.4547404\n",
      "Epoch 174: -- Training acc  0.9436619718309859 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 175: -- Training loss 0.43395057 -- Validation loss:0.47843346 -- Test loss 0.4529339\n",
      "Epoch 175: -- Training acc  0.9436619718309859 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 176: -- Training loss 0.43184173 -- Validation loss:0.47669646 -- Test loss 0.4511404\n",
      "Epoch 176: -- Training acc  0.9436619718309859 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 177: -- Training loss 0.42974275 -- Validation loss:0.47497228 -- Test loss 0.44935933\n",
      "Epoch 177: -- Training acc  0.9436619718309859 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 178: -- Training loss 0.42765313 -- Validation loss:0.47325984 -- Test loss 0.44758996\n",
      "Epoch 178: -- Training acc  0.9436619718309859 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 179: -- Training loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42557245 -- Validation loss:0.47155952 -- Test loss 0.44583207\n",
      "Epoch 179: -- Training acc  0.9577464788732394 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 180: -- Training loss 0.4235004 -- Validation loss:0.46987042 -- Test loss 0.44408503\n",
      "Epoch 180: -- Training acc  0.9577464788732394 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 181: -- Training loss 0.42143658 -- Validation loss:0.4681925 -- Test loss 0.44234863\n",
      "Epoch 181: -- Training acc  0.9577464788732394 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 182: -- Training loss 0.4193807 -- Validation loss:0.46652532 -- Test loss 0.44062224\n",
      "Epoch 182: -- Training acc  0.9577464788732394 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 183: -- Training loss 0.41733235 -- Validation loss:0.46486863 -- Test loss 0.43890584\n",
      "Epoch 183: -- Training acc  0.9577464788732394 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 184: -- Training loss 0.41529146 -- Validation loss:0.46322227 -- Test loss 0.43719882\n",
      "Epoch 184: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.8\n",
      "Epoch 185: -- Training loss 0.41325757 -- Validation loss:0.4615858 -- Test loss 0.43550095\n",
      "Epoch 185: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.84\n",
      "Epoch 186: -- Training loss 0.4112306 -- Validation loss:0.45995924 -- Test loss 0.43381217\n",
      "Epoch 186: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.84\n",
      "Epoch 187: -- Training loss 0.40921035 -- Validation loss:0.4583421 -- Test loss 0.432132\n",
      "Epoch 187: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.84\n",
      "Epoch 188: -- Training loss 0.40719652 -- Validation loss:0.4567345 -- Test loss 0.43046016\n",
      "Epoch 188: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.84\n",
      "Epoch 189: -- Training loss 0.4051891 -- Validation loss:0.45513597 -- Test loss 0.4287965\n",
      "Epoch 189: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.84\n",
      "Epoch 190: -- Training loss 0.4031878 -- Validation loss:0.4535465 -- Test loss 0.4271409\n",
      "Epoch 190: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 191: -- Training loss 0.40119267 -- Validation loss:0.45196572 -- Test loss 0.425493\n",
      "Epoch 191: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 192: -- Training loss 0.3992035 -- Validation loss:0.45039356 -- Test loss 0.42385268\n",
      "Epoch 192: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 193: -- Training loss 0.3972202 -- Validation loss:0.44882992 -- Test loss 0.4222198\n",
      "Epoch 193: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 194: -- Training loss 0.39524272 -- Validation loss:0.44727445 -- Test loss 0.42059413\n",
      "Epoch 194: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 195: -- Training loss 0.393271 -- Validation loss:0.44572714 -- Test loss 0.41897544\n",
      "Epoch 195: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.88\n",
      "Epoch 196: -- Training loss 0.39130488 -- Validation loss:0.44418785 -- Test loss 0.41736367\n",
      "Epoch 196: -- Training acc  0.971830985915493 -- Validation acc: 0.7916666666666666 -- Test acc  0.92\n",
      "Epoch 197: -- Training loss 0.38934448 -- Validation loss:0.4426562 -- Test loss 0.41575873\n",
      "Epoch 197: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 198: -- Training loss 0.3873897 -- Validation loss:0.4411323 -- Test loss 0.41416034\n",
      "Epoch 198: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 199: -- Training loss 0.3854404 -- Validation loss:0.43961596 -- Test loss 0.4125684\n",
      "Epoch 199: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 200: -- Training loss 0.38349682 -- Validation loss:0.43810698 -- Test loss 0.41098294\n",
      "Epoch 200: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 201: -- Training loss 0.3815588 -- Validation loss:0.4366052 -- Test loss 0.4094037\n",
      "Epoch 201: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 202: -- Training loss 0.37962636 -- Validation loss:0.4351106 -- Test loss 0.4078307\n",
      "Epoch 202: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 203: -- Training loss 0.37769946 -- Validation loss:0.43362305 -- Test loss 0.40626374\n",
      "Epoch 203: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 204: -- Training loss 0.37577826 -- Validation loss:0.43214238 -- Test loss 0.40470284\n",
      "Epoch 204: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 205: -- Training loss 0.37386262 -- Validation loss:0.43066847 -- Test loss 0.40314782\n",
      "Epoch 205: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 206: -- Training loss 0.37195268 -- Validation loss:0.42920145 -- Test loss 0.4015987\n",
      "Epoch 206: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 207: -- Training loss 0.37004843 -- Validation loss:0.42774096 -- Test loss 0.40005532\n",
      "Epoch 207: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 208: -- Training loss 0.36814994 -- Validation loss:0.42628708 -- Test loss 0.39851788\n",
      "Epoch 208: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 209: -- Training loss 0.36625713 -- Validation loss:0.4248397 -- Test loss 0.3969859\n",
      "Epoch 209: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 210: -- Training loss 0.3643702 -- Validation loss:0.42339864 -- Test loss 0.39545962\n",
      "Epoch 210: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 211: -- Training loss 0.3624891 -- Validation loss:0.42196396 -- Test loss 0.39393893\n",
      "Epoch 211: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 212: -- Training loss 0.360614 -- Validation loss:0.42053553 -- Test loss 0.3924238\n",
      "Epoch 212: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 213: -- Training loss 0.35874486 -- Validation loss:0.41911316 -- Test loss 0.39091423\n",
      "Epoch 213: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 214: -- Training loss 0.3568816 -- Validation loss:0.41769704 -- Test loss 0.38941002\n",
      "Epoch 214: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 215: -- Training loss 0.35502452 -- Validation loss:0.4162868 -- Test loss 0.38791135\n",
      "Epoch 215: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 216: -- Training loss 0.3531735 -- Validation loss:0.4148825 -- Test loss 0.3864179\n",
      "Epoch 216: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 217: -- Training loss 0.35132873 -- Validation loss:0.4134842 -- Test loss 0.38492978\n",
      "Epoch 217: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 218: -- Training loss 0.34949014 -- Validation loss:0.41209164 -- Test loss 0.38344705\n",
      "Epoch 218: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 219: -- Training loss 0.34765786 -- Validation loss:0.41070485 -- Test loss 0.38196954\n",
      "Epoch 219: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 220: -- Training loss 0.345832 -- Validation loss:0.40932378 -- Test loss 0.38049728\n",
      "Epoch 220: -- Training acc  0.971830985915493 -- Validation acc: 0.8333333333333334 -- Test acc  0.92\n",
      "Epoch 221: -- Training loss 0.34401253 -- Validation loss:0.40794837 -- Test loss 0.37903032\n",
      "Epoch 221: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 222: -- Training loss 0.34219947 -- Validation loss:0.40657857 -- Test loss 0.3775685\n",
      "Epoch 222: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 223: -- Training loss 0.34039304 -- Validation loss:0.40521434 -- Test loss 0.3761119\n",
      "Epoch 223: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 224: -- Training loss 0.33859313 -- Validation loss:0.4038556 -- Test loss 0.37466052\n",
      "Epoch 224: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 225: -- Training loss "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33679992 -- Validation loss:0.4025024 -- Test loss 0.3732143\n",
      "Epoch 225: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 226: -- Training loss 0.33501336 -- Validation loss:0.4011546 -- Test loss 0.3717732\n",
      "Epoch 226: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 227: -- Training loss 0.3332336 -- Validation loss:0.39981222 -- Test loss 0.37033722\n",
      "Epoch 227: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 228: -- Training loss 0.33146062 -- Validation loss:0.39847514 -- Test loss 0.36890647\n",
      "Epoch 228: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 229: -- Training loss 0.32969457 -- Validation loss:0.39714336 -- Test loss 0.3674807\n",
      "Epoch 229: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 230: -- Training loss 0.32793543 -- Validation loss:0.39581695 -- Test loss 0.36606008\n",
      "Epoch 230: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 231: -- Training loss 0.32618317 -- Validation loss:0.39449573 -- Test loss 0.36464456\n",
      "Epoch 231: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 232: -- Training loss 0.3244381 -- Validation loss:0.39317968 -- Test loss 0.363234\n",
      "Epoch 232: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 233: -- Training loss 0.32270005 -- Validation loss:0.39186883 -- Test loss 0.36182863\n",
      "Epoch 233: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 234: -- Training loss 0.32096905 -- Validation loss:0.39056298 -- Test loss 0.36042812\n",
      "Epoch 234: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 235: -- Training loss 0.31924525 -- Validation loss:0.3892623 -- Test loss 0.35903287\n",
      "Epoch 235: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 236: -- Training loss 0.31752872 -- Validation loss:0.38796666 -- Test loss 0.35764253\n",
      "Epoch 236: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 237: -- Training loss 0.31581944 -- Validation loss:0.38667604 -- Test loss 0.35625708\n",
      "Epoch 237: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 238: -- Training loss 0.3141175 -- Validation loss:0.38539037 -- Test loss 0.3548767\n",
      "Epoch 238: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 239: -- Training loss 0.31242278 -- Validation loss:0.38410977 -- Test loss 0.3535014\n",
      "Epoch 239: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 240: -- Training loss 0.31073564 -- Validation loss:0.3828341 -- Test loss 0.35213116\n",
      "Epoch 240: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 241: -- Training loss 0.30905578 -- Validation loss:0.3815634 -- Test loss 0.35076576\n",
      "Epoch 241: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 242: -- Training loss 0.3073834 -- Validation loss:0.38029757 -- Test loss 0.34940544\n",
      "Epoch 242: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 243: -- Training loss 0.30571863 -- Validation loss:0.37903666 -- Test loss 0.34805015\n",
      "Epoch 243: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 244: -- Training loss 0.3040613 -- Validation loss:0.3777807 -- Test loss 0.34669974\n",
      "Epoch 244: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 245: -- Training loss 0.30241156 -- Validation loss:0.37652948 -- Test loss 0.34535423\n",
      "Epoch 245: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 246: -- Training loss 0.30076945 -- Validation loss:0.37528312 -- Test loss 0.34401378\n",
      "Epoch 246: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 247: -- Training loss 0.299135 -- Validation loss:0.37404168 -- Test loss 0.34267837\n",
      "Epoch 247: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 248: -- Training loss 0.29750818 -- Validation loss:0.372805 -- Test loss 0.3413478\n",
      "Epoch 248: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 249: -- Training loss 0.29588905 -- Validation loss:0.37157333 -- Test loss 0.34002233\n",
      "Epoch 249: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 250: -- Training loss 0.29427767 -- Validation loss:0.37034622 -- Test loss 0.33870167\n",
      "Epoch 250: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 251: -- Training loss 0.29267406 -- Validation loss:0.36912417 -- Test loss 0.33738598\n",
      "Epoch 251: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 252: -- Training loss 0.29107818 -- Validation loss:0.36790678 -- Test loss 0.33607534\n",
      "Epoch 252: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 253: -- Training loss 0.28949013 -- Validation loss:0.3666942 -- Test loss 0.33476952\n",
      "Epoch 253: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 254: -- Training loss 0.28790987 -- Validation loss:0.36548647 -- Test loss 0.3334687\n",
      "Epoch 254: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 255: -- Training loss 0.28633744 -- Validation loss:0.36428356 -- Test loss 0.33217284\n",
      "Epoch 255: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 256: -- Training loss 0.28477287 -- Validation loss:0.36308542 -- Test loss 0.33088204\n",
      "Epoch 256: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 257: -- Training loss 0.28321624 -- Validation loss:0.36189222 -- Test loss 0.32959613\n",
      "Epoch 257: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 258: -- Training loss 0.2816674 -- Validation loss:0.36070397 -- Test loss 0.32831523\n",
      "Epoch 258: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 259: -- Training loss 0.28012657 -- Validation loss:0.35952044 -- Test loss 0.3270393\n",
      "Epoch 259: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 260: -- Training loss 0.27859366 -- Validation loss:0.35834178 -- Test loss 0.32576835\n",
      "Epoch 260: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 261: -- Training loss 0.27706861 -- Validation loss:0.35716805 -- Test loss 0.3245023\n",
      "Epoch 261: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 262: -- Training loss 0.27555156 -- Validation loss:0.3559991 -- Test loss 0.3232412\n",
      "Epoch 262: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 263: -- Training loss 0.2740425 -- Validation loss:0.35483524 -- Test loss 0.32198521\n",
      "Epoch 263: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 264: -- Training loss 0.27254137 -- Validation loss:0.3536762 -- Test loss 0.32073417\n",
      "Epoch 264: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 265: -- Training loss 0.27104825 -- Validation loss:0.35252213 -- Test loss 0.31948808\n",
      "Epoch 265: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 266: -- Training loss 0.26956308 -- Validation loss:0.351373 -- Test loss 0.31824702\n",
      "Epoch 266: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 267: -- Training loss 0.2680859 -- Validation loss:0.350229 -- Test loss 0.3170111\n",
      "Epoch 267: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 268: -- Training loss 0.26661676 -- Validation loss:0.34908983 -- Test loss 0.31578007\n",
      "Epoch 268: -- Training acc  0.971830985915493 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 269: -- Training loss 0.26515564 -- Validation loss:0.3479558 -- Test loss 0.3145541\n",
      "Epoch 269: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 270: -- Training loss 0.26370254 -- Validation loss:0.34682688 -- Test loss 0.31333315\n",
      "Epoch 270: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 271: -- Training loss 0.26225737 -- Validation loss:0.34570292 -- Test loss 0.3121173\n",
      "Epoch 271: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 272: -- Training loss 0.26082024 -- Validation loss:0.3445842 -- Test loss 0.31090644\n",
      "Epoch 272: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 273: -- Training loss 0.25939116 -- Validation loss:0.34347054 -- Test loss 0.30970073\n",
      "Epoch 273: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 274: -- Training loss 0.25797006 -- Validation loss:0.34236202 -- Test loss 0.3085001\n",
      "Epoch 274: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 275: -- Training loss 0.25655705 -- Validation loss:0.3412588 -- Test loss 0.30730447\n",
      "Epoch 275: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 276: -- Training loss 0.25515193 -- Validation loss:0.34016064 -- Test loss 0.30611405\n",
      "Epoch 276: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 277: -- Training loss 0.25375488 -- Validation loss:0.33906785 -- Test loss 0.30492875\n",
      "Epoch 277: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 278: -- Training loss 0.2523658 -- Validation loss:0.33798036 -- Test loss 0.30374843\n",
      "Epoch 278: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 279: -- Training loss 0.25098467 -- Validation loss:0.33689806 -- Test loss 0.30257335\n",
      "Epoch 279: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 280: -- Training loss 0.24961163 -- Validation loss:0.33582106 -- Test loss 0.30140334\n",
      "Epoch 280: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 281: -- Training loss 0.24824642 -- Validation loss:0.3347495 -- Test loss 0.30023852\n",
      "Epoch 281: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 282: -- Training loss 0.24688928 -- Validation loss:0.33368325 -- Test loss 0.29907888\n",
      "Epoch 282: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 283: -- Training loss 0.24554002 -- Validation loss:0.3326224 -- Test loss 0.2979244\n",
      "Epoch 283: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 284: -- Training loss 0.24419875 -- Validation loss:0.33156696 -- Test loss 0.2967751\n",
      "Epoch 284: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 285: -- Training loss 0.24286538 -- Validation loss:0.33051702 -- Test loss 0.29563105\n",
      "Epoch 285: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 286: -- Training loss 0.24153997 -- Validation loss:0.32947257 -- Test loss 0.29449213\n",
      "Epoch 286: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 287: -- Training loss 0.24022242 -- Validation loss:0.32843354 -- Test loss 0.2933585\n",
      "Epoch 287: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 288: -- Training loss 0.23891278 -- Validation loss:0.32740012 -- Test loss 0.2922301\n",
      "Epoch 288: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 289: -- Training loss 0.23761103 -- Validation loss:0.32637218 -- Test loss 0.29110694\n",
      "Epoch 289: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 290: -- Training loss 0.23631711 -- Validation loss:0.3253499 -- Test loss 0.28998908\n",
      "Epoch 290: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 291: -- Training loss 0.23503105 -- Validation loss:0.32433322 -- Test loss 0.2888766\n",
      "Epoch 291: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 292: -- Training loss 0.23375274 -- Validation loss:0.32332218 -- Test loss 0.2877693\n",
      "Epoch 292: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 293: -- Training loss 0.23248227 -- Validation loss:0.32231686 -- Test loss 0.28666738\n",
      "Epoch 293: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 294: -- Training loss 0.23121963 -- Validation loss:0.3213171 -- Test loss 0.28557074\n",
      "Epoch 294: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 295: -- Training loss 0.22996467 -- Validation loss:0.32032293 -- Test loss 0.28447938\n",
      "Epoch 295: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 296: -- Training loss 0.2287175 -- Validation loss:0.3193346 -- Test loss 0.2833934\n",
      "Epoch 296: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 297: -- Training loss 0.22747803 -- Validation loss:0.31835195 -- Test loss 0.28231278\n",
      "Epoch 297: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 298: -- Training loss 0.22624625 -- Validation loss:0.3173751 -- Test loss 0.28123757\n",
      "Epoch 298: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 299: -- Training loss 0.22502212 -- Validation loss:0.31640396 -- Test loss 0.2801677\n",
      "Epoch 299: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 300: -- Training loss 0.22380568 -- Validation loss:0.3154386 -- Test loss 0.2791033\n",
      "Epoch 300: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 301: -- Training loss 0.22259684 -- Validation loss:0.31447908 -- Test loss 0.2780443\n",
      "Epoch 301: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 302: -- Training loss 0.2213956 -- Validation loss:0.3135254 -- Test loss 0.2769907\n",
      "Epoch 302: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 303: -- Training loss 0.2202019 -- Validation loss:0.31257758 -- Test loss 0.2759426\n",
      "Epoch 303: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 304: -- Training loss 0.2190157 -- Validation loss:0.31163558 -- Test loss 0.2748999\n",
      "Epoch 304: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 305: -- Training loss 0.2178371 -- Validation loss:0.31069937 -- Test loss 0.27386278\n",
      "Epoch 305: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 306: -- Training loss 0.21666594 -- Validation loss:0.30976918 -- Test loss 0.27283105\n",
      "Epoch 306: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 307: -- Training loss 0.21550222 -- Validation loss:0.30884477 -- Test loss 0.2718048\n",
      "Epoch 307: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 308: -- Training loss 0.21434595 -- Validation loss:0.30792624 -- Test loss 0.27078405\n",
      "Epoch 308: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 309: -- Training loss 0.21319707 -- Validation loss:0.30701366 -- Test loss 0.26976895\n",
      "Epoch 309: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 310: -- Training loss 0.21205555 -- Validation loss:0.30610698 -- Test loss 0.26875922\n",
      "Epoch 310: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 311: -- Training loss 0.21092135 -- Validation loss:0.3052063 -- Test loss 0.2677552\n",
      "Epoch 311: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 312: -- Training loss 0.20979445 -- Validation loss:0.3043114 -- Test loss 0.26675662\n",
      "Epoch 312: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 313: -- Training loss 0.20867485 -- Validation loss:0.30342254 -- Test loss 0.2657636\n",
      "Epoch 313: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 314: -- Training loss 0.20756248 -- Validation loss:0.30253968 -- Test loss 0.2647762\n",
      "Epoch 314: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 315: -- Training loss 0.2064573 -- Validation loss:0.30166265 -- Test loss 0.26379448\n",
      "Epoch 315: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 316: -- Training loss 0.20535932 -- Validation loss:0.3007916 -- Test loss 0.26281822\n",
      "Epoch 316: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 317: -- Training loss 0.20426847 -- Validation loss:0.29992655 -- Test loss 0.26184765\n",
      "Epoch 317: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 318: -- Training loss 0.20318474 -- Validation loss:0.29906744 -- Test loss 0.26088277\n",
      "Epoch 318: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 319: -- Training loss 0.20210804 -- Validation loss:0.2982143 -- Test loss 0.25992334\n",
      "Epoch 319: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 320: -- Training loss 0.20103839 -- Validation loss:0.2973671 -- Test loss 0.2589696\n",
      "Epoch 320: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 321: -- Training loss 0.19997579 -- Validation loss:0.2965258 -- Test loss 0.2580216\n",
      "Epoch 321: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 322: -- Training loss 0.19892012 -- Validation loss:0.2956906 -- Test loss 0.25707924\n",
      "Epoch 322: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 323: -- Training loss 0.19787139 -- Validation loss:0.29486117 -- Test loss 0.25614244\n",
      "Epoch 323: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 324: -- Training loss 0.19682959 -- Validation loss:0.29403776 -- Test loss 0.25521144\n",
      "Epoch 324: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 325: -- Training loss 0.19579458 -- Validation loss:0.29322028 -- Test loss 0.25428596\n",
      "Epoch 325: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 326: -- Training loss 0.1947665 -- Validation loss:0.29240873 -- Test loss 0.25336632\n",
      "Epoch 326: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 327: -- Training loss 0.19374514 -- Validation loss:0.2916032 -- Test loss 0.25245228\n",
      "Epoch 327: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 328: -- Training loss 0.19273055 -- Validation loss:0.29080352 -- Test loss 0.251544\n",
      "Epoch 328: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 329: -- Training loss 0.19172266 -- Validation loss:0.29000983 -- Test loss 0.2506413\n",
      "Epoch 329: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 330: -- Training loss 0.1907215 -- Validation loss:0.28922197 -- Test loss 0.24974443\n",
      "Epoch 330: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 331: -- Training loss 0.18972693 -- Validation loss:0.28843996 -- Test loss 0.24885319\n",
      "Epoch 331: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 332: -- Training loss 0.18873902 -- Validation loss:0.287664 -- Test loss 0.2479677\n",
      "Epoch 332: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 333: -- Training loss 0.18775764 -- Validation loss:0.28689378 -- Test loss 0.2470879\n",
      "Epoch 333: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 334: -- Training loss 0.18678284 -- Validation loss:0.28612947 -- Test loss 0.24621378\n",
      "Epoch 334: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 335: -- Training loss 0.18581451 -- Validation loss:0.285371 -- Test loss 0.24534541\n",
      "Epoch 335: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 336: -- Training loss 0.18485263 -- Validation loss:0.28461835 -- Test loss 0.24448274\n",
      "Epoch 336: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 337: -- Training loss 0.18389712 -- Validation loss:0.28387162 -- Test loss 0.24362576\n",
      "Epoch 337: -- Training acc  0.9859154929577465 -- Validation acc: 0.875"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Test acc  0.92\n",
      "Epoch 338: -- Training loss 0.18294808 -- Validation loss:0.28313062 -- Test loss 0.24277455\n",
      "Epoch 338: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 339: -- Training loss 0.1820054 -- Validation loss:0.2823956 -- Test loss 0.24192913\n",
      "Epoch 339: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 340: -- Training loss 0.18106897 -- Validation loss:0.28166628 -- Test loss 0.2410894\n",
      "Epoch 340: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 341: -- Training loss 0.18013886 -- Validation loss:0.28094277 -- Test loss 0.24025537\n",
      "Epoch 341: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 342: -- Training loss 0.17921495 -- Validation loss:0.28022495 -- Test loss 0.23942702\n",
      "Epoch 342: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 343: -- Training loss 0.17829725 -- Validation loss:0.2795128 -- Test loss 0.23860429\n",
      "Epoch 343: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 344: -- Training loss 0.17738569 -- Validation loss:0.2788065 -- Test loss 0.23778738\n",
      "Epoch 344: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 345: -- Training loss 0.17648028 -- Validation loss:0.27810588 -- Test loss 0.2369761\n",
      "Epoch 345: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 346: -- Training loss 0.1755809 -- Validation loss:0.2774109 -- Test loss 0.23617058\n",
      "Epoch 346: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 347: -- Training loss 0.17468765 -- Validation loss:0.27672163 -- Test loss 0.23537071\n",
      "Epoch 347: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 348: -- Training loss 0.17380038 -- Validation loss:0.27603796 -- Test loss 0.23457652\n",
      "Epoch 348: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 349: -- Training loss 0.17291905 -- Validation loss:0.27536005 -- Test loss 0.23378801\n",
      "Epoch 349: -- Training acc  0.9859154929577465 -- Validation acc: 0.875 -- Test acc  0.92\n",
      "Epoch 350: -- Training loss 0.17204367 -- Validation loss:0.27468768 -- Test loss 0.23300526\n",
      "Epoch 350: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 351: -- Training loss 0.17117415 -- Validation loss:0.27402088 -- Test loss 0.23222816\n",
      "Epoch 351: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 352: -- Training loss 0.17031057 -- Validation loss:0.2733597 -- Test loss 0.2314567\n",
      "Epoch 352: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 353: -- Training loss 0.16945274 -- Validation loss:0.27270398 -- Test loss 0.23069078\n",
      "Epoch 353: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 354: -- Training loss 0.16860074 -- Validation loss:0.27205387 -- Test loss 0.2299306\n",
      "Epoch 354: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 355: -- Training loss 0.16775444 -- Validation loss:0.27140933 -- Test loss 0.22917606\n",
      "Epoch 355: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 356: -- Training loss 0.16691385 -- Validation loss:0.27077022 -- Test loss 0.22842714\n",
      "Epoch 356: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 357: -- Training loss 0.16607894 -- Validation loss:0.27013656 -- Test loss 0.22768381\n",
      "Epoch 357: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 358: -- Training loss 0.16524969 -- Validation loss:0.26950836 -- Test loss 0.2269461\n",
      "Epoch 358: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 359: -- Training loss 0.164426 -- Validation loss:0.26888555 -- Test loss 0.22621393\n",
      "Epoch 359: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 360: -- Training loss 0.16360793 -- Validation loss:0.2682682 -- Test loss 0.22548741\n",
      "Epoch 360: -- Training acc  0.9859154929577465 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 361: -- Training loss 0.16279532 -- Validation loss:0.2676562 -- Test loss 0.22476643\n",
      "Epoch 361: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 362: -- Training loss 0.1619882 -- Validation loss:0.26704955 -- Test loss 0.22405095\n",
      "Epoch 362: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 363: -- Training loss 0.16118655 -- Validation loss:0.2664483 -- Test loss 0.223341\n",
      "Epoch 363: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 364: -- Training loss 0.16039027 -- Validation loss:0.26585227 -- Test loss 0.22263665\n",
      "Epoch 364: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 365: -- Training loss 0.15959941 -- Validation loss:0.26526156 -- Test loss 0.22193778\n",
      "Epoch 365: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 366: -- Training loss 0.1588139 -- Validation loss:0.26467603 -- Test loss 0.22124438\n",
      "Epoch 366: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 367: -- Training loss 0.15803364 -- Validation loss:0.26409596 -- Test loss 0.22055653\n",
      "Epoch 367: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 368: -- Training loss 0.1572587 -- Validation loss:0.2635209 -- Test loss 0.21987402\n",
      "Epoch 368: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 369: -- Training loss 0.156489 -- Validation loss:0.26295105 -- Test loss 0.21919702\n",
      "Epoch 369: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 370: -- Training loss 0.15572439 -- Validation loss:0.26238635 -- Test loss 0.21852542\n",
      "Epoch 370: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 371: -- Training loss 0.15496504 -- Validation loss:0.26182684 -- Test loss 0.21785934\n",
      "Epoch 371: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 372: -- Training loss 0.15421075 -- Validation loss:0.26127246 -- Test loss 0.2171986\n",
      "Epoch 372: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 373: -- Training loss 0.15346158 -- Validation loss:0.26072314 -- Test loss 0.21654321\n",
      "Epoch 373: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 374: -- Training loss 0.15271746 -- Validation loss:0.26017883 -- Test loss 0.2158932\n",
      "Epoch 374: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 375: -- Training loss 0.15197836 -- Validation loss:0.2596396 -- Test loss 0.21524854\n",
      "Epoch 375: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 376: -- Training loss 0.15124422 -- Validation loss:0.2591054 -- Test loss 0.21460916\n",
      "Epoch 376: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 377: -- Training loss 0.15051506 -- Validation loss:0.25857607 -- Test loss 0.21397513\n",
      "Epoch 377: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 378: -- Training loss 0.1497908 -- Validation loss:0.25805172 -- Test loss 0.21334633\n",
      "Epoch 378: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 379: -- Training loss 0.14907138 -- Validation loss:0.25753233 -- Test loss 0.21272287\n",
      "Epoch 379: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 380: -- Training loss 0.14835684 -- Validation loss:0.2570179 -- Test loss 0.2121046\n",
      "Epoch 380: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 381: -- Training loss 0.1476471 -- Validation loss:0.2565084 -- Test loss 0.2114916\n",
      "Epoch 381: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 382: -- Training loss 0.14694214 -- Validation loss:0.25600365 -- Test loss 0.2108837\n",
      "Epoch 382: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 383: -- Training loss 0.14624192 -- Validation loss:0.25550377 -- Test loss 0.21028109\n",
      "Epoch 383: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 384: -- Training loss 0.14554639 -- Validation loss:0.25500867 -- Test loss 0.20968367\n",
      "Epoch 384: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 385: -- Training loss 0.14485554 -- Validation loss:0.25451842 -- Test loss 0.20909126\n",
      "Epoch 385: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 386: -- Training loss 0.14416933 -- Validation loss:0.2540328 -- Test loss 0.20850405\n",
      "Epoch 386: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 387: -- Training loss 0.14348768 -- Validation loss:0.25355193 -- Test loss 0.20792192\n",
      "Epoch 387: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 388: -- Training loss 0.14281066 -- Validation loss:0.25307587 -- Test loss 0.20734483\n",
      "Epoch 388: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 389: -- Training loss 0.14213814 -- Validation loss:0.2526043 -- Test loss 0.20677273\n",
      "Epoch 389: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 390: -- Training loss 0.1414701 -- Validation loss:0.25213754 -- Test loss 0.20620583\n",
      "Epoch 390: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 391: -- Training loss 0.14080662 -- Validation loss:0.25167528 -- Test loss 0.20564386\n",
      "Epoch 391: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 392: -- Training loss 0.14014754 -- Validation loss:0.2512178 -- Test loss 0.20508689\n",
      "Epoch 392: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 393: -- Training loss 0.13949284 -- Validation loss:0.25076464 -- Test loss 0.20453486\n",
      "Epoch 393: -- Training acc  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 394: -- Training loss 0.13884257 -- Validation loss:0.2503162 -- Test loss 0.20398775\n",
      "Epoch 394: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 395: -- Training loss 0.13819659 -- Validation loss:0.24987221 -- Test loss 0.20344563\n",
      "Epoch 395: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 396: -- Training loss 0.13755488 -- Validation loss:0.2494328 -- Test loss 0.20290838\n",
      "Epoch 396: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 397: -- Training loss 0.13691759 -- Validation loss:0.2489977 -- Test loss 0.2023759\n",
      "Epoch 397: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 398: -- Training loss 0.13628444 -- Validation loss:0.24856722 -- Test loss 0.20184833\n",
      "Epoch 398: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 399: -- Training loss 0.1356555 -- Validation loss:0.24814093 -- Test loss 0.20132554\n",
      "Epoch 399: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 400: -- Training loss 0.13503079 -- Validation loss:0.24771918 -- Test loss 0.20080753\n",
      "Epoch 400: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 401: -- Training loss 0.13441017 -- Validation loss:0.24730183 -- Test loss 0.20029432\n",
      "Epoch 401: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 402: -- Training loss 0.13379377 -- Validation loss:0.2468887 -- Test loss 0.19978583\n",
      "Epoch 402: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 403: -- Training loss 0.1331814 -- Validation loss:0.24647997 -- Test loss 0.19928211\n",
      "Epoch 403: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 404: -- Training loss 0.13257308 -- Validation loss:0.2460755 -- Test loss 0.19878311\n",
      "Epoch 404: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 405: -- Training loss 0.13196883 -- Validation loss:0.24567527 -- Test loss 0.19828874\n",
      "Epoch 405: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 406: -- Training loss 0.13136858 -- Validation loss:0.2452793 -- Test loss 0.19779903\n",
      "Epoch 406: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 407: -- Training loss 0.13077226 -- Validation loss:0.24488749 -- Test loss 0.1973139\n",
      "Epoch 407: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 408: -- Training loss 0.1301799 -- Validation loss:0.2444998 -- Test loss 0.19683328\n",
      "Epoch 408: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 409: -- Training loss 0.12959146 -- Validation loss:0.24411638 -- Test loss 0.19635743\n",
      "Epoch 409: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 410: -- Training loss 0.12900692 -- Validation loss:0.24373712 -- Test loss 0.19588605\n",
      "Epoch 410: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 411: -- Training loss 0.1284262 -- Validation loss:0.24336196 -- Test loss 0.19541918\n",
      "Epoch 411: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 412: -- Training loss 0.12784933 -- Validation loss:0.24299087 -- Test loss 0.19495687\n",
      "Epoch 412: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 413: -- Training loss 0.12727623 -- Validation loss:0.24262382 -- Test loss 0.19449902\n",
      "Epoch 413: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 414: -- Training loss 0.12670691 -- Validation loss:0.24226081 -- Test loss 0.19404554\n",
      "Epoch 414: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 415: -- Training loss 0.12614132 -- Validation loss:0.24190186 -- Test loss 0.19359657\n",
      "Epoch 415: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 416: -- Training loss 0.12557946 -- Validation loss:0.24154691 -- Test loss 0.19315189\n",
      "Epoch 416: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 417: -- Training loss 0.12502128 -- Validation loss:0.2411958 -- Test loss 0.19271168\n",
      "Epoch 417: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 418: -- Training loss 0.12446671 -- Validation loss:0.24084872 -- Test loss 0.19227579\n",
      "Epoch 418: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 419: -- Training loss 0.12391581 -- Validation loss:0.24050547 -- Test loss 0.19184417\n",
      "Epoch 419: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 420: -- Training loss 0.123368494 -- Validation loss:0.24016613 -- Test loss 0.19141689\n",
      "Epoch 420: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 421: -- Training loss 0.12282475 -- Validation loss:0.23983072 -- Test loss 0.19099385\n",
      "Epoch 421: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 422: -- Training loss 0.12228454 -- Validation loss:0.23949917 -- Test loss 0.1905752\n",
      "Epoch 422: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 423: -- Training loss 0.12174784 -- Validation loss:0.23917134 -- Test loss 0.19016074\n",
      "Epoch 423: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 424: -- Training loss 0.1212146 -- Validation loss:0.23884736 -- Test loss 0.18975034\n",
      "Epoch 424: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 425: -- Training loss 0.12068486 -- Validation loss:0.23852725 -- Test loss 0.18934426\n",
      "Epoch 425: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 426: -- Training loss 0.12015856 -- Validation loss:0.2382108 -- Test loss 0.18894228\n",
      "Epoch 426: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 427: -- Training loss 0.11963568 -- Validation loss:0.23789804 -- Test loss 0.1885444\n",
      "Epoch 427: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 428: -- Training loss 0.119116135 -- Validation loss:0.237589 -- Test loss 0.18815063\n",
      "Epoch 428: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 429: -- Training loss 0.118599996 -- Validation loss:0.23728351 -- Test loss 0.18776095\n",
      "Epoch 429: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 430: -- Training loss 0.118087165 -- Validation loss:0.23698173 -- Test loss 0.18737529\n",
      "Epoch 430: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 431: -- Training loss 0.117577635 -- Validation loss:0.23668368 -- Test loss 0.18699366\n",
      "Epoch 431: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 432: -- Training loss 0.11707139 -- Validation loss:0.23638922 -- Test loss "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Excessive output truncated after 524292 bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18661608\n",
      "Epoch 432: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 433: -- Training loss 0.11656842 -- Validation loss:0.23609835 -- Test loss 0.18624245\n",
      "Epoch 433: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 434: -- Training loss 0.116068654 -- Validation loss:0.23581104 -- Test loss 0.18587282\n",
      "Epoch 434: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 435: -- Training loss 0.115572125 -- Validation loss:0.23552726 -- Test loss 0.18550712\n",
      "Epoch 435: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 436: -- Training loss 0.11507874 -- Validation loss:0.23524696 -- Test loss 0.1851453\n",
      "Epoch 436: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 437: -- Training loss 0.11458852 -- Validation loss:0.23497017 -- Test loss 0.1847874\n",
      "Epoch 437: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 438: -- Training loss 0.11410144 -- Validation loss:0.23469685 -- Test loss 0.18443333\n",
      "Epoch 438: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 439: -- Training loss 0.11361744 -- Validation loss:0.23442692 -- Test loss 0.18408313\n",
      "Epoch 439: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 440: -- Training loss 0.11313656 -- Validation loss:0.23416053 -- Test loss 0.18373671\n",
      "Epoch 440: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 441: -- Training loss 0.11265873 -- Validation loss:0.23389752 -- Test loss 0.183394\n",
      "Epoch 441: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 442: -- Training loss 0.112183936 -- Validation loss:0.23363782 -- Test loss 0.18305518\n",
      "Epoch 442: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 443: -- Training loss 0.111712135 -- Validation loss:0.23338158 -- Test loss 0.18272004\n",
      "Epoch 443: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 444: -- Training loss 0.111243345 -- Validation loss:0.23312856 -- Test loss 0.18238863\n",
      "Epoch 444: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 445: -- Training loss 0.1107775 -- Validation loss:0.23287892 -- Test loss 0.18206085\n",
      "Epoch 445: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 446: -- Training loss 0.11031461 -- Validation loss:0.23263258 -- Test loss 0.1817369\n",
      "Epoch 446: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 447: -- Training loss 0.10985463 -- Validation loss:0.2323895 -- Test loss 0.18141656\n",
      "Epoch 447: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 448: -- Training loss 0.10939754 -- Validation loss:0.2321497 -- Test loss 0.18109977\n",
      "Epoch 448: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 449: -- Training loss 0.10894331 -- Validation loss:0.23191316 -- Test loss 0.1807866\n",
      "Epoch 449: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 450: -- Training loss 0.10849196 -- Validation loss:0.23167984 -- Test loss 0.18047702\n",
      "Epoch 450: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 451: -- Training loss 0.10804344 -- Validation loss:0.23144965 -- Test loss 0.180171\n",
      "Epoch 451: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 452: -- Training loss 0.107597716 -- Validation loss:0.23122257 -- Test loss 0.17986856\n",
      "Epoch 452: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 453: -- Training loss 0.107154794 -- Validation loss:0.23099875 -- Test loss 0.17956965\n",
      "Epoch 453: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 454: -- Training loss 0.10671463 -- Validation loss:0.23077805 -- Test loss 0.17927413\n",
      "Epoch 454: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 455: -- Training loss 0.10627721 -- Validation loss:0.23056048 -- Test loss 0.17898217\n",
      "Epoch 455: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 456: -- Training loss 0.105842486 -- Validation loss:0.2303459 -- Test loss 0.17869368\n",
      "Epoch 456: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 457: -- Training loss 0.105410494 -- Validation loss:0.23013444 -- Test loss 0.17840849\n",
      "Epoch 457: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 458: -- Training loss 0.104981154 -- Validation loss:0.22992595 -- Test loss 0.17812677\n",
      "Epoch 458: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 459: -- Training loss 0.10455448 -- Validation loss:0.22972055 -- Test loss 0.17784846\n",
      "Epoch 459: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 460: -- Training loss 0.10413044 -- Validation loss:0.22951816 -- Test loss 0.17757347\n",
      "Epoch 460: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 461: -- Training loss 0.10370901 -- Validation loss:0.22931875 -- Test loss 0.1773018\n",
      "Epoch 461: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 462: -- Training loss 0.1032902 -- Validation loss:0.22912236 -- Test loss 0.17703348\n",
      "Epoch 462: -- Training acc  1.0 -- Validation acc: 0.9166666666666666 -- Test acc  0.92\n",
      "Epoch 463: -- Training loss 0.10287395 -- Validation loss:0.22892891 -- Test loss 0.17676844\n",
      "Epoch 463"
     ]
    }
   ],
   "source": [
    "import Pkg;\n",
    "Pkg.add(\"DelimitedFiles\");    \n",
    "using DelimitedFiles\n",
    "\n",
    "include(\"./code/general/model_factory.jl\")\n",
    "include(\"./code/ann/utils_ann.jl\")\n",
    "include(\"./code/general/utils_general.jl\")\n",
    "\n",
    "\n",
    "\n",
    "topology = [4, 3]\n",
    "\n",
    "ann_hyperparameters = Dict(\n",
    "    :modelType => :ANN,\n",
    "    :topology => topology,                      \n",
    "    :transferFunctions => fill(, length(topology)),            \n",
    "    :learningRate => 0.01,                  \n",
    "    :validationRatio => 0.2,                  \n",
    "    :maxEpochs => 1000,          \n",
    "    :maxEpochsVal => 20                         \n",
    ")\n",
    "\n",
    "\n",
    "svc_hyperparameters = Dict(\n",
    "    :modelType => :SVC,\n",
    "    :cost   => Float64(1.0),                          \n",
    "    :kernel => \"rbf\",              \n",
    "    :degree => Int32(3),                             \n",
    "    :gamma  => Float64(0.1),                          \n",
    "    :coef0  => Float64(0.0)                         \n",
    ")\n",
    "\n",
    "dt_hyperparameters = Dict(\n",
    "    :modelType => :DecisionTreeClassifier,\n",
    "    :max_depth => 5,                                     \n",
    "    :rng       => Random.MersenneTwister(1)             \n",
    ")\n",
    "\n",
    "knn_hyperparameters = Dict(\n",
    "    :modelType => :KNeighborsClassifier,\n",
    "    :n_neighbors => 3   \n",
    ")\n",
    "\n",
    "\n",
    "#Load iris dataset\n",
    "dataset = readdlm(\"./data_test/iris.data\",',');\n",
    "datasetLength = size(dataset, 1)\n",
    "\n",
    "\n",
    "(trainIndexes, testIndexes) = holdOut(datasetLength, 0.2)\n",
    "(trainDataset, testDataset) = (dataset[trainIndexes, :], dataset[testIndexes, :])\n",
    "(trainInput, testInput) =  (trainDataset[:,1:4], testDataset[:,1:4])\n",
    "\n",
    "(trainInput, testInput) = (convert(Array{Float32,2}, trainDataset[:,1:4]), convert(Array{Float32,2}, testDataset[:,1:4]))\n",
    "\n",
    "normalizationParameters = calculateMinMaxNormalizationParameters(trainInput);\n",
    "(trainInputNormalized, testInputNormalized) = (normalizeMinMax(trainInput, normalizationParameters), normalizeMinMax(testInput, normalizationParameters))\n",
    "\n",
    "crossValidationIndices = crossvalidation(trainDataset[:, 5], 5)\n",
    "\n",
    "\n",
    "result = modelCrossValidation(\n",
    "    :ANN, ann_hyperparameters,\n",
    "    (trainInputNormalized, trainDataset[:, 5]),\n",
    "    crossValidationIndices)\n",
    "\n",
    "println(\"Result ANN\",result)\n",
    "\n",
    "\n",
    "\n",
    "result = modelCrossValidation(\n",
    "    :SVC, svc_hyperparameters,\n",
    "    (trainInputNormalized, trainDataset[:, 5]),\n",
    "    crossValidationIndices)\n",
    "\n",
    "println(\"Result SVC\",result)\n",
    "\n",
    "result = modelCrossValidation(\n",
    "    :DecisionTreeClassifier, svc_hyperparameters,\n",
    "    (trainInputNormalized, trainDataset[:, 5]),\n",
    "    crossValidationIndices)\n",
    "\n",
    "println(\"Result DecisionTreeClassifier\",result)\n",
    "\n",
    "\n",
    "result = modelCrossValidation(\n",
    "    :KNeighborsClassifier, knn_hyperparameters,\n",
    "    (trainInputNormalized, trainDataset[:, 5]),\n",
    "    crossValidationIndices)\n",
    "\n",
    "println(\"Result KNN\",result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
